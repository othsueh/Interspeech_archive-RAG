<!DOCTYPE html>
<html>
    <head>
        <meta charset="UTF-8">
        <title>ISCA Archive</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">

        <link rel="stylesheet" href="../resources/jquery.dataTables.min.css">
        <script src="../resources/jquery-3.5.1.min.js"></script>
        <script src="../resources/jquery.dataTables.min.js"></script>
        <script src="../resources/accent-neutralise.js"></script>

        <!-- Fonts -->
        <link rel="stylesheet" href="../resources/fontawesome-free-subset/style.css">

        <!-- Overall theme -->
        <link rel="stylesheet" href="../resources/w3.css">
        <link rel="stylesheet" href="../resources/w3-theme-blue.css">
        <script src="../resources/w3.js"></script>

        <!-- ISCA Archive modifications -->
        <link rel="stylesheet" href="../resources/is.css">
    </head>
    <body>

        <!-- Top menu bar, fixed on large/medium screens -->
        <div class="w3-top w3-hide-small">
            <div class="w3-bar w3-grayscale-min w3-theme-d4 w3-center">
                <a href="../../index.html" class="w3-bar-item w3-button w3-theme-d2 w3-mobile">
                    <i class="icon-home w3-margin-right"></i>ISCA
                </a>
                <a href="../index.html" class="w3-bar-item w3-button w3-mobile">Archive</a>
                <a href="#" class="w3-bar-item w3-button w3-mobile">Interspeech 2024</a>
                <a class="w3-bar-item w3-button w3-mobile" onclick="document.getElementById('sessionchooser').style.display='block'">Sessions
                </a>
                <a href="#bypaper" class="w3-bar-item w3-button w3-mobile"><i class="icon-search" style='margin-right:5px'></i>Search</a>
                <a href="https://interspeech2024.org/" class="w3-bar-item w3-button w3-mobile w3-right">Website</a>
                <a href="intro.pdf" class="w3-bar-item w3-button w3-mobile w3-right">Booklet</a>
            </div>
        </div>

        <!-- Top menu bar, scrollable on small screens -->
        <div class="w3-hide-large w3-hide-medium">
            <div class="w3-bar w3-grayscale-min w3-theme-d4 w3-center">
                <span class="w3-bar-item w3-button w3-mobile w3-opacity-max">&nbsp;</span>
                <a href="../../index.html" class="w3-bar-item w3-button w3-mobile">
                    <i class="icon-home w3-margin-right"></i>ISCA
                </a>
                <a href="../index.html" class="w3-bar-item w3-button w3-mobile">Archive</a>
                <a href="#" class="w3-bar-item w3-button w3 w3-mobile" onclick="document.getElementById('sessionchooser').style.display='block'">Sessions
                </a>
                <a href="#bypaper" class="w3-bar-item w3-button w3-mobile"><i class="icon-search" style='margin-right:5px'></i>Search</a>
                <a href="https://interspeech2024.org/" class="w3-bar-item w3-button w3-mobile w3-right">Website</a>
                <a href="intro.pdf" class="w3-bar-item w3-button w3-mobile w3-right">Booklet</a>
            </div>
        </div>

        <!-- Papers help popup -->
        <div id="help_papers" class="w3-modal">
            <div class="w3-modal-content w3-card-4 w3-greyscale w3-theme-d4 w3-padding w3-bordered">
                <div class="w3-container">
                    <span onclick="document.getElementById('help_papers').style.display='none'"
                          class="w3-button w3-display-topright">&times;</span>
                    <div class="w3-container">
                        <p class="w3-text">Click on column names to sort.</p>
                        <p class="w3-text">Searching uses the 'and' of terms e.g. <span class='w3-monospace'>Smith Interspeech</span> matches all papers by Smith in any Interspeech. The order of terms is not significant.</p>
                        <p class="w3-text">Use double quotes for exact phrasal matches e.g. <span class='w3-monospace'>"acoustic features"</span>.</p>
                        <p class="w3-text">Case is ignored.</p>
                        <p class="w3-text">Diacritics are optional e.g. <span class='w3-monospace'>lefevre</span> also matches <span class='w3-monospace'>lefÃ¨vre</span> (but not vice versa).</p>
                        <p class="w3-text">It can be useful to turn off spell-checking for the search box in your browser preferences.</p>
                        <p class="w3-text">If you prefer to scroll rather than page, increase the number in the show entries dropdown.</p>
                    </div>
                </div>
            </div>
        </div>


        <div class="w3-top w3-hide-medium w3-hide-large">
            <div class="w3-bar w3-grayscale-min w3-theme-d4 w3-opacity-max">
                <a href="#" class="w3-bar-item w3-button w3-theme-d2 w3-left">top</a>
            </div>
        </div>

        <div class="w3-grayscale w3-theme-l5">

            <!-- Conference header -->
            <div class="w3-container" id="about">
                <div class="w3-content" style="max-width:1100px;margin-top:50px; margin-bottom: 10px">
                    <h2 class="w3-center w3-padding-16">
                        <span class="w3-text">Interspeech 2024</span>
                    </h2>
                    <h5 class="w3-text w3-center"> Kos, Greece<br>
                        1-5 September 2024</h5>
                    <br>
                    <h5 class="w3-text w3-center">Chairs: Itshak Lapidot, Sharon Gannot</h5>
                    <pre class="w3-text w3-center">doi: 10.21437/Interspeech.2024</pre>
                    <pre class="w3-text w3-center">ISSN: 2958-1796</pre>
                </div>
            </div>

            <!-- Sessions -->
            <div class="w3-container">
                <div class="w3-content" style="max-width:1200px;margin-top: 10px">
                    <div class="w3-content" style="height:10px"  id="Keynote 1 ISCA Medallist"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Keynote 1 ISCA Medallist</h4>
                            <hr>
                            <a class="w3-text" href="trancoso24_interspeech.html">
                                <p>
                                    Towards Responsible Speech Processing
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Isabel Trancoso
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="L2 Speech, Bilingualism and Code-Switching"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">L2 Speech, Bilingualism and Code-Switching</h4>
                            <hr>
                            <a class="w3-text" href="wesolek24_interspeech.html">
                                <p>
                                    The influence of L2 accent strength and different error types on personality trait ratings
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Sarah Wesolek, Piotr Gulgowski, Joanna Blaszczak, Marzena Zygis
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="chi24_interspeech.html">
                                <p>
                                    Characterizing code-switching: Applying Linguistic Principles for Metric Assessment and Development
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jie Chi, Electra Wallington, Peter Bell
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="xue24_interspeech.html">
                                <p>
                                    Towards a better understanding of receptive multilingualism: listening conditions and priming effects
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Wei Xue, Ivan Yuen, Bernd MÃ¶bius
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="mohapatra24b_interspeech.html">
                                <p>
                                    2.5D Vocal Tract Modeling: Bridging Low-Dimensional Efficiency with 3D Accuracy
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Debasish Ray Mohapatra, Victor Zappi, Sidney Fels
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Speaker Diarization 1"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Speaker Diarization 1</h4>
                            <hr>
                            <a class="w3-text" href="chowdhury24_interspeech.html">
                                <p>
                                    Investigating Confidence Estimation Measures for Speaker Diarization
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Anurag Chowdhury, Abhinav Misra, Mark C. Fuhs, Monika Woszczyna
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="li24x_interspeech.html">
                                <p>
                                    Speakers Unembedded: Embedding-free Approach to Long-form Neural Diarization
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Xiang Li, Vivek Govindan, Rohit Paturi, Sundararajan Srinivasan
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="huang24d_interspeech.html">
                                <p>
                                    On the Success and Limitations of Auxiliary Network Based Word-Level End-to-End Neural Speaker Diarization
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yiling Huang, Weiran Wang, Guanlong Zhao, Hank Liao, Wei Xia, Quan Wang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="harkonen24_interspeech.html">
                                <p>
                                    EEND-M2F: Masked-attention mask transformers for speaker diarization
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Marc HÃ¤rkÃ¶nen, Samuel J. Broughton, Lahiru Samarakoon
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="yin24_interspeech.html">
                                <p>
                                    AFL-Net: Integrating Audio, Facial, and Lip Modalities with a Two-step Cross-attention for Robust Speaker Diarization in the Wild
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        YongKang Yin, Xu Li, Ying Shan, YueXian Zou
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="arya24_interspeech.html">
                                <p>
                                    Exploiting Wavelet Scattering Transform for an Unsupervised Speaker Diarization in Deep Neural Network Framework
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Arunav Arya, Murtiza Ali, Karan Nathwani
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Speech and Audio Analysis and Representations"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Speech and Audio Analysis and Representations</h4>
                            <hr>
                            <a class="w3-text" href="zhao24h_interspeech.html">
                                <p>
                                    MINT: Boosting Audio-Language Model via Multi-Target Pre-Training and Instruction Tuning
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Hang Zhao, Yifei Xin, Zhesong Yu, Bilei Zhu, Lu Lu, Zejun Ma
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="niizumi24_interspeech.html">
                                <p>
                                    M2D-CLAP: Masked Modeling Duo Meets CLAP for Learning General-purpose Audio-Language Representation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Daisuke Niizumi, Daiki Takeuchi, Yasunori Ohishi, Noboru Harada, Masahiro Yasuda, Shunsuke Tsubaki, Keisuke Imoto
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="fujita24_interspeech.html">
                                <p>
                                    Audio Fingerprinting with Holographic Reduced Representations
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yusuke Fujita, Tatsuya Komatsu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="meyer24b_interspeech.html">
                                <p>
                                    RAST: A Reference-Audio Synchronization Tool for Dubbed Content
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        David Meyer, Eitan Abecassis, Clara Fernandez-Labrador, Christopher Schroers
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="li24ja_interspeech.html">
                                <p>
                                    YOLOPitch: A Time-Frequency Dual-Branch YOLO Model for Pitch Estimation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Xuefei Li, Hao Huang, Ying Hu, Liang He, Jiabao Zhang, Yuyi Wang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="ullah24_interspeech.html">
                                <p>
                                    Reduce, Reuse, Recycle: Is Perturbed Data Better than Other Language Augmentation for Low Resource Self-Supervised Speech Models
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Asad Ullah, Alessandro Ragano, Andrew Hines
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="pieper24_interspeech.html">
                                <p>
                                    AlignNet: Learning dataset score alignment functions to enable better training of speech quality estimators
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jaden Pieper, Stephen Voran
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Acoustic Event Detection and Classification 2"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Acoustic Event Detection and Classification 2</h4>
                            <hr>
                            <a class="w3-text" href="liang24_interspeech.html">
                                <p>
                                    Improving Audio Classification with Low-Sampled Microphone Input: An Empirical Study Using Model Self-Distillation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Dawei Liang, Alice Zhang, David Harwath, Edison Thomaz
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="mu24_interspeech.html">
                                <p>
                                    MFF-EINV2: Multi-scale Feature Fusion across Spectral-Spatial-Temporal Domains for Sound Event Localization and Detection
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Da Mu, Zhicheng Zhang, Haobo Yue
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="nam24_interspeech.html">
                                <p>
                                    Diversifying and Expanding Frequency-Adaptive Convolution Kernels for Sound Event Detection
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Hyeonuk Nam, Seong-Hu Kim, Deokki Min, Junhyeok Lee, Yong-Hwa Park
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="ho24_interspeech.html">
                                <p>
                                    Stream-based Active Learning for Anomalous Sound Detection in Machine Condition Monitoring
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Tuan Vu Ho, Kota Dohi, Yohei Kawaguchi
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="jiang24c_interspeech.html">
                                <p>
                                    AnoPatch: Towards Better Consistency in Machine Anomalous Sound Detection
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Anbai Jiang, Bing Han, Zhiqiang Lv, Yufeng Deng, Wei-Qiang Zhang, Xie Chen, Yanmin Qian, Jia Liu, Pingyi Fan
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="xie24d_interspeech.html">
                                <p>
                                    FakeSound: Deepfake General Audio Detection
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Zeyu Xie, Baihan Li, Xuenan Xu, Zheng Liang, Kai Yu, Mengyue Wu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="ghaffarzadegan24_interspeech.html">
                                <p>
                                    Sound of Traffic: A Dataset for Acoustic Traffic Identification and Counting
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Shabnam Ghaffarzadegan, Luca Bondi, Wei-Chang Lin, Abinaya Kumar, Ho-Hsiang Wu, Hans-Georg Horst, Samarjit Das
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Detection and Classification of Bioacoustic Signals"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Detection and Classification of Bioacoustic Signals</h4>
                            <hr>
                            <a class="w3-text" href="kumar24_interspeech.html">
                                <p>
                                    Vision Transformer Segmentation for Visual Bird Sound Denoising
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Sahil Kumar, Jialu Li, Youshan Zhang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="jing24_interspeech.html">
                                <p>
                                    DB3V: A Dialect Dominated Dataset of Bird Vocalisation for Cross-corpus Bird Species Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Xin Jing, Luyang Zhang, Jiangjian Xie, Alexander Gebhard, Alice Baird, BjÃ¶rn Schuller
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="cauzinille24_interspeech.html">
                                <p>
                                    Investigating self-supervised speech models' ability to classify animal vocalizations: The case of gibbon's vocal signatures
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jules Cauzinille, BenoÃ®t Favre, Ricard Marxer, Dena Clink, Abdul Hamid Ahmad, Arnaud Rey
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="qiu24_interspeech.html">
                                <p>
                                    Study Selectively: An Adaptive Knowledge Distillation based on a Voting Network for Heart Sound Classification
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Xihang Qiu, Lixian Zhu, Zikai Song, Zeyu Chen, Haojie Zhang, Kun Qian, Ye Zhang, Bin Hu, Yoshiharu Yamamoto, BjÃ¶rn W. Schuller
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="lin24_interspeech.html">
                                <p>
                                    SimuSOE: A Simulated Snoring Dataset for Obstructive Sleep Apnea-Hypopnea Syndrome Evaluation during Wakefulness
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jie Lin, Xiuping Yang, Li Xiao, Xinhong Li, Weiyan Yi, Yuhong Yang, Weiping Tu, Xiong Chen
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Acoustic Echo Cancellation"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Acoustic Echo Cancellation</h4>
                            <hr>
                            <a class="w3-text" href="nayak24_interspeech.html">
                                <p>
                                    Multi-mic Echo Cancellation Coalesced with Beamforming for Real World Adverse Acoustic Conditions
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Premanand Nayak, Kamini Sabu, M. Ali Basha Shaik
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="khanagha24_interspeech.html">
                                <p>
                                    Interference Aware Training Target for DNN based joint Acoustic Echo Cancellation and Noise Suppression
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Vahid Khanagha, Dimitris Koutsaidis, Kaustubh Kalgaonkar, Sriram Srinivasan
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="gao24b_interspeech.html">
                                <p>
                                    Low Complexity Echo Delay Estimator Based on Binarized Feature Matching
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yi Gao, Xiang Su
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="ni24_interspeech.html">
                                <p>
                                    MSA-DPCRN: A Multi-Scale Asymmetric Dual-Path Convolution Recurrent Network with Attentional Feature Fusion for Acoustic Echo Cancellation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Ye Ni, Cong Pang, Chengwei Huang, Cairong Zou
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="schwartz24_interspeech.html">
                                <p>
                                    Efficient Joint Bemforming and Acoustic Echo Cancellation Structure for Conference Call Scenarios
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Ofer Schwartz, Sharon Gannot
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="zhao24b_interspeech.html">
                                <p>
                                    SDAEC: Signal Decoupling for Advancing Acoustic Echo Cancellation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Fei Zhao, Jinjiang Liu, Xueliang Zhang
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Speech Synthesis: Voice Conversion 1"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Speech Synthesis: Voice Conversion 1</h4>
                            <hr>
                            <a class="w3-text" href="seki24_interspeech.html">
                                <p>
                                    Spatial Voice Conversion: Voice Conversion Preserving Spatial Information and Non-target Signals
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Kentaro Seki, Shinnosuke Takamichi, Norihiro Takamune, Yuki Saito, Kanami Imamura, Hiroshi Saruwatari
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="baade24_interspeech.html">
                                <p>
                                    Neural Codec Language Models for Disentangled and Textless Voice Conversion
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Alan Baade, Puyuan Peng, David Harwath
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="morrison24_interspeech.html">
                                <p>
                                    Fine-Grained and Interpretable Neural Speech Editing
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Max Morrison, Cameron Churchwell, Nathan Pruyne, Bryan Pardo
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kaneko24_interspeech.html">
                                <p>
                                    FastVoiceGrad: One-step Diffusion-Based Voice Conversion with Adversarial Conditional Diffusion Distillation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Takuhiro Kaneko, Hirokazu Kameoka, Kou Tanaka, Yuto Kondo
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="ning24_interspeech.html">
                                <p>
                                    DualVC 3: Leveraging Language Model Generated Pseudo Context for End-to-end Low Latency Streaming Voice Conversion
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Ziqian Ning, Shuai Wang, Pengcheng Zhu, Zhichao Wang, Jixun Yao, Lei Xie, Mengxiao Bi
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="qi24_interspeech.html">
                                <p>
                                    Towards Realistic Emotional Voice Conversion using Controllable Emotional Intensity
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Tianhua Qi, Shiyan Wang, Cheng Lu, Yan Zhao, Yuan Zong, Wenming Zheng
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Neural Network Architectures for ASR 2"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Neural Network Architectures for ASR 2</h4>
                            <hr>
                            <a class="w3-text" href="nakagome24_interspeech.html">
                                <p>
                                    InterBiasing: Boost Unseen Word Recognition through Biasing Intermediate Predictions
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yu Nakagome, Michael Hentschel
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="meng24_interspeech.html">
                                <p>
                                    SEQ-former: A context-enhanced and efficient automatic speech recognition framework
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Qinglin Meng, Min Liu, Kaixun Huang, Kun Wei, Lei Xie, Zongfeng Quan, Weihong Deng, Quan Lu, Ning Jiang, Guoqing Zhao
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="flynn24b_interspeech.html">
                                <p>
                                    How Much Context Does My Attention-Based ASR System Need?
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Robert Flynn, Anton Ragni
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="vitale24_interspeech.html">
                                <p>
                                    Rich speech signal: exploring and exploiting  end-to-end automatic speech recognizersâ ability to model hesitation phenomena
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Vincenzo Norman Vitale, Loredana Schettino, Francesco Cutugno
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="zhang24q_interspeech.html">
                                <p>
                                    Transmitted and Aggregated Self-Attention for Automatic Speech Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Tian-Hao Zhang, Xinyuan Qian, Feng Chen, Xu-Cheng Yin
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="prabhu24_interspeech.html">
                                <p>
                                    MULTI-CONVFORMER: Extending Conformer with Multiple Convolution Kernels
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Darshan Prabhu, Yifan Peng, Preethi Jyothi, Shinji Watanabe
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="miyazaki24_interspeech.html">
                                <p>
                                    Exploring the Capability of Mamba in Speech Applications
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Koichi Miyazaki, Yoshiki Masuyama, Masato Murata
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="li24sa_interspeech.html">
                                <p>
                                    Robust Voice Activity Detection using Locality-Sensitive Hashing and Residual Frequency-Temporal Attention
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Shu Li, Peng Zhang, Ye Li
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="wan24_interspeech.html">
                                <p>
                                    Lightweight Transducer Based on Frame-Level Criterion
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Genshun Wan, Mengzhi Wang, Tingzhi Mao, Hang Chen, Zhongfu Ye
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="gupta24_interspeech.html">
                                <p>
                                    Exploring the limits of decoder-only models trained on public speech recognition corpora
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Ankit Gupta, George Saon, Brian Kingsbury
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="gong24b_interspeech.html">
                                <p>
                                    Contextual Biasing Speech Recognition in Speech-enhanced Large Language Model
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Xun Gong, Anqi Lv, Zhiming Wang, Yanmin Qian
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Decoding Algorithms"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Decoding Algorithms</h4>
                            <hr>
                            <a class="w3-text" href="wang24k_interspeech.html">
                                <p>
                                    Towards Effective and Efficient Non-autoregressive Decoding Using Block-based Attention Mask
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Tianzi Wang, Xurong Xie, Zhaoqing Li, Shoukang Hu, Zengrui Jin, Jiajun Deng, Mingyu Cui, Shujie Hu, Mengzhe Geng, Guinan Li, Helen Meng, Xunying Liu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="zou24_interspeech.html">
                                <p>
                                    E-Paraformer: A Faster and Better  Parallel Transformer for Non-autoregressive End-to-End Mandarin Speech Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Kun Zou, Fengyun Tan, Ziyang Zhuang, Chenfeng Miao, Tao Wei, Shaodan Zhai, Zijian Li, Wei Hu, Shaojun Wang, Jing Xiao
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="ciaperoni24_interspeech.html">
                                <p>
                                    Beam-search SIEVE for low-memory speech recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Martino Ciaperoni, Athanasios Katsamanis, Aristides Gionis, Panagiotis Karras
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="galvez24_interspeech.html">
                                <p>
                                    Speed of Light Exact Greedy Decoding for RNN-T Speech Recognition Models on GPU
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Daniel Galvez, Vladimir Bataev, Hainan Xu, Tim Kaldewey
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="wang24w_interspeech.html">
                                <p>
                                    Contextual Biasing with the Knuth-Morris-Pratt Matching Algorithm
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Weiran Wang, Zelin Wu, Diamantino Caseiro, Tsendsuren Munkhdalai, Khe Chai Sim, Pat Rondon, Golan Pundak, Gan Song, Rohit Prabhavalkar, Zhong Meng, Ding Zhao, Tara Sainath, Yanzhang He, Pedro Moreno Mengibar
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="takagi24_interspeech.html">
                                <p>
                                    Text-only Domain Adaptation for CTC-based Speech Recognition through Substitution of Implicit Linguistic Information in the Search Space
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Tatsunari Takagi, Yukoh Wakabayashi, Atsunori Ogawa, Norihide Kitaoka
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Pronunciation Assessment"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Pronunciation Assessment</h4>
                            <hr>
                            <a class="w3-text" href="wang24la_interspeech.html">
                                <p>
                                    Pitch-Aware RNN-T for Mandarin Chinese Mispronunciation Detection and Diagnosis
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Xintong Wang, Mingqian Shi, Ye Wang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="chen24c_interspeech.html">
                                <p>
                                    MultiPA: A Multi-task Speech Pronunciation Assessment Model for Open Response Scenarios
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yu-Wen Chen, Zhou Yu, Julia Hirschberg
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="cao24b_interspeech.html">
                                <p>
                                    A Framework for Phoneme-Level Pronunciation Assessment Using CTC
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Xinwei Cao, Zijian Fan, TorbjÃ¸rn Svendsen, Giampiero Salvi
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="shahin24_interspeech.html">
                                <p>
                                    Phonological-Level Mispronunciation Detection and Diagnosis
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Mostafa Shahin, Beena Ahmed
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="do24_interspeech.html">
                                <p>
                                    Acoustic Feature Mixup for Balanced Multi-aspect Pronunciation Assessment
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Heejin Do, Wonjun Lee, Gary Geunbae Lee
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="phan24_interspeech.html">
                                <p>
                                    Automated content assessment and feedback for Finnish L2 learners in a picture description speaking task
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Nhan Phan, Anna von Zansen, Maria Kautonen, Ekaterina Voskoboinik, Tamas Grosz, Raili Hilden, Mikko Kurimo
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Spoken Language Processing"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Spoken Language Processing</h4>
                            <hr>
                            <a class="w3-text" href="wang24c_interspeech.html">
                                <p>
                                    Query-by-Example Keyword Spotting Using Spectral-Temporal Graph Attentive Pooling and Multi-Task Learning
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Zhenyu Wang, Shuyu Kong, Li Wan, Biqiao Zhang, Yiteng Huang, Mumin Jin, Ming Sun, Xin Lei, Zhaojun Yang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="jung24_interspeech.html">
                                <p>
                                    Relational Proxy Loss for Audio-Text based Keyword Spotting
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Youngmoon Jung, Seungjin Lee, Joon-Young Yang, Jaeyoung Roh, Chang Woo Han, Hoon-Young Cho
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="jin24d_interspeech.html">
                                <p>
                                    CTC-aligned Audio-Text Embedding for Streaming Open-vocabulary Keyword Spotting
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Sichen Jin, Youngmoon Jung, Seungjin Lee, Jaeyoung Roh, Changwoo Han, Hoonyoung Cho
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="li24r_interspeech.html">
                                <p>
                                    Text-aware Speech Separation for Multi-talker Keyword Spotting
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Haoyu Li, Baochen Yang, Yu Xi, Linfeng Yu, Tian Tan, Hao Li, Kai Yu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="yen24_interspeech.html">
                                <p>
                                    Language-Universal Speech Attributes Modeling for Zero-Shot Multilingual Spoken Keyword Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Hao Yen, Pin-Jui Ku, Sabato Marco Siniscalchi, Chin-Hui Lee
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="monteiro24_interspeech.html">
                                <p>
                                    Adding User Feedback To Enhance CB-Whisper
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Raul Monteiro
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="peng24b_interspeech.html">
                                <p>
                                    OWSM v3.1: Better and Faster Open Whisper-Style Speech Models based on E-Branchformer
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yifan Peng, Jinchuan Tian, William Chen, Siddhant Arora, Brian Yan, Yui Sudo, Muhammad Shakeel, Kwanghee Choi, Jiatong Shi, Xuankai Chang, Jee-weon Jung, Shinji Watanabe
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Spoken Machine Translation 2"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Spoken Machine Translation 2</h4>
                            <hr>
                            <a class="w3-text" href="chen24m_interspeech.html">
                                <p>
                                    Parameter-Efficient Adapter Based on Pre-trained Models for Speech Translation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Nan Chen, Yonghe Wang, Feilong Bao
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="abdullah24_interspeech.html">
                                <p>
                                    Wave to Interlingua: Analyzing Representations of Multilingual Speech Transformers for Spoken Language Translation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Badr M. Abdullah, Mohammed Maqsood Shaik, Dietrich Klakow
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="chen24w_interspeech.html">
                                <p>
                                    Knowledge-Preserving Pluggable Modules for Multilingual Speech Translation Tasks
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Nan Chen, Yonghe Wang, Feilong Bao
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="rabatin24_interspeech.html">
                                <p>
                                    Navigating the Minefield of MT Beam Search in Cascaded Streaming Speech Translation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Rastislav Rabatin, Frank Seide, Ernie Chang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="wang24aa_interspeech.html">
                                <p>
                                    Soft Language Identification for Language-Agnostic Many-to-One End-to-End Speech Translation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Peidong Wang, Jian Xue, Jinyu Li, Junkun Chen, Aswin Shanmugam Subramanian
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="min24_interspeech.html">
                                <p>
                                    A Unit-based System and Dataset for Expressive Direct Speech-to-Speech Translation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Anna Min, Chenxu Hu, Yi Ren, Hang Zhao
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="oneata24_interspeech.html">
                                <p>
                                    Translating speech with just images
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Dan Oneata, Herman Kamper
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="khurana24_interspeech.html">
                                <p>
                                    ZeroST: Zero-Shot Speech Translation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Sameer Khurana, Chiori Hori, Antoine Laurent, Gordon Wichern, Jonathan Le Roux
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Biosignal-enabled Spoken Communication"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Biosignal-enabled Spoken Communication</h4>
                            <hr>
                            <a class="w3-text" href="li24ca_interspeech.html">
                                <p>
                                    A multimodal approach to study the nature of coordinative patterns underlying speech rhythm
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jinyu Li, Leonardo Lancia
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="wu24k_interspeech.html">
                                <p>
                                    Towards EMG-to-Speech with Necklace Form Factor
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Peter Wu, Ryan Kaveh, Raghav Nautiyal, Christine Zhang, Albert Guo, Anvitha Kachinthaya, Tavish Mishra, Bohan Yu, Alan W Black, Rikky Muller, Gopala Krishna Anumanchipalli
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="bras24_interspeech.html">
                                <p>
                                    Using articulated speech EEG signals for imagined speech decoding
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Chris Bras, Tanvina Patel, Odette Scharenborg
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kwon24_interspeech.html">
                                <p>
                                    Direct Speech Synthesis from Non-Invasive, Neuromagnetic Signals
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jinuk Kwon, David Harwath, Debadatta Dash, Paul Ferrari, Jun Wang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="yang24o_interspeech.html">
                                <p>
                                    Optical Flow Guided Tongue Trajectory Generation for Diffusion-based Acoustic to Articulatory Inversion
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yudong Yang, Rongfeng Su, Rukiye Ruzi, Manwa Ng, Shaofeng Zhao, Nan Yan, Lan Wang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="jain24_interspeech.html">
                                <p>
                                    Multimodal Segmentation for Vocal Tract Modeling
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Rishi Jain, Bohan Yu, Peter Wu, Tejas Prabhune, Gopala Anumanchipalli
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="bandekar24_interspeech.html">
                                <p>
                                    Articulatory synthesis using representations learnt through phonetic label-aware contrastive loss
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jesuraj Bandekar, Sathvik Udupa, Prasanta Kumar Ghosh
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="yan24b_interspeech.html">
                                <p>
                                    Auditory Attention Decoding in Four-Talker Environment with EEG
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yujie Yan, Xiran Xu, Haolin Zhu, Pei Tian, Zhongshu Ge, Xihong Wu, Jing Chen
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="lin24f_interspeech.html">
                                <p>
                                    ASA: An Auditory Spatial Attention Dataset with Multiple Speaking Locations
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Zijie Lin, Tianyu He, Siqi Cai, Haizhou Li
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="pahuja24_interspeech.html">
                                <p>
                                    Leveraging Graphic and Convolutional Neural Networks for Auditory Attention Detection with EEG
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Saurav Pahuja, Gabriel Ivucic, Pascal Himmelmann, Siqi Cai, Tanja Schultz, Haizhou Li
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Individual and Social Factors in Phonetics"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Individual and Social Factors in Phonetics</h4>
                            <hr>
                            <a class="w3-text" href="pistor24_interspeech.html">
                                <p>
                                    Echoes of Implicit Bias Exploring Aesthetics and Social Meanings of Swiss German Dialect Features
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Tillmann Pistor, Adrian Leemann
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="li24ra_interspeech.html">
                                <p>
                                    In search of structure and correspondence in intra-speaker trial-to-trial variability
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Vivian G. Li
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="smith24_interspeech.html">
                                <p>
                                    Modelled Multivariate Overlap: A method for measuring vowel merger
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Irene Smith, Morgan Sonderegger, The Spade Consortium
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="ochi24_interspeech.html">
                                <p>
                                    Entrainment Analysis and Prosody Prediction of Subsequent Interlocutorâs Backchannels in Dialogue
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Keiko Ochi, Koji Inoue, Divesh Lala, Tatsuya Kawahara
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="tanner24_interspeech.html">
                                <p>
                                    Exploring the anatomy of articulation rate in spontaneous English speech: relationships between utterance length effects and social factors
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        James Tanner, Morgan Sonderegger, Jane Stuart-Smith, Tyler Kendall, Jeff Mielke, Robin Dodsworth, Erik Thomas
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="taylor24_interspeech.html">
                                <p>
                                    Familiar and Unfamiliar Speaker Identification in Speech and Singing
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Katelyn Taylor, Amelia Gully, Helena Daffern
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Paralinguistics"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Paralinguistics</h4>
                            <hr>
                            <a class="w3-text" href="parragallego24_interspeech.html">
                                <p>
                                    Cross-transfer Knowledge between Speech and Text Encoders to Evaluate Customer Satisfaction
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Luis Felipe Parra-Gallego, Tilak Purohit, Bogdan Vlasenko, Juan Rafael Orozco-Arroyave, Mathew Magimai.-Doss
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kodali24_interspeech.html">
                                <p>
                                    Fine-tuning of Pre-trained Models for Classification of Vocal Intensity Category from Speech Signals
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Manila Kodali, Sudarsana Reddy Kadiri, Paavo Alku
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kathan24_interspeech.html">
                                <p>
                                    Real-world PTSD Recognition: A Cross-corpus and Cross-linguistic Evaluation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Alexander Kathan, Martin BÃ¼rger, Andreas Triantafyllopoulos, Sabrina Milkus, Jonas Hohmann, Pauline Muderlak, JÃ¼rgen Schottdorf, Richard Musil, BjÃ¶rn Schuller, Shahin Amiriparian
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="bhattacharya24_interspeech.html">
                                <p>
                                    Switching Tongues, Sharing Hearts: Identifying the Relationship between Empathy and Code-switching in Speech
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Debasmita Bhattacharya, Eleanor Lin, Run Chen, Julia Hirschberg
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Speaker Recognition: Adversarial and Spoofing Attacks"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Speaker Recognition: Adversarial and Spoofing Attacks</h4>
                            <hr>
                            <a class="w3-text" href="rosello24_interspeech.html">
                                <p>
                                    Anti-spoofing Ensembling Model: Dynamic Weight Allocation in Ensemble Models for Improved Voice Biometrics Security
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Eros Rosello, Angel M. Gomez, IvÃ¡n LÃ³pez-Espejo, Antonio M. Peinado, Juan M. MartÃ­n-DoÃ±as
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="zhang24j_interspeech.html">
                                <p>
                                    Spoof Diarization: &quot;What Spoofed When&quot; in Partially Spoofed Audio
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Lin Zhang, Xin Wang, Erica Cooper, Mireia Diez, Federico Landini, Nicholas Evans, Junichi Yamagishi
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="wu24b_interspeech.html">
                                <p>
                                    Spoofing Speech Detection by Modeling Local Spectro-Temporal and Long-term Dependency
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Haochen Wu, Wu Guo, Zhentao Zhang, Wenting Zhao, Shengyu Peng, Jie Zhang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="lu24b_interspeech.html">
                                <p>
                                    Improving Copy-Synthesis Anti-Spoofing Training Method with Rhythm and Speaker Perturbation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jingze Lu, Yuxiang Zhang, Zhuo Li, Zengqiang Shang, Wenchao Wang, Pengyuan Zhang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kan24_interspeech.html">
                                <p>
                                    VoiceDefense: Protecting Automatic Speaker Verification Models Against Black-box Adversarial Attacks
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yip Keng Kan, Ke Xu, Hao Li, Jie Shi
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="chen24p_interspeech.html">
                                <p>
                                    Neural Codec-based Adversarial Sample Detection for Speaker Verification
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Xuanjun Chen, Jiawei Du, Haibin Wu, Jyh-Shing Roger Jang, Hung-yi Lee
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="chen24_interspeech.html">
                                <p>
                                    Textual-Driven Adversarial Purification for Speaker Verification
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Sizhou Chen, Yibo Bai, Jiadi Yao, Xiao-Lei Zhang, Xuelong Li
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="li24g_interspeech.html">
                                <p>
                                    Boosting the Transferability of Adversarial Examples with Gradient-Aligned Ensemble Attack for Speaker Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Zhuhai Li, Jie Zhang, Wu Guo, Haochen Wu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="truong24b_interspeech.html">
                                <p>
                                    Temporal-Channel Modeling in Multi-head Self-Attention for Synthetic Speech Detection
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Duc-Tuan Truong, Ruijie Tao, Tuan Nguyen, Hieu-Thi Luong, Kong Aik Lee, Eng Siong Chng
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Audio Event Detection and Classification 1"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Audio Event Detection and Classification 1</h4>
                            <hr>
                            <a class="w3-text" href="feng24b_interspeech.html">
                                <p>
                                    Can Synthetic Audio From Generative Foundation Models Assist Audio Recognition and Speech Modeling?
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Tiantian Feng, Dimitrios Dimitriadis, Shrikanth S. Narayanan
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="dinkel24b_interspeech.html">
                                <p>
                                    Scaling up masked audio encoder learning for general audio classification
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Heinrich Dinkel, Zhiyong Yan, Yongqing Wang, Junbo Zhang, Yujun Wang, Bin Wang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="yadav24_interspeech.html">
                                <p>
                                    Audio Mamba: Selective State Spaces for Self-Supervised Audio Representations
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Sarthak Yadav, Zheng-Hua Tan
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="cai24_interspeech.html">
                                <p>
                                    MAT-SED: A Masked Audio Transformer with Masked-Reconstruction Based Pre-training for Sound Event Detection
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Pengfei Cai, Yan Song, Kang Li, Haoyu Song, Ian McLoughlin
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="ebbers24_interspeech.html">
                                <p>
                                    Sound Event Bounding Boxes
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Janek Ebbers, FranÃ§ois G. Germain, Gordon Wichern, Jonathan Le Roux
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="li24k_interspeech.html">
                                <p>
                                    Low-Complexity Acoustic Scene Classification Using Parallel Attention-Convolution Network
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yanxiong Li, Jiaxin Tan, Guoqing Chen, Jialong Li, Yongjie Si, Qianhua He
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Source Separation 2"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Source Separation 2</h4>
                            <hr>
                            <a class="w3-text" href="taherian24_interspeech.html">
                                <p>
                                    Towards Explainable Monaural Speaker Separation with Auditory-based Training
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Hassan Taherian, Vahid Ahmadi Kalkhorani, Ashutosh Pandey, Daniel Wong, Buye Xu, DeLiang Wang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="ewert24_interspeech.html">
                                <p>
                                    Does the Lombard Effect Matter in Speech Separation? Introducing the Lombard-GRID-2mix Dataset
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Iva Ewert, Marvin Borsdorf, Haizhou Li, Tanja Schultz
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="pan24_interspeech.html">
                                <p>
                                    PARIS: Pseudo-AutoRegressIve Siamese Training for Online Speech Separation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Zexu Pan, Gordon Wichern, FranÃ§ois G. Germain, Kohei Saijo, Jonathan Le Roux
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="zhang24p_interspeech.html">
                                <p>
                                    OR-TSE: An Overlap-Robust Speaker Encoder for Target Speech Extraction
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yiru Zhang, Linyu Yao, Qun Yang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="hsieh24b_interspeech.html">
                                <p>
                                    Multimodal Representation Loss Between Timed Text and Audio for Regularized Speech Separation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Tsun-An Hsieh, Heeyoul Choi, Minje Kim
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="lin24g_interspeech.html">
                                <p>
                                    SA-WavLM: Speaker-Aware Self-Supervised Pre-training for Mixture Speech
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jingru Lin, Meng Ge, Junyi Ao, Liqun Deng, Haizhou Li
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="wang24g_interspeech.html">
                                <p>
                                    TSE-PI: Target Sound Extraction under Reverberant Environments with Pitch Information
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yiwen Wang, Xihong Wu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="saijo24_interspeech.html">
                                <p>
                                    Enhanced Reverberation as Supervision for Unsupervised Speech Separation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Kohei Saijo, Gordon Wichern, FranÃ§ois G. Germain, Zexu Pan, Jonathan Le Roux
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Noise Reduction, Dereverberation, and Echo Cancellation"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Noise Reduction, Dereverberation, and Echo Cancellation</h4>
                            <hr>
                            <a class="w3-text" href="zhao24_interspeech.html">
                                <p>
                                    Deep Echo Path Modeling for Acoustic Echo Cancellation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Fei Zhao, Chenggang Zhang, Shulin He, Jinjiang Liu, Xueliang Zhang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="guo24_interspeech.html">
                                <p>
                                    Graph Attention Based Multi-Channel U-Net for Speech Dereverberation With Ad-Hoc Microphone Arrays
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Hongmei Guo, Yijiang Chen, Xiao-Lei Zhang, Xuelong Li
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="bahrman24_interspeech.html">
                                <p>
                                    Speech dereverberation constrained on room impulse response characteristics
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Louis Bahrman, Mathieu Fontaine, Jonathan Le Roux, GaÃ«l Richard
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="yuan24_interspeech.html">
                                <p>
                                    DeWinder: Single-Channel Wind Noise Reduction using Ultrasound Sensing
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Kuang Yuan, Shuo Han, Swarun Kumar, Bhiksha Raj
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="barnhill24_interspeech.html">
                                <p>
                                    ANIMAL-CLEAN â A Deep Denoising Toolkit for Animal-Independent Signal Enhancement
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Alexander Barnhill, Elmar Noeth, Andreas Maier, Christian Bergler
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="nayak24b_interspeech.html">
                                <p>
                                    Elucidating Clock-drift Using Real-world Audios In Wireless Mode For Time-offset Insensitive End-to-End Asynchronous Acoustic Echo Cancellation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Premanand Nayak, M. Ali Basha Shaik
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="wang24o_interspeech.html">
                                <p>
                                    QMixCAT: Unsupervised Speech Enhancement Using Quality-guided Signal Mixing and Competitive Alternating Model Training
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Shilin Wang, Haixin Guan, Yanhua Long
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Computationally-Efficient Speech Enhancement"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Computationally-Efficient Speech Enhancement</h4>
                            <hr>
                            <a class="w3-text" href="bae24_interspeech.html">
                                <p>
                                    Speech Boosting: Low-Latency Live Speech Enhancement for TWS Earbuds
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Hanbin Bae, Pavel Andreev, Azat Saginbaev, Nicholas Babaev, WonJun Lee, Hosang Sung, Hoon-Young Cho
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="gholami24_interspeech.html">
                                <p>
                                    Knowledge Distillation for Tiny Speech Enhancement with Latent Feature Augmentation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Behnam Gholami, Mostafa El-Khamy, KeeBong Song
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="zhang24o_interspeech.html">
                                <p>
                                    Sub-PNWR: Speech Enhancement Based on Signal Sub-Band Splitting and Pseudo Noisy Waveform Reconstruction Loss
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yuewei Zhang, Huanbin Zou, Jie Zhu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="zhao24c_interspeech.html">
                                <p>
                                    Streamlining Speech Enhancement DNNs: an Automated Pruning Method Based on Dependency Graph with Advanced Regularized Loss Strategies
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Zugang Zhao, Jinghong Zhang, Yonghui Liu, Jianbing Liu, Kai Niu, Zhiqiang He
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="zhang24k_interspeech.html">
                                <p>
                                    Lightweight Dynamic Sparse Transformer for Monaural Speech Enhancement
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Zehua Zhang, Xuyi Zhuang, Yukun Qian, Mingjiang Wang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="lin24h_interspeech.html">
                                <p>
                                    MUSE: Flexible Voiceprint Receptive Fields and Multi-Path Fusion Enhanced Taylor Transformer for U-Net-based Speech Enhancement
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Zizhen Lin, Xiaoting Chen, Junyu Wang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="cheng24_interspeech.html">
                                <p>
                                    Dynamic Gated Recurrent Neural Network for Compute-efficient Speech Enhancement
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Longbiao Cheng, Ashutosh Pandey, Buye Xu, Tobi Delbruck, Shih-Chii Liu
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Zero-shot TTS"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Zero-shot TTS</h4>
                            <hr>
                            <a class="w3-text" href="xue24c_interspeech.html">
                                <p>
                                    Improving Audio Codec-based Zero-Shot Text-to-Speech Synthesis with Multi-Modal Context and Large Language Model
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jinlong Xue, Yayue Deng, Yicheng Han, Yingming Gao, Ya Li
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="wang24v_interspeech.html">
                                <p>
                                    An Investigation of Noise Robustness for Flow-Matching-Based Zero-Shot TTS
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Xiaofei Wang, Sefik Emre Eskimez, Manthan Thakker, Hemin Yang, Zirun Zhu, Min Tang, Yufei Xia, Jinzhu Li, Sheng Zhao, Jinyu Li, Naoyuki Kanda
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="fujita24b_interspeech.html">
                                <p>
                                    Lightweight Zero-shot Text-to-Speech with Mixture of Adapters
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Kenichi Fujita, Takanori Ashihara, Marc Delcroix, Yusuke Ijima
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="pankov24_interspeech.html">
                                <p>
                                    DINO-VITS: Data-Efficient Zero-Shot TTS with Self-Supervised Speaker Verification Loss for Noise Robustness
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Vikentii Pankov, Valeria Pronina, Alexander Kuzmin, Maksim Borisov, Nikita Usoltsev, Xingshan Zeng, Alexander Golubkov, Nikolai Ermolenko, Aleksandra Shirshova, Yulia Matveeva
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Noise Robustness, Far-Field, and Multi-Talker ASR"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Noise Robustness, Far-Field, and Multi-Talker ASR</h4>
                            <hr>
                            <a class="w3-text" href="jin24_interspeech.html">
                                <p>
                                    LibriheavyMix: A 20,000-Hour Dataset for Single-Channel Reverberant Multi-Talker Speech Separation, ASR and Speaker Diarization
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Zengrui Jin, Yifan Yang, Mohan Shi, Wei Kang, Xiaoyu Yang, Zengwei Yao, Fangjun Kuang, Liyong Guo, Lingwei Meng, Long Lin, Yong Xu, Shi-Xiong Zhang, Daniel Povey
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="xing24_interspeech.html">
                                <p>
                                    A Joint Noise Disentanglement and Adversarial Training Framework for Robust Speaker Verification
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Xujiang Xing, Mingxing Xu, Thomas Fang Zheng
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="shi24e_interspeech.html">
                                <p>
                                    Serialized Output Training by Learned Dominance
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Ying Shi, Lantian Li, Shi Yin, Dong Wang, Jiqing Han
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="zheng24d_interspeech.html">
                                <p>
                                    SOT Triggered Neural Clustering for Speaker Attributed ASR
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Xianrui Zheng, Guangzhi Sun, Chao Zhang, Philip C. Woodland
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="bando24_interspeech.html">
                                <p>
                                    Neural Blind Source Separation and Diarization for Distant Speech Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yoshiaki Bando, Tomohiko Nakamura, Shinji Watanabe
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="masumura24_interspeech.html">
                                <p>
                                    Unified Multi-Talker ASR with and without Target-speaker Enrollment
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Ryo Masumura, Naoki Makishima, Tomohiro Tanaka, Mana Ihori, Naotaka Kawata, Shota Orihashi, Kazutoshi Shinoda, Taiga Yamane, Saki Mizuno, Keita Suzuki, Satoshi Suzuki, Nobukatsu Hojo, Takafumi Moriya, Atsushi Ando
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Contextual Biasing and Adaptation"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Contextual Biasing and Adaptation</h4>
                            <hr>
                            <a class="w3-text" href="shamsian24_interspeech.html">
                                <p>
                                    Keyword-Guided Adaptation of Automatic Speech Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Aviv Shamsian, Aviv Navon, Neta Glazer, Gill Hetz, Joseph Keshet
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="manhtienanh24_interspeech.html">
                                <p>
                                    Improving Speech Recognition with Prompt-based Contextualized ASR and LLM-based Re-predictor
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Nguyen Manh Tien Anh, Thach Ho Sy
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="wang24q_interspeech.html">
                                <p>
                                    Incorporating Class-based Language Model for Named Entity Recognition in Factorized Neural Transducer
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Peng Wang, Yifan Yang, Zheng Liang, Tian Tan, Shiliang Zhang, Xie Chen
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="yang24j_interspeech.html">
                                <p>
                                    Contextual Biasing with Confidence-based Homophone Detector for Mandarin End-to-End Speech Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Chengxu Yang, Lin Zheng, Sanli Tian, Gaofeng Cheng, Sujie Xiao, Ta Li
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="huang24f_interspeech.html">
                                <p>
                                    Improving Neural Biasing for Contextual Speech Recognition by Early Context Injection and Text Perturbation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Ruizhe Huang, Mahsa Yarmohammadi, Sanjeev Khudanpur, Daniel Povey
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="andrusenko24_interspeech.html">
                                <p>
                                    Fast Context-Biasing for CTC and Transducer ASR models with CTC-based Word Spotter
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Andrei Andrusenko, Aleksandr Laptev, Vladimir Bataev, Vitaly Lavrukhin, Boris Ginsburg
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="wei24_interspeech.html">
                                <p>
                                    Prompt Tuning for Speech Recognition on Unknown Spoken Name Entities
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Xizi Wei, Stephen McGregor
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="liu24e_interspeech.html">
                                <p>
                                    Improved Factorized Neural Transducer Model For Text-only Domain Adaptation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Junzhe Liu, Jianwei Yu, Xie Chen
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="liu24d_interspeech.html">
                                <p>
                                    Modality Translation Learning for Joint Speech-Text Model
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Pin-Yen Liu, Jen-Tzung Chien
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="zhao24d_interspeech.html">
                                <p>
                                    SAML: Speaker Adaptive Mixture of LoRA Experts for End-to-End ASR
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Qiuming Zhao, Guangzhi Sun, Chao Zhang, Mingxing Xu, Thomas Fang Zheng
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="ando24_interspeech.html">
                                <p>
                                    Factor-Conditioned Speaking-Style Captioning
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Atsushi Ando, Takafumi Moriya, Shota Horiguchi, Ryo Masumura
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="khassanov24_interspeech.html">
                                <p>
                                    Dual-Pipeline with Low-Rank Adaptation for New Language Integration in Multilingual ASR
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yerbolat Khassanov, Zhipeng Chen, Tianfeng Chen, Tze Yuang Chong, Wei Li, Jun Zhang, Lu Lu, Yuxuan Wang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="yusuf24_interspeech.html">
                                <p>
                                    Speculative Speech Recognition by Audio-Prefixed Low-Rank Adaptation of Language Models
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Bolaji Yusuf, Murali Karthick Baskar, Andrew Rosenberg, Bhuvana Ramabhadran
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kim24u_interspeech.html">
                                <p>
                                    Domain-Aware Data Selection for Speech Classification via Meta-Reweighting
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Junghun Kim, Ka Hyun Park, Hoyoung Yoon, U Kang
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Spoken Language Understanding"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Spoken Language Understanding</h4>
                            <hr>
                            <a class="w3-text" href="futami24_interspeech.html">
                                <p>
                                    Finding Task-specific Subnetworks in Multi-task Spoken Language Understanding Model
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Hayato Futami, Siddhant Arora, Yosuke Kashiwagi, Emiru Tsunoo, Shinji Watanabe
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="porjazovski24_interspeech.html">
                                <p>
                                    Out-of-distribution generalisation in spoken language understanding
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Dejan Porjazovski, Anssi Moisio, Mikko Kurimo
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="laperriere24_interspeech.html">
                                <p>
                                    A dual task learning approach to fine-tune a multilingual semantic speech encoder for Spoken Language Understanding
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        GaÃ«lle LaperriÃ¨re, Sahar Ghannay, Bassam Jabaian, Yannick EstÃ¨ve
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="lee24i_interspeech.html">
                                <p>
                                    Speech-MASSIVE: A Multilingual Speech Dataset for SLU and Beyond
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Beomseok Lee, Ioan Calapodescu, Marco Gaido, Matteo Negri, Laurent Besacier
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="li24b_interspeech.html">
                                <p>
                                    Using Large Language Model for End-to-End Chinese ASR and NER
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yuang Li, Jiawei Yu, Min Zhang, Mengxin Ren, Yanqing Zhao, Xiaofeng Zhao, Shimin Tao, Jinsong Su, Hao Yang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="koudounas24b_interspeech.html">
                                <p>
                                    A Contrastive Learning Approach to Mitigate Bias in Speech Models
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Alkis Koudounas, Flavio Giobergia, Eliana Pastor, Elena Baralis
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Spoken Machine Translation 1"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Spoken Machine Translation 1</h4>
                            <hr>
                            <a class="w3-text" href="huang24h_interspeech.html">
                                <p>
                                    Investigating Decoder-only Large Language Models for Speech-to-text Translation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Chao-Wei Huang, Hui Lu, Hongyu Gong, Hirofumi Inaguma, Ilia Kulikov, Ruslan Mavlyutov, Sravya Popuri
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="hirschkind24_interspeech.html">
                                <p>
                                    Diffusion Synthesizer for Efficient Multilingual Speech to Speech Translation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Nameer Hirschkind, Xiao Yu, Mahesh Kumar Nandwana, Joseph Liu, Eloi DuBois, Dao Le, Nicolas Thiebaut, Colin Sinclair, Kyle Spence, Charles Shang, Zoe Abrams, Morgan McGuire
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="chen24v_interspeech.html">
                                <p>
                                    Sign Value Constraint Decomposition for Efficient 1-Bit Quantization of Speech Translation Tasks
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Nan Chen, Yonghe Wang, Feilong Bao
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="lee24h_interspeech.html">
                                <p>
                                    Lightweight Audio Segmentation for Long-form Speech Translation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jaesong Lee, Soyoon Kim, Hanbyul Kim, Joon Son Chung
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="tan24b_interspeech.html">
                                <p>
                                    Contrastive Feedback Mechanism for Simultaneous Speech Translation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Haotian Tan, Sakriani Sakti
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="macaire24_interspeech.html">
                                <p>
                                    Towards Speech-to-Pictograms Translation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        CÃ©cile Macaire, ChloÃ© Dion, Didier Schwab, Benjamin Lecouteux, Emmanuelle EsperanÃ§a-Rodier
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Hearing Disorders"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Hearing Disorders</h4>
                            <hr>
                            <a class="w3-text" href="lee24e_interspeech.html">
                                <p>
                                    Automatic Assessment of Speech Production Skills for Children with Cochlear Implants Using Wav2Vec2.0 Acoustic Embeddings
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Seonwoo Lee, Sunhee Kim, Minhwa Chung
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="ahn24_interspeech.html">
                                <p>
                                    SyncVSR: Data-Efficient Visual Speech Recognition with End-to-End Crossmodal Audio Token Synchronization
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Young Jin Ahn, Jungwoo Park, Sangha Park, Jonghyun Choi, Kee-Eung Kim
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="huckvale24_interspeech.html">
                                <p>
                                    Evaluating a 3-factor listener model for prediction of speech intelligibility to hearing-impaired listeners
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Mark Huckvale, Gaston Hilkhuysen
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="fagniart24_interspeech.html">
                                <p>
                                    Production of fricative consonants in French-speaking children with cochlear implants and typical hearing: acoustic and phonological analyses.
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Sophie Fagniart, Brigitte Charlier, VÃ©ronique Delvaux, Bernard Harmegnies, Anne Huberlant, Myriam Piccaluga, Kathy Huet
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="irino24_interspeech.html">
                                <p>
                                    Signal processing algorithm effective for sound quality of hearing loss simulators 
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Toshio Irino, Shintaro Doan, Minami Ishikawa
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="niu24c_interspeech.html">
                                <p>
                                    Auditory Spatial Attention Detection Based on Feature Disentanglement and Brain Connectivity-Informed Graph Neural Networks
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yixiang Niu, Ning Chen, Hongqing Zhu, Zhiying Zhu, Guangqiang Li, Yibo Chen
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="monaghan24_interspeech.html">
                                <p>
                                    Automatic Detection of Hearing Loss from Children's Speech using wav2vec 2.0 Features
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jessica Monaghan, Arun Sebastian, Nicky Chong-White, Vicky Zhang, Vijayalakshmi Easwar, Padraig Kitterick
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Speech Disorders 2"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Speech Disorders 2</h4>
                            <hr>
                            <a class="w3-text" href="changawala24_interspeech.html">
                                <p>
                                    Whister: Using Whisperâs representations for Stuttering detection
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Vrushank Changawala, Frank Rudzicz
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="xiong24_interspeech.html">
                                <p>
                                    Improving Speech-Based Dysarthria Detection using Multi-task Learning with Gradient Projection
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yan Xiong, Visar Berisha, Julie Liss, Chaitali Chakrabarti
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="chen24i_interspeech.html">
                                <p>
                                    Cascaded Transfer Learning Strategy for Cross-Domain Alzheimer's  Disease Recognition through Spontaneous Speech
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Guanlin Chen, Yun Jin
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="ilias24_interspeech.html">
                                <p>
                                    A Cross-Attention Layer coupled with Multimodal Fusion Methods for Recognizing Depression from Spontaneous Speech
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Loukas Ilias, Dimitris Askounis
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="ng24_interspeech.html">
                                <p>
                                    Segmental and Suprasegmental Speech Foundation Models for Classifying Cognitive Risk Factors: Evaluating Out-of-the-Box Performance
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Si-Ioi Ng, Lingfeng Xu, Kimberly D. Mueller, Julie Liss, Visar Berisha
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="papadimitriou24_interspeech.html">
                                <p>
                                    Multimodal Continuous Fingerspelling Recognition via Visual Alignment Learning
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Katerina Papadimitriou, Gerasimos Potamianos
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="ariasvergara24_interspeech.html">
                                <p>
                                    Contrastive Learning Approach for Assessment of Phonological Precision in Patients with Tongue Cancer Using MRI Data
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Tomas Arias-Vergara, Paula Andrea PÃ©rez-Toro, Xiaofeng Liu, Fangxu Xing, Maureen Stone, Jiachen Zhuo, Jerry L. Prince, Maria Schuster, Elmar Noeth, Jonghye Woo, Andreas Maier
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="zhang24l_interspeech.html">
                                <p>
                                    DysArinVox: DYSphonia &amp; DYSarthria mandARIN speech corpus
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Haojie Zhang, Tao Zhang, Ganjun Liu, Dehui Fu, Xiaohui Hou, Ying Lv
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="zhou24e_interspeech.html">
                                <p>
                                    YOLO-Stutter: End-to-end Region-Wise Speech Dysfluency Detection
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Xuanru Zhou, Anshul Kashyap, Steve Li, Ayati Sharma, Brittany Morin, David Baquirin, Jet Vonk, Zoe Ezzes, Zachary Miller, Maria Tempini, Jiachen Lian, Gopala Anumanchipalli
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="gosztolya24c_interspeech.html">
                                <p>
                                    Automatic Longitudinal Investigation of Multiple Sclerosis Subjects
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        GÃ¡bor Gosztolya, Veronika Svindt, Judit BÃ³na, IldikÃ³ Hoffmann
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="TAUKADIAL Challenge: Speech-Based Cognitive Assessment in Chinese and English (Special Session)"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">TAUKADIAL Challenge: Speech-Based Cognitive Assessment in Chinese and English (Special Session)</h4>
                            <hr>
                            <a class="w3-text" href="luz24_interspeech.html">
                                <p>
                                    Connected Speech-Based Cognitive Assessment in Chinese and English
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Saturnino Luz, Sofia De La Fuente Garcia, Fasih Haider, Davida Fromm, Brian MacWhinney, Alyssa Lanzi, Ya-Ning Chang, Chia-Ju Chou, Yi-Chien Liu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="ortizperez24_interspeech.html">
                                <p>
                                    Cognitive Insights Across Languages: Enhancing Multimodal Interview Analysis
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        David Ortiz-Perez, Jose Garcia-Rodriguez, David TomÃ¡s
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="gosztolya24_interspeech.html">
                                <p>
                                    Combining Acoustic Feature Sets for Detecting Mild Cognitive Impairment in the Interspeech'24 TAUKADIAL Challenge
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        GÃ¡bor Gosztolya, LÃ¡szlÃ³ TÃ³th
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="duan24_interspeech.html">
                                <p>
                                    Pre-trained Feature Fusion and Matching for Mild Cognitive Impairment Detection
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Junwen Duan, Fangyuan Wei, Hong-Dong Li, Jin Liu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="barreraaltuna24_interspeech.html">
                                <p>
                                    The Interspeech 2024 TAUKADIAL Challenge: Multilingual Mild Cognitive Impairment Detection with Multimodal Approach
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Benjamin Barrera-Altuna, Daeun Lee, Zaima Zarnaz, Jinyoung Han, Seungbae Kim
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="favaro24_interspeech.html">
                                <p>
                                    Leveraging Universal Speech Representations for Detecting and Assessing the Severity of Mild Cognitive Impairment Across Languages
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Anna Favaro, Tianyu Cao, Najim Dehak, Laureano Moro-Velazquez
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="hoang24_interspeech.html">
                                <p>
                                    Translingual Language Markers for Cognitive Assessment from Spontaneous Speech
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Bao Hoang, Yijiang Pang, Hiroko Dodge, Jiayu Zhou
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="pereztoro24_interspeech.html">
                                <p>
                                    Multilingual Speech and Language Analysis for the Assessment of Mild Cognitive Impairment: Outcomes from the Taukadial Challenge
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Paula Andrea PÃ©rez-Toro, Tomas Arias-Vergara, Philipp Klumpp, Tobias Weise, Maria Schuster, Elmar Noeth, Juan Rafael Orozco-Arroyave, Andreas Maier
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Show and Tell 1"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Show and Tell 1</h4>
                            <hr>
                            <a class="w3-text" href="arai24_interspeech.html">
                                <p>
                                    Production of phrases by mechanical models of the human vocal tract
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Takayuki Arai, Ryohei Suzuki, Chandler Earp, Shinya Tsuji, Keiko Ochi
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="gourav24_interspeech.html">
                                <p>
                                    Faster Vocoder: a multi threading approach to achieve low latency during TTS Inference
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Vishal Gourav, Ankit Tyagi, Phanindra Mankale
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="mohan24_interspeech.html">
                                <p>
                                    A powerful and modern AAC composition tool for impaired speakers
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Aanchan Mohan, Monideep Chakraborti, Katelyn Eng, Nailia Kushaeva, Mirjana Prpa, Jordan Lewis, Tianyi Zhang, Vince Geisler, Carol Geisler
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="mika24_interspeech.html">
                                <p>
                                    VoxFlow AI: wearable voice converter for atypical speech
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Grzegorz P. Mika, Konrad ZieliÂ´nski, PaweÅ Cyrta, Marek Grzelec
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="akarsh24_interspeech.html">
                                <p>
                                    Stress transfer in speech-to-speech machine translation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Sai Akarsh, Vamshiraghusimha Narasinga, Anil Kumar Vuppala
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="okamoto24b_interspeech.html">
                                <p>
                                    Mobile PresenTra: NICT fast neural text-to-speech system on smartphones with incremental inference of MS-FC-HiFi-GAN for law-latency synthesis
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Takuma Okamoto, Yamato Ohtani, Hisashi Kawai
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="peirolilja24_interspeech.html">
                                <p>
                                    Multi-speaker and multi-dialectal Catalan TTS models for video gaming
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Alex PeirÃ³-Lilja, JosÃ© Giraldo, MartÃ­ Llopart-Font, Carme Armentano-Oller, Baybars KÃ¼lebi, Mireia FarrÃºs
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="francis24_interspeech.html">
                                <p>
                                    ConnecTone: a modular AAC system prototype with contextual generative text prediction and style-adaptive conversational TTS
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Juliana Francis, Ãva SzÃ©kely, Joakim Gustafson
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="rohmatillah24_interspeech.html">
                                <p>
                                    Reliable dialogue system for facilitating student-counselor communication
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Mahdin Rohmatillah, Bryan Gautama Ngo, Willianto Sulaiman, Po-Chuan Chen, Jen-Tzung Chien
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="lameris24_interspeech.html">
                                <p>
                                    CreakVC: a voice conversion tool for modulating creaky voice
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Harm Lameris, Joakim Gustafson, Ãva SzÃ©kely
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="tsao24_interspeech.html">
                                <p>
                                    EZTalking: English assessment platform for teachers and students
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yu-Sheng Tsao, Yung-Chang Hsu, Jiun-Ting Li, Siang-Hong Weng, Tien-Hong Lo, Berlin Chen
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Keynote 2"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Keynote 2</h4>
                            <hr>
                            <a class="w3-text" href="araki24_interspeech.html">
                                <p>
                                    Frontier of Frontend for Conversational Speech Processing
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Shoko Araki
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Phonetics and Phonology of Second Language Acquisition"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Phonetics and Phonology of Second Language Acquisition</h4>
                            <hr>
                            <a class="w3-text" href="tuttosi24_interspeech.html">
                                <p>
                                    Mmm whatcha say? Uncovering distal and proximal context effects in first and second-language word perception using psychophysical reverse correlation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Paige TuttÃ¶sÃ­, H. Henny Yeung, Yue Wang, Fenqi Wang, Guillaume Denis, Jean-Julien Aucouturier, Angelica Lim
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="popescu24_interspeech.html">
                                <p>
                                    Automatic Speech Recognition with parallel L1 and L2 acoustic phone models to evaluate /l/ allophony in L2 English speech production
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Anisia Popescu, Lori Lamel, Ioana Vasilescu, Laurence Devillers
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="huang24i_interspeech.html">
                                <p>
                                    Analysis of articulatory setting for L1 and L2 English speakers using MRI data
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Kevin Huang, Jack Goldberg, Louis Goldstein, Shrikanth Narayanan
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="colgiu24_interspeech.html">
                                <p>
                                    Bilingual Rhotic Production Patterns: A Generational Comparison of Spanish-English Bilingual Speakers in Canada
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Ioana Colgiu, Laura Spinu, Rajiv Rao, Yasaman Rafat
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="coulange24_interspeech.html">
                                <p>
                                    Exploring Impact of Pausing and Lexical Stress Patterns on L2 English Comprehensibility in Real Time
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Sylvain Coulange, Tsuneo Kato, Solange Rossato, Monica Masperi
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="wu24m_interspeech.html">
                                <p>
                                    Mandarin T3 Production by Chinese and Japanese Native Speakers
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Qi Wu
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Corpora-based Approaches in Automatic Emotion Recognition"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Corpora-based Approaches in Automatic Emotion Recognition</h4>
                            <hr>
                            <a class="w3-text" href="ranjan24_interspeech.html">
                                <p>
                                    Reinforcement Learning based Data Augmentation for Noise Robust Speech Emotion Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Sumit Ranjan, Rupayan Chakraborty, Sunil Kumar Kopparapu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="mote24_interspeech.html">
                                <p>
                                    Unsupervised Domain Adaptation for Speech Emotion Recognition using K-Nearest Neighbors Voice Conversion
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Pravin Mote, Berrak Sisman, Carlos Busso
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="wang24ja_interspeech.html">
                                <p>
                                    Confidence-aware Hypothesis Transfer Networks for Source-Free Cross-Corpus Speech Emotion Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jincen Wang, Yan Zhao, Cheng Lu, Hailun Lian, Hongli Chang, Yuan Zong, Wenming Zheng
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="xi24_interspeech.html">
                                <p>
                                    An Effective Local Prototypical Mapping Network for Speech Emotion Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yuxuan Xi, Yan Song, Lirong Dai, Haoyu Song, Ian McLoughlin
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="gao24f_interspeech.html">
                                <p>
                                    Speech Emotion Recognition with Multi-level Acoustic and Semantic Information Extraction and Interaction
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yuan Gao, Hao Shi, Chenhui Chu, Tatsuya Kawahara
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Analysis of Speakers States and Traits"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Analysis of Speakers States and Traits</h4>
                            <hr>
                            <a class="w3-text" href="niebuhr24_interspeech.html">
                                <p>
                                    How rhythm metrics are linked to produced and perceived speaker charisma
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Oliver Niebuhr, Nafiseh Taghva
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="li24ma_interspeech.html">
                                <p>
                                    A Functional Trade-off between Prosodic and Semantic Cues in Conveying Sarcasm
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Zhu Li, Xiyuan Gao, Yuqing Zhang, Shekhar Nayak, Matt Coler
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="murzaku24_interspeech.html">
                                <p>
                                    Multimodal Belief Prediction
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        John Murzaku, Adil Soubki, Owen Rambow
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="chen24f_interspeech.html">
                                <p>
                                    Detecting Empathy in Speech
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Run Chen, Haozhe Chen, Anushka Kulkarni, Eleanor Lin, Linda Pang, Divya Tadimeti, Jun Shin, Julia Hirschberg
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="tao24b_interspeech.html">
                                <p>
                                    Learning Representation of Therapist Empathy in Counseling Conversation Using Siamese Hierarchical Attention Network
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Dehua Tao, Tan Lee, Harold Chui, Sarah Luk
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kunmei24_interspeech.html">
                                <p>
                                    Modelling Lexical Characteristics of the Healthy Aging Population: A Corpus-Based Study
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Han Kunmei
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="gerczuk24_interspeech.html">
                                <p>
                                    Exploring Gender-Specific Speech Patterns in Automatic Suicide Risk Assessment
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Maurice Gerczuk, Shahin Amiriparian, Justina Lutz, Wolfgang Strube, Irina Papazova, Alkomiet Hasan, BjÃ¶rn W. Schuller
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Spoofing and Deepfake Detection"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Spoofing and Deepfake Detection</h4>
                            <hr>
                            <a class="w3-text" href="klein24_interspeech.html">
                                <p>
                                    Source Tracing of Audio Deepfake Systems
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Nicholas Klein, Tianxiang Chen, Hemlata Tak, Ricardo Casal, Elie Khoury
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="liu24m_interspeech.html">
                                <p>
                                    How Do Neural Spoofing Countermeasures Detect Partially Spoofed Audio?
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Tianchi Liu, Lin Zhang, Rohan Kumar Das, Yi Ma, Ruijie Tao, Haizhou Li
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="wang24l_interspeech.html">
                                <p>
                                    Revisiting and Improving Scoring Fusion for Spoofing-aware Speaker Verification Using Compositional Data Analysis
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Xin Wang, Tomi Kinnunen, Kong Aik Lee, Paul-Gauthier NoÃ©, Junichi Yamagishi
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="baser24_interspeech.html">
                                <p>
                                    SecureSpectra: Safeguarding Digital Identity from Deep Fake Threats via Intelligent Signatures
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Oguzhan Baser, Kaan Kale, Sandeep P. Chinchali
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="li24oa_interspeech.html">
                                <p>
                                    Interpretable Temporal Class Activation Representation for Audio Spoofing  Detection
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Menglu Li, Xiao-Ping Zhang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="ge24_interspeech.html">
                                <p>
                                    DGPN: A Dual Graph Prototypical Network for Few-Shot Speech Spoofing Algorithm Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Zirui Ge, Xinzhou Xu, Haiyan Guo, Tingting Wang, Zhen Yang, BjÃ¶rn W. Schuller
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Audio Captioning, Tagging, and Audio-Text Retrieval"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Audio Captioning, Tagging, and Audio-Text Retrieval</h4>
                            <hr>
                            <a class="w3-text" href="sun24c_interspeech.html">
                                <p>
                                    PFCA-Net: Pyramid Feature Fusion and Cross Content Attention Network for Automated Audio Captioning
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jianyuan Sun, Wenwu Wang, Mark D. Plumbley
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="liu24_interspeech.html">
                                <p>
                                    Enhancing Automated Audio Captioning via Large Language Models with Optimized Audio Encoding
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jizhong Liu, Gang Li, Junbo Zhang, Heinrich Dinkel, Yongqing Wang, Zhiyong Yan, Yujun Wang, Bin Wang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="xin24b_interspeech.html">
                                <p>
                                    Audio-text Retrieval with Transformer-based Hierarchical Alignment and Disentangled Cross-modal Representation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yifei Xin, Zhihong Zhu, Xuxin Cheng, Xusheng Yang, Yuexian Zou
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="dinkel24_interspeech.html">
                                <p>
                                    Streaming Audio Transformers for Online Audio Tagging
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Heinrich Dinkel, Zhiyong Yan, Yongqing Wang, Junbo Zhang, Yujun Wang, Bin Wang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="chaudhary24_interspeech.html">
                                <p>
                                    Efficient CNNs with Quaternion Transformations and Pruning for Audio Tagging
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Aryan Chaudhary, Arshdeep Singh, Vinayak Abrol, Mark D. Plumbley
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="jing24b_interspeech.html">
                                <p>
                                    ParaCLAP â Towards a general language-audio model for computational paralinguistic tasks
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Xin Jing, Andreas Triantafyllopoulos, BjÃ¶rn Schuller
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="xu24e_interspeech.html">
                                <p>
                                    Efficient Audio Captioning with Encoder-Level Knowledge Distillation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Xuenan Xu, Haohe Liu, Mengyue Wu, Wenwu Wang, Mark D. Plumbley
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Generative Speech Enhancement"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Generative Speech Enhancement</h4>
                            <hr>
                            <a class="w3-text" href="scheibler24_interspeech.html">
                                <p>
                                    Universal Score-based Speech Enhancement with High Content Preservation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Robin Scheibler, Yusuke Fujita, Yuma Shirahata, Tatsuya Komatsu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="yang24h_interspeech.html">
                                <p>
                                    Genhancer: High-Fidelity Speech Enhancement via Generative Modeling on Discrete Codec Tokens
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Haici Yang, Jiaqi Su, Minje Kim, Zeyu Jin
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="jukic24_interspeech.html">
                                <p>
                                    SchrÃ¶dinger Bridge for Generative Speech Enhancement
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Ante JukiÄ, Roman Korostik, Jagadeesh Balam, Boris Ginsburg
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="trachu24_interspeech.html">
                                <p>
                                    Thunder : Unified Regression-Diffusion Speech Enhancement with a Single Reverse Step using Brownian Bridge
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Thanapat Trachu, Chawan Piansaddhayanon, Ekapol Chuangsuwanich
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="yang24k_interspeech.html">
                                <p>
                                    Pre-training Feature Guided Diffusion Model for Speech Enhancement
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yiyuan Yang, Niki Trigoni, Andrew Markham
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kim24o_interspeech.html">
                                <p>
                                    Guided conditioning with predictive network on score-based diffusion model for speech enhancement
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Dail Kim, Da-Hee Yang, Donghyun Kim, Joon-Hyuk Chang, Jeonghwan Choi, Moa Lee, Jaemo Yang, Han-gil Moon
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Speech Synthesis: Evaluation"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Speech Synthesis: Evaluation</h4>
                            <hr>
                            <a class="w3-text" href="yin24b_interspeech.html">
                                <p>
                                    SVSNet+: Enhancing Speaker Voice Similarity Assessment Models with Representations from Speech Foundation Models
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Chun Yin, Tai-Shih Chi, Yu Tsao, Hsin-Min Wang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="anand24_interspeech.html">
                                <p>
                                    Enhancing Out-of-Vocabulary Performance of Indian TTS Systems for Practical Applications through Low-Effort Data Strategies
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Srija Anand, Praveen Srinivasa Varadhan, Ashwin Sankar, Giri Raju, Mitesh M. Khapra
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="edlund24_interspeech.html">
                                <p>
                                    Assessing the impact of contextual framing on subjective TTS quality
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jens Edlund, Christina TÃ¥nnander, SÃ©bastien Le Maguer, Petra Wagner
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="adigwe24_interspeech.html">
                                <p>
                                    What do people hear? Listenersâ Perception of Conversational Speech
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Adaeze Adigwe, Sarenne Wallbridge, Simon King
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="wang24s_interspeech.html">
                                <p>
                                    Uncertainty-Aware Mean Opinion Score Prediction
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Hui Wang, Shiwan Zhao, Jiaming Zhou, Xiguang Zheng, Haoqin Sun, Xuechen Wang, Yong Qin
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="saget24_interspeech.html">
                                <p>
                                    Lifelong Learning MOS Prediction for Synthetic Speech Quality Evaluation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        FÃ©lix Saget, Meysam Shamsi, Marie Tahon
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Multilingual ASR"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Multilingual ASR</h4>
                            <hr>
                            <a class="w3-text" href="kwok24_interspeech.html">
                                <p>
                                    Continual Learning Optimizations for Auto-regressive Decoder of Multilingual ASR systems
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Chin Yuen Kwok, Jia Qi Yip, Eng Siong Chng
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="shi24g_interspeech.html">
                                <p>
                                    ML-SUPERB 2.0: Benchmarking Multilingual Speech Models Across Modeling Constraints, Languages, and Datasets
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jiatong Shi, Shih-Heng Wang, William Chen, Martijn Bartelds, Vanya Bannihatti Kumar, Jinchuan Tian, Xuankai Chang, Dan Jurafsky, Karen Livescu, Hung-yi Lee, Shinji Watanabe
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="pineiromartin24_interspeech.html">
                                <p>
                                    Weighted Cross-entropy for Low-Resource Languages in Multilingual Speech Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        AndrÃ©s PiÃ±eiro-MartÃ­n, Carmen GarcÃ­a-Mateo, Laura Docio-Fernandez, MarÃ­a del Carmen LÃ³pez-PÃ©rez, Georg Rehm
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="saif24_interspeech.html">
                                <p>
                                    M2ASR: Multilingual Multi-task Automatic Speech Recognition via Multi-objective Optimization
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        A F M Saif, Lisha Chen, Xiaodong Cui, Songtao Lu, Brian Kingsbury, Tianyi Chen
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="li24s_interspeech.html">
                                <p>
                                    MSR-86K: An Evolving, Multilingual Corpus with 86,300 Hours of Transcribed Audio for Speech Recognition Research
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Song Li, Yongbin You, Xuezhi Wang, Zhengkun Tian, Ke Ding, Guanglu Wan
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="houston24_interspeech.html">
                                <p>
                                    Improving Multilingual ASR Robustness to Errors in Language Input
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Brady Houston, Omid Sadjadi, Zejiang Hou, Srikanth Vishnubhotla, Kyu J. Han
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="General Topics in ASR"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">General Topics in ASR</h4>
                            <hr>
                            <a class="w3-text" href="suh24_interspeech.html">
                                <p>
                                    Improving Domain-Specific ASR with LLM-Generated Contextual Descriptions
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jiwon Suh, Injae Na, Woohwan Jung
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="li24c_interspeech.html">
                                <p>
                                    A Multitask Training Approach to Enhance Whisper with Open-Vocabulary Keyword Spotting
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yuang Li, Min Zhang, Chang Su, Yinglu Li, Xiaosong Qiao, Mengxin Ren, Miaomiao Ma, Daimeng Wei, Shimin Tao, Hao Yang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="zusag24_interspeech.html">
                                <p>
                                    CrisperWhisper: Accurate Timestamps on Verbatim Speech Transcriptions
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Mario Zusag, Laurin Wagner, Bernhad Thallinger
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="mihajlik24_interspeech.html">
                                <p>
                                    On Disfluency and Non-lexical Sound Labeling for End-to-end Automatic Speech Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Peter Mihajlik, Yan Meng, Mate S Kadar, Julian Linke, Barbara Schuppler, Katalin MÃ¡dy
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="mujtaba24_interspeech.html">
                                <p>
                                    Inclusive ASR for Disfluent Speech: Cascaded Large-Scale Self-Supervised Learning with Targeted Fine-Tuning and Data Augmentation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Dena Mujtaba, Nihar R. Mahapatra, Megan Arney, J. Scott Yaruss, Caryn Herring, Jia Bin
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="tan24_interspeech.html">
                                <p>
                                    DualPure: An Efficient Adversarial Purification Method for Speech Command Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Hao Tan, Xiaochen Liu, Huan Zhang, Junjian Zhang, Yaguan Qian, Zhaoquan Gu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="lehecka24_interspeech.html">
                                <p>
                                    A Comparative Analysis of Bilingual and Trilingual Wav2Vec Models for Automatic Speech Recognition in Multilingual Oral History Archives
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jan LeheÄka, Josef V. Psutka, Lubos Smidl, Pavel Ircing, Josef Psutka
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="delafuente24_interspeech.html">
                                <p>
                                    A layer-wise analysis of Mandarin and English suprasegmentals in SSL speech models
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Anton de la Fuente, Dan Jurafsky
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="leivaditi24_interspeech.html">
                                <p>
                                    Fine-Tuning Strategies for Dutch Dysarthric Speech Recognition: Evaluating the Impact of Healthy, Disease-Specific, and Speaker-Specific Data
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Spyretta Leivaditi, Tatsunari Matsushima, Matt Coler, Shekhar Nayak, Vass Verkhodanova
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="hsieh24_interspeech.html">
                                <p>
                                    Dysarthric Speech Recognition Using Curriculum Learning and Articulatory Feature Embedding
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        I-Ting Hsieh, Chung-Hsien Wu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="wang24x_interspeech.html">
                                <p>
                                    Enhancing Dysarthric Speech Recognition for Unseen Speakers via Prototype-Based Adaptation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Shiyao Wang, Shiwan Zhao, Jiaming Zhou, Aobo Kong, Yong Qin
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="zheng24_interspeech.html">
                                <p>
                                    An efficient text augmentation approach for contextualized Mandarin speech recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Naijun Zheng, Xucheng Wan, Kai Liu, Ziqing Du, Zhou Huan
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="li24h_interspeech.html">
                                <p>
                                    Investigating ASR Error Correction with Large Language Model and Multilingual 1-best Hypotheses
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Sheng Li, Chen Chen, Chin Yuen Kwok, Chenhui Chu, Eng Siong Chng, Hisashi Kawai
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="wang24n_interspeech.html">
                                <p>
                                    Efficiently Train ASR Models that Memorize Less and Perform Better with Per-core Clipping
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Lun Wang, Om Thakkar, Zhong Meng, Nicole Rafidi, Rohit Prabhavalkar, Arun Narayanan
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Spoken Language Understanding"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Spoken Language Understanding</h4>
                            <hr>
                            <a class="w3-text" href="phung24_interspeech.html">
                                <p>
                                    AR-NLU: A Framework for Enhancing Natural Language Understanding Model Robustness against ASR Errors
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Emmy Phung, Harsh Deshpande, Ahmad Emami, Kanishk Singh
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="li24_interspeech.html">
                                <p>
                                    Prompting Whisper for QA-driven Zero-shot End-to-end Spoken Language Understanding
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Mohan Li, Simon Keizer, Rama Doddipatla
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="tran24b_interspeech.html">
                                <p>
                                    VN-SLU: A Vietnamese Spoken Language Understanding Dataset
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Tuyen Tran, Khanh Le, Ngoc Dang Nguyen, Minh Vu, Huyen Ngo, Woomyoung Park, Thi Thu Trang Nguyen
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kando24_interspeech.html">
                                <p>
                                    Textless Dependency Parsing by Labeled Sequence Prediction
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Shunsuke Kando, Yusuke Miyao, Jason Naradowsky, Shinnosuke Takamichi
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="yue24_interspeech.html">
                                <p>
                                    Towards Speech Classification from Acoustic and Vocal Tract data in Real-time MRI
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yaoyao Yue, Michael Proctor, Luping Zhou, Rijul Gupta, Tharinda Piyadasa, Amelia Gully, Kirrie Ballard, Craig Jin
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="johnson24_interspeech.html">
                                <p>
                                    Efficient SQA from Long Audio Contexts: A Policy-driven Approach
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Alexander Johnson, Peter Plantinga, Pheobe Sun, Swaroop Gadiyaram, Abenezer Girma, Ahmad Emami
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Speech and Multimodal Resources"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Speech and Multimodal Resources</h4>
                            <hr>
                            <a class="w3-text" href="pesan24_interspeech.html">
                                <p>
                                    BESST Dataset: A Multimodal Resource for Speech-based Stress Detection and Analysis
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jan PeÅ¡Ã¡n, VojtÄch JuÅÃ­k, Martin KarafiÃ¡t, Jan ÄernockÃ½
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="turetzky24_interspeech.html">
                                <p>
                                    HebDB: a Weakly Supervised Dataset for Hebrew Speech Processing
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Arnon Turetzky, Or Tal, Yael Segal, Yehoshua Dissen, Ella Zeldes, Amit Roth, Eyal Cohen, Yosi Shrem, Bronya R. Chernyak, Olga Seleznova, Joseph Keshet, Yossi Adi
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="wang24b_interspeech.html">
                                <p>
                                    GLOBE: A High-quality English Corpus with Global Accents for Zero-shot Speaker Adaptive Text-to-Speech
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Wenbin Wang, Yang Song, Sanjay Jha
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kong24_interspeech.html">
                                <p>
                                    STraDa: A Singer Traits Dataset
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yuexuan Kong, Viet-Anh Tran, Romain Hennequin
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="anderer24_interspeech.html">
                                <p>
                                    MaViLS, a Benchmark Dataset for Video-to-Slide Alignment, Assessing Baseline Accuracy with a Multimodal Alignment Algorithm Leveraging Speech, OCR, and Visual Features
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Katharina Anderer, Andreas Reich, Matthias WÃ¶lfel
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="sungbin24_interspeech.html">
                                <p>
                                    MultiTalk: Enhancing 3D Talking Head Generation Across Languages with Multilingual Video Dataset
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Kim Sung-Bin, Lee Chae-Yeon, Gihun Son, Oh Hyun-Bin, Janghoon Ju, Suekyeong Nam, Tae-Hyun Oh
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="veliche24_interspeech.html">
                                <p>
                                    Towards measuring fairness in speech recognition: Fair-Speech dataset
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Irina-Elena Veliche, Zhuangqun Huang, Vineeth Ayyat Kochaniyan, Fuchun Peng, Ozlem Kalinli, Michael L. Seltzer
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="lu24f_interspeech.html">
                                <p>
                                    Codecfake: An Initial Dataset for Detecting LLM-based Deepfake Audio
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yi Lu, Yuankun Xie, Ruibo Fu, Zhengqi Wen, Jianhua Tao, Zhiyong Wang, Xin Qi, Xuefei Liu, Yongwei Li, Yukun Liu, Xiaopeng Wang, Shuchen Shi
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="osman24_interspeech.html">
                                <p>
                                    SER Evals: In-domain and Out-of-domain benchmarking for speech emotion recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Mohamed Osman, Daniel Z. Kaplan, Tamer Nadeem
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Pathological Speech Analysis 1"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Pathological Speech Analysis 1</h4>
                            <hr>
                            <a class="w3-text" href="gudmundsson24_interspeech.html">
                                <p>
                                    The MARRYS helmet: A new device for researching and training âjaw dancingâ
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Vidar Freyr Gudmundsson, Keve MÃ¡rton GÃ¶nczi, Malin Svensson Lundmark, Donna Erickson, Oliver Niebuhr
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="laquatra24_interspeech.html">
                                <p>
                                    Exploiting Foundation Models and Speech Enhancement for Parkinson's Disease Detection from Speech in Real-World Operative Conditions
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Moreno La Quatra, Maria Francesca Turco, TorbjÃ¸rn Svendsen, Giampiero Salvi, Juan Rafael Orozco-Arroyave, Sabato Marco Siniscalchi
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="triantafyllopoulos24_interspeech.html">
                                <p>
                                    Sustained Vowels for Pre- vs Post-Treatment COPD Classification
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Andreas Triantafyllopoulos, Anton Batliner, Wolfgang Mayr, Markus Fendler, Florian Pokorny, Maurice Gerczuk, Shahin Amiriparian, Thomas Berghaus, BjÃ¶rn Schuller
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="amiri24_interspeech.html">
                                <p>
                                    Adversarial Robustness Analysis in Automatic Pathological Speech Detection Approaches
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Mahdi Amiri, Ina Kodrasi
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kim24q_interspeech.html">
                                <p>
                                    Automatic Children Speech Sound Disorder Detection with Age and Speaker Bias Mitigation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Gahye Kim, Yunjung Eom, Selina S. Sung, Seunghee Ha, Tae-Jin Yoon, Jungmin So
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Speech and Language in Health: from Remote Monitoring to Medical Conversations - 1 (Special Session)"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Speech and Language in Health: from Remote Monitoring to Medical Conversations - 1 (Special Session)</h4>
                            <hr>
                            <a class="w3-text" href="kadkhodaieelyaderani24_interspeech.html">
                                <p>
                                    Reference-Free Estimation of the Quality of Clinical Notes Generated from Doctor-Patient Conversations
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Mojtaba Kadkhodaie Elyaderani, John Glover, Thomas Schaaf
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="mun24_interspeech.html">
                                <p>
                                    Developing an End-to-End Framework for Predicting the Social Communication Severity Scores of Children with Autism Spectrum Disorder
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jihyun Mun, Sunhee Kim, Minhwa Chung
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="despotovic24_interspeech.html">
                                <p>
                                    Multimodal Fusion for Vocal Biomarkers Using Vector Cross-Attention
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Vladimir Despotovic, Abir ElbÃ©ji, Petr V. Nazarov, Guy Fagherazzi
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="goria24_interspeech.html">
                                <p>
                                    Revealing Confounding Biases: A Novel Benchmarking Approach for Aggregate-Level Performance Metrics in Health Assessments
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Stefano Goria, Roseline Polle, Salvatore Fara, Nicholas Cummins
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="rameau24_interspeech.html">
                                <p>
                                    Developing Multi-Disorder Voice Protocols: A team science approach involving clinical expertise, bioethics, standards, and DEI.
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        AnaÃ¯s Rameau, Satrajit Ghosh, Alexandros Sigaras, Olivier Elemento, Jean-Christophe Belisle-Pipon, Vardit Ravitsky, Maria Powell, Alistair Johnson, David Dorr, Philip Payne, Micah Boyer, Stephanie Watts, Ruth Bahr, Frank Rudzicz, Jordan Lerner-Ellis, Shaheen Awan, Don Bolser, Yael Bensoussan
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="dumpala24b_interspeech.html">
                                <p>
                                    Self-Supervised Embeddings for Detecting Individual Symptoms of Depression
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Sri Harsha Dumpala, Katerina Dikaios, Abraham Nunes, Frank Rudzicz, Rudolf Uher, Sageev Oore
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="mehta24_interspeech.html">
                                <p>
                                    Comparing ambulatory voice measures during daily life with brief laboratory assessments in speakers with and without vocal hyperfunction
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Daryush D. Mehta, Jarrad H. Van Stan, Hamzeh Ghasemzadeh, Robert E. Hillman
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="williams24_interspeech.html">
                                <p>
                                    Predicting Acute Pain Levels Implicitly from Vocal Features
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jennifer Williams, Eike Schneiders, Henry Card, Tina Seabrooke, Beatrice Pakenham-Walsh, Tayyaba Azim, Lucy Valls-Reed, Ganesh Vigneswaran, John Robert Bautista, Rohan Chandra, Arya Farahi
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="demir24_interspeech.html">
                                <p>
                                    Towards Intelligent Speech Assistants in Operating Rooms: A Multimodal Model for Surgical Workflow Analysis
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Kubilay Can Demir, BelÃ©n Lojo RodrÃ­guez, Tobias Weise, Andreas Maier, Seung Hee Yang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="premananth24_interspeech.html">
                                <p>
                                    A Multimodal Framework for the Assessment of the Schizophrenia Spectrum
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Gowtham Premananth, Yashish M. Siriwardena, Philip Resnik, Sonia Bansal, Deanna L.Kelly, Carol Espy-Wilson
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Speech and Brain"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Speech and Brain</h4>
                            <hr>
                            <a class="w3-text" href="wang24ka_interspeech.html">
                                <p>
                                    Exploring the Complementary Nature of Speech and Eye Movements for Profiling Neurological Disorders
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yuzhe Wang, Anna Favaro, Thomas Thebaud, Jesus Villalba, Najim Dehak, Laureano Moro-Velazquez
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="li24l_interspeech.html">
                                <p>
                                    Refining Self-supervised Learnt Speech Representation using Brain Activations
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        HengYu Li, Kangdi Mei, Zhaoci Liu, Yang Ai, Liping Chen, Jie Zhang, Zhenhua Ling
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="wang24ba_interspeech.html">
                                <p>
                                    Large Language Model-based FMRI Encoding of Language Functions for Subjects with Neurocognitive Disorder
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yuejiao Wang, Xianmin Gong, Lingwei Meng, Xixin Wu, Helen Meng
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="neelabh24_interspeech.html">
                                <p>
                                    From Sound to Meaning in the Auditory Cortex: A Neuronal Representation and Classification Analysis
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Kumar Neelabh, Vishnu Sreekumar
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="feng24_interspeech.html">
                                <p>
                                    Towards an End-to-End Framework for Invasive Brain Signal Decoding with Large Language Models
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Sheng Feng, Heyang Liu, Yu Wang, Yanfeng Wang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="lee24c_interspeech.html">
                                <p>
                                    Toward Fully-End-to-End Listened Speech Decoding from EEG Signals
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jihwan Lee, Aditya Kommineni, Tiantian Feng, Kleanthis Avramidis, Xuan Shi, Sudarsana Reddy Kadiri, Shrikanth Narayanan
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Innovative Methods in Phonetics and Phonology"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Innovative Methods in Phonetics and Phonology</h4>
                            <hr>
                            <a class="w3-text" href="ahn24d_interspeech.html">
                                <p>
                                    The Use of Phone Categories and Cross-Language Modeling for Phone Alignment of PanÃ£ra
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Emily P. Ahn, Eleanor Chodroff, Myriam Lapierre, Gina-Anne Levow
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="raybarman24_interspeech.html">
                                <p>
                                    Deciphering Assamese Vowel Harmony with Featural InfoWaveGAN
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Sneha Ray Barman, Shakuntala Mahanta, Neeraj Kumar Sharma
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="tadavarthy24_interspeech.html">
                                <p>
                                    Phonological Feature Detection for US English using the Phonet Library
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Harsha Veena Tadavarthy, Austin Jones, Margaret E. L. Renwick
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kaland24_interspeech.html">
                                <p>
                                    K-means and hierarchical clustering of f0 contours
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Constantijn Kaland, Jeremy Steffman, Jennifer Cole
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="rousso24_interspeech.html">
                                <p>
                                    Tradition or Innovation: A Comparison of Modern ASR Methods for Forced Alignment
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Rotem Rousso, Eyal Cohen, Joseph Keshet, Eleanor Chodroff
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kim24l_interspeech.html">
                                <p>
                                    Using wav2vec 2.0 for phonetic classification tasks: methodological aspects
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Lila Kim, CÃ©dric Gendrot
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="lambropoulos24_interspeech.html">
                                <p>
                                    The sub-band cepstrum as a tool for locating local spectral regions of phonetic sensitivity: A first attempt with multi-speaker vowel data
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Michael Lambropoulos, Frantz Clermont, Shunichi Ishihara
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="chung24_interspeech.html">
                                <p>
                                    Speaker-Independent Acoustic-to-Articulatory Inversion through Multi-Channel Attention Discriminator
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Woo-Jin Chung, Hong-Goo Kang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="weise24_interspeech.html">
                                <p>
                                    Speaker- and Text-Independent Estimation of Articulatory Movements and Phoneme Alignments from Speech
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Tobias Weise, Philipp Klumpp, Kubilay Can Demir, Paula Andrea PÃ©rez-Toro, Maria Schuster, Elmar Noeth, Bjoern Heismann, Andreas Maier, Seung Hee Yang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="oura24_interspeech.html">
                                <p>
                                    Preprocessing for acoustic-to-articulatory inversion using real-time MRI movies of Japanese speech
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Anna Oura, Hideaki Kikuchi, Tetsunori Kobayashi
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Voice, Tones and F0"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Voice, Tones and F0</h4>
                            <hr>
                            <a class="w3-text" href="li24f_interspeech.html">
                                <p>
                                    Impact of the tonal factor on diphthong realizations in Standard Mandarin with Generalized Additive Mixed Models
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Chenyu Li, Jalal Al-Tamimi
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="xiaowang24_interspeech.html">
                                <p>
                                    A Study on the Information Mechanism of the 3rd Tone Sandhi Rule in Mandarin Disyllabic Words
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Liu Xiaowang, Jinsong Zhang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="weirich24_interspeech.html">
                                <p>
                                    Gender and age based f0-variation in the German Plapper Corpus
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Melanie Weirich, Daniel Duran, Stefanie Jannedy
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="xu24j_interspeech.html">
                                <p>
                                    Voice quality in telephone speech: Comparing acoustic measures between VoIP telephone and high-quality recordings
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Chenzi Xu, Jessica Wormald, Paul Foulkes, Philip Harrison, Vincent Hughes, Poppy Welch, Finnian Kelly, David van der Vloed
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="gessinger24_interspeech.html">
                                <p>
                                    The Use of Modifiers and f0 in Remote Referential Communication with Human and Computer Partners
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Iona Gessinger, Bistra Andreeva, Benjamin R. Cowan
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Emotion Recognition: Resources and Benchmarks"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Emotion Recognition: Resources and Benchmarks</h4>
                            <hr>
                            <a class="w3-text" href="ma24b_interspeech.html">
                                <p>
                                    EmoBox: Multilingual Multi-corpus Speech Emotion Recognition Toolkit and Benchmark
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Ziyang Ma, Mingjie Chen, Hezhao Zhang, Zhisheng Zheng, Wenxi Chen, Xiquan Li, Jiaxin Ye, Xie Chen, Thomas Hain
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="triantafyllopoulos24b_interspeech.html">
                                <p>
                                    INTERSPEECH 2009 Emotion Challenge Revisited: Benchmarking 15 Years of Progress in Speech Emotion Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Andreas Triantafyllopoulos, Anton Batliner, Simon Rampp, Manuel Milling, BjÃ¶rn Schuller
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="ibrahim24_interspeech.html">
                                <p>
                                    What Does it Take to Generalize SER Model Across Datasets? A Comprehensive Benchmark
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Adham Ibrahim, Shady Shehata, Ajinkya Kulkarni, Mukhtar Mohamed, Muhammad Abdul-Mageed
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="naini24_interspeech.html">
                                <p>
                                    WHiSER: White House Tapes Speech Emotion Recognition Corpus
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Abinay Reddy Naini, Lucas Goncalves, Mary A. Kohler, Donita Robinson, Elizabeth Richerson, Carlos Busso
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="latif24_interspeech.html">
                                <p>
                                    Evaluating Transformer-Enhanced Deep Reinforcement Learning for Speech Emotion Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Siddique Latif, Raja Jurdak, BjÃ¶rn W. Schuller
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="wang24ia_interspeech.html">
                                <p>
                                    Boosting Cross-Corpus Speech Emotion Recognition using CycleGAN with Contrastive Learning
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jincen Wang, Yan Zhao, Cheng Lu, Chuangao Tang, Sunan Li, Yuan Zong, Wenming Zheng
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Speaker and Language Identification and Diarization"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Speaker and Language Identification and Diarization</h4>
                            <hr>
                            <a class="w3-text" href="rahou24_interspeech.html">
                                <p>
                                    Multi-latency look-ahead for streaming speaker segmentation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Bilal Rahou, HervÃ© Bredin
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="boeddeker24_interspeech.html">
                                <p>
                                    Once more Diarization: Improving meeting transcription systems through segment-level speaker reassignment
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Christoph Boeddeker, Tobias Cord-Landwehr, Reinhold Haeb-Umbach
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="mariotte24_interspeech.html">
                                <p>
                                    ASoBO: Attentive Beamformer Selection for Distant Speaker Diarization in Meetings
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        ThÃ©o Mariotte, Anthony Larcher, Silvio MontrÃ©sor, Jean-Hugh Thomas
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="pirlogeanu24_interspeech.html">
                                <p>
                                    Hybrid-Diarization System with Overlap Post-Processing for the DISPLACE 2024 Challenge
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Gabriel PÃ®rlogeanu, Octavian Pascu, Alexandru-Lucian Georgescu, Horia Cucu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kalluri24_interspeech.html">
                                <p>
                                    The Second DISPLACE Challenge: DIarization of SPeaker and LAnguage in Conversational Environments
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Shareef Babu Kalluri, Prachi Singh, Pratik Roy Chowdhuri, Apoorva Kulkarni, Shikha Baghel, Pradyoth Hegde, Swapnil Sontakke, Deepak K T, S.R. Mahadeva Prasanna, Deepu Vijayasenan, Sriram Ganapathy
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kalda24_interspeech.html">
                                <p>
                                    TalTech-IRIT-LIS Speaker and Language Diarization Systems for DISPLACE 2024
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Joonas Kalda, Tanel Alumae, Martin Lebourdais, HervÃ© Bredin, SÃ©verin Baroudi, Ricard Marxer
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="hao24b_interspeech.html">
                                <p>
                                    Exploring Energy-Based Models for Out-of-Distribution Detection in Dialect Identification
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yaqian Hao, Chenguang Hu, Yingying Gao, Shilei Zhang, Junlan Feng
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="valente24_interspeech.html">
                                <p>
                                    Exploring Spoken Language Identification Strategies for Automatic Transcription of Multilingual Broadcast and Institutional Speech
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Martina Valente, Fabio Brugnara, Giovanni Morrone, Enrico Zovato, Leonardo Badino
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="paturi24_interspeech.html">
                                <p>
                                    AG-LSEC: Audio Grounded Lexical Speaker Error Correction
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Rohit Paturi, Xiang Li, Sundararajan Srinivasan
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="su24_interspeech.html">
                                <p>
                                    Speaker Change Detection with Weighted-sum Knowledge Distillation based on Self-supervised Pre-trained Models
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Hang Su, Yuxiang Kong, Lichun Fan, Peng Gao, Yujun Wang, Zhiyong Wu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="makishima24_interspeech.html">
                                <p>
                                    SOMSRED: Sequential Output Modeling for Joint Multi-talker Overlapped Speech Recognition and Speaker Diarization
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Naoki Makishima, Naotaka Kawata, Mana Ihori, Tomohiro Tanaka, Shota Orihashi, Atsushi Ando, Ryo Masumura
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="munakata24_interspeech.html">
                                <p>
                                    Song Data Cleansing for End-to-End Neural Singer Diarization Using Neural Analysis and Synthesis Framework
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Hokuto Munakata, Ryo Terashima, Yusuke Fujita
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Audio-Text Retrieval"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Audio-Text Retrieval</h4>
                            <hr>
                            <a class="w3-text" href="xin24_interspeech.html">
                                <p>
                                    DiffATR: Diffusion-based Generative Modeling for Audio-Text Retrieval
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yifei Xin, Xuxin Cheng, Zhihong Zhu, Xusheng Yang, Yuexian Zou
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="yan24_interspeech.html">
                                <p>
                                    Bridging Language Gaps in Audio-Text Retrieval
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Zhiyong Yan, Heinrich Dinkel, Yongqing Wang, Jizhong Liu, Junbo Zhang, Yujun Wang, Bin Wang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="deshmukh24_interspeech.html">
                                <p>
                                    Domain Adaptation for Contrastive Audio-Language Models
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Soham Deshmukh, Rita Singh, Bhiksha Raj
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="paissan24_interspeech.html">
                                <p>
                                    tinyCLAP: Distilling Constrastive Language-Audio Pretrained Models
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Francesco Paissan, Elisabetta Farella
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kim24f_interspeech.html">
                                <p>
                                    BTS: Bridging Text and Sound Modalities for Metadata-Aided Respiratory Sound Classification
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        June-Woo Kim, Miika Toikkanen, Yera Choi, Seoung-Eun Moon, Ho-Young Jung
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="tang24b_interspeech.html">
                                <p>
                                    Enhanced Feature Learning with Normalized Knowledge Distillation for Audio Tagging
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yuwu Tang, Ziang Ma, Haitao Zhang
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Speech Enhancement"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Speech Enhancement</h4>
                            <hr>
                            <a class="w3-text" href="liu24n_interspeech.html">
                                <p>
                                    RaD-Net 2: A causal two-stage repairing and denoising speech enhancement network with knowledge distillation and complex axial self-attention
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Mingshuai Liu, Zhuangqi Chen, Xiaopeng Yan, Yuanjun Lv, Xianjun Xia, Chuanzeng Huang, Yijian Xiao, Lei Xie
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="liu24o_interspeech.html">
                                <p>
                                    DNN-based monaural speech enhancement using alternate analysis windows for phase and magnitude modification
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Xi Liu, John H.L. Hansen
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="li24aa_interspeech.html">
                                <p>
                                    Improved Remixing Process for Domain Adaptation-Based Speech Enhancement by Mitigating Data Imbalance in Signal-to-Noise Ratio
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Li Li, Shogo Seki
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="zhang24_interspeech.html">
                                <p>
                                    Neural Network Augmented Kalman Filter for Robust Acoustic Howling Suppression
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yixuan Zhang, Hao Zhang, Meng Yu, Dong Yu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="li24w_interspeech.html">
                                <p>
                                    Improving Speech Enhancement by Integrating Inter-Channel and Band Features with Dual-branch Conformer
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jizhen Li, Xinmeng Xu, Weiping Tu, Yuhong Yang, Rong Zhu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="zhang24n_interspeech.html">
                                <p>
                                    An Exploration of Length Generalization in Transformer-Based Speech Enhancement
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Qiquan Zhang, Hongxu Zhu, Xinyuan Qian, Eliathamby Ambikairajah, Haizhou Li
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="guan24_interspeech.html">
                                <p>
                                    Reducing Speech Distortion and Artifacts for Speech Enhancement by Loss Function
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Haixin Guan, Wei Dai, Guangyong Wang, Xiaobin Tan, Peng Li, Jiaen Liang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="mawalim24_interspeech.html">
                                <p>
                                    Are Recent Deep Learning-Based Speech Enhancement Methods Ready to Confront Real-World Noisy Environments?
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Candy Olivia Mawalim, Shogo Okada, Masashi Unoki
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="zhang24i_interspeech.html">
                                <p>
                                    Beyond Performance Plateaus: A Comprehensive Study on Scalability in Speech Enhancement
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Wangyou Zhang, Kohei Saijo, Jee-weon Jung, Chenda Li, Shinji Watanabe, Yanmin Qian
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Speech Coding"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Speech Coding</h4>
                            <hr>
                            <a class="w3-text" href="zhang24g_interspeech.html">
                                <p>
                                    TD-PLC: A Semantic-Aware Speech Encoding for Improved Packet Loss Concealment
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jinghong Zhang, Zugang Zhao, Yonghui Liu, Jianbing Liu, Zhiqiang He, Kai Niu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="zhang24m_interspeech.html">
                                <p>
                                    BS-PLCNet 2: Two-stage Band-split Packet Loss Concealment Network with Intra-model Knowledge Distillation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Zihan Zhang, Xianjun Xia, Chuanzeng Huang, Yijian Xiao, Lei Xie
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="gupta24c_interspeech.html">
                                <p>
                                    On Improving Error Resilience of Neural End-to-End Speech Coders
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Kishan Gupta, Nicola Pia, Srikanth Korse, Andreas Brendel, Guillaume Fuchs, Markus Multrus
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="muller24c_interspeech.html">
                                <p>
                                    Speech quality evaluation of neural audio codecs
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Thomas Muller, Stephane Ragot, Laetitia Gros, Pierrick Philippe, Pascal Scalart
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="ai24b_interspeech.html">
                                <p>
                                    A Low-Bitrate Neural Audio Codec Framework with Bandwidth Reduction and Recovery for High-Sampling-Rate Waveforms
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yang Ai, Ye-Xin Lu, Xiao-Hang Jiang, Zheng-Yan Sheng, Rui-Chen Zheng, Zhen-Hua Ling
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="wu24p_interspeech.html">
                                <p>
                                    CodecFake: Enhancing Anti-Spoofing Models Against Deepfake Audios from Codec-Based Speech Synthesis Systems
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Haibin Wu, Yuan Tseng, Hung-yi Lee
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Speech Synthesis: Expressivity and Emotion"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Speech Synthesis: Expressivity and Emotion</h4>
                            <hr>
                            <a class="w3-text" href="li24pa_interspeech.html">
                                <p>
                                    GTR-Voice: Articulatory Phonetics Informed Controllable Expressive Speech Synthesis
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Zehua Kcriss Li, Meiying Melissa Chen, Yi Zhong, Pinxin Liu, Zhiyao Duan
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="seong24b_interspeech.html">
                                <p>
                                    TSP-TTS: Text-based Style Predictor with Residual Vector Quantization for Expressive Text-to-Speech
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Donghyun Seong, Hoyoung Lee, Joon-Hyuk Chang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="li24na_interspeech.html">
                                <p>
                                    Spontaneous Style Text-to-Speech Synthesis with Controllable Spontaneous Behaviors Based on Language Models
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Weiqin Li, Peiji Yang, Yicheng Zhong, Yixuan Zhou, Zhisheng Wang, Zhiyong Wu, Xixin Wu, Helen Meng
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="guo24d_interspeech.html">
                                <p>
                                    Text-aware and Context-aware Expressive Audiobook Speech Synthesis
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Dake Guo, Xinfa Zhu, Liumeng Xue, Yongmao Zhang, Wenjie Tian, Lei Xie
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="bott24_interspeech.html">
                                <p>
                                    Controlling Emotion in Text-to-Speech with Natural Language Prompts
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Thomas Bott, Florian Lux, Ngoc Thang Vu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="xue24b_interspeech.html">
                                <p>
                                    Retrieval Augmented Generation in Prompt-based Text-to-Speech Synthesis with Context-Aware Contrastive Language-Audio Pretraining
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jinlong Xue, Yayue Deng, Yingming Gao, Ya Li
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kalyan24_interspeech.html">
                                <p>
                                    Emotion Arithmetic: Emotional Speech Synthesis via Weight Space Interpolation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Pavan Kalyan, Preeti Rao, Preethi Jyothi, Pushpak Bhattacharyya
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="cho24_interspeech.html">
                                <p>
                                    EmoSphere-TTS: Emotional Style and Intensity Modeling via Spherical Emotion Vector for Controllable Emotional Text-to-Speech
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Deok-Hyeon Cho, Hyung-Seok Oh, Seung-Bin Kim, Sang-Hoon Lee, Seong-Whan Lee
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="li24da_interspeech.html">
                                <p>
                                    Expressive paragraph text-to-speech synthesis with multi-step variational autoencoder
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Xuyuan Li, Zengqiang Shang, Peiyang Shi, Hua Hua, Ta Li, Pengyuan Zhang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="yu24b_interspeech.html">
                                <p>
                                    Differentiable Time-Varying Linear Prediction in the Context of End-to-End Analysis-by-Synthesis
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Chin-Yun Yu, GyÃ¶rgy Fazekas
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Speech Synthesis: Tools and Data"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Speech Synthesis: Tools and Data</h4>
                            <hr>
                            <a class="w3-text" href="saito24_interspeech.html">
                                <p>
                                    SRC4VC: Smartphone-Recorded Corpus for Voice Conversion Benchmark
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yuki Saito, Takuto Igarashi, Kentaro Seki, Shinnosuke Takamichi, Ryuichi Yamamoto, Kentaro Tachibana, Hiroshi Saruwatari
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="srinivasavaradhan24_interspeech.html">
                                <p>
                                    Rasa: Building Expressive Speech Synthesis Systems for Indian Languages in Low-resource Settings
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Praveen Srinivasa Varadhan, Ashwin Sankar, Giri Raju, Mitesh M Khapra
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="ma24c_interspeech.html">
                                <p>
                                    FLEURS-R: A Restored Multilingual Speech Corpus for Generation Tasks
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Min Ma, Yuma Koizumi, Shigeki Karita, Heiga Zen, Jason Riesa, Haruko Ishikawa, Michiel Bacchiani
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="ma24d_interspeech.html">
                                <p>
                                    WenetSpeech4TTS: A 12,800-hour Mandarin TTS Corpus for Large Speech Generation Model Benchmark
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Linhan Ma, Dake Guo, Kun Song, Yuepeng Jiang, Shuai Wang, Liumeng Xue, Weiming Xu, Huan Zhao, Binbin Zhang, Lei Xie
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="yang24d_interspeech.html">
                                <p>
                                    MSceneSpeech: A Multi-Scene Speech Dataset For Expressive Speech Synthesis
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Qian Yang, Jialong Zuo, Zhe Su, Ziyue Jiang, Mingze Li, Zhou Zhao, Feiyang Chen, Zhefeng Wang, Baoxing Huai
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kawamura24_interspeech.html">
                                <p>
                                    LibriTTS-P: A Corpus with Speaking Style and Speaker Identity Prompts for Text-to-Speech and Style Captioning
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Masaya Kawamura, Ryuichi Yamamoto, Yuma Shirahata, Takuya Hasumi, Kentaro Tachibana
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="ogun24_interspeech.html">
                                <p>
                                    1000 African Voices: Advancing inclusive multi-speaker multi-accent speech synthesis
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Sewade Ogun, Abraham T. Owodunni, Tobi Olatunji, Eniola Alese, Babatunde Oladimeji, Tejumade Afonja, Kayode Olaleye, Naome A. Etori, Tosin Adewumi
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="take24_interspeech.html">
                                <p>
                                    SaSLaW: Dialogue Speech Corpus with Audio-visual Egocentric Information Toward Environment-adaptive Dialogue Speech Synthesis
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Osamu Take, Shinnosuke Takamichi, Kentaro Seki, Yoshiaki Bando, Hiroshi Saruwatari
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Speech Synthesis: Singing Voice Synthesis"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Speech Synthesis: Singing Voice Synthesis</h4>
                            <hr>
                            <a class="w3-text" href="kim24i_interspeech.html">
                                <p>
                                    MakeSinger: A Semi-Supervised Training Method for Data-Efficient Singing Voice Synthesis via Classifier-free Diffusion Guidance
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Semin Kim, Myeonghun Jeong, Hyeonseung Lee, Minchan Kim, Byoung Jin Choi, Nam Soo Kim
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="okamoto24_interspeech.html">
                                <p>
                                    Challenge of Singing Voice Synthesis Using Only Text-To-Speech Corpus With FIRNet Source-Filter Neural Vocoder
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Takuma Okamoto, Yamato Ohtani, Sota Shimizu, Tomoki Toda, Hisashi Kawai
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kim24p_interspeech.html">
                                <p>
                                    Period Singer: Integrating Periodic and Aperiodic Variational Autoencoders for Natural-Sounding End-to-End Singing Voice Synthesis
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Taewoo Kim, Choonsang Cho, Young Han Lee
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="shi24_interspeech.html">
                                <p>
                                    Singing Voice Data Scaling-up: An Introduction to ACE-Opencpop and ACE-KiSing
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jiatong Shi, Yueqian Lin, Xinyi Bai, Keyi Zhang, Yuning Wu, Yuxun Tang, Yifeng Yu, Qin Jin, Shinji Watanabe
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="hwang24_interspeech.html">
                                <p>
                                    X-Singer: Code-Mixed Singing Voice Synthesis via Cross-Lingual Learning
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Ji-Sang Hwang, Hyeongrae Noh, Yoonseok Hong, Insoo Oh
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="gao24e_interspeech.html">
                                <p>
                                    An End-to-End Approach for Chord-Conditioned Song Generation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Shuochen Gao, Shun Lei, Fan Zhuo, Hangyu Liu, Feng Liu, Boshi Tang, Qiaochu Huang, Shiyin Kang, Zhiyong Wu
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="LLM in ASR"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">LLM in ASR</h4>
                            <hr>
                            <a class="w3-text" href="baskar24_interspeech.html">
                                <p>
                                    Speech Prefix-Tuning with RNNT Loss for Improving LLM Predictions
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Murali Karthick Baskar, Andrew Rosenberg, Bhuvana Ramabhadran, Neeraj Gaur, Zhong Meng
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="seide24_interspeech.html">
                                <p>
                                    Speech ReaLLM â Real-time Speech Recognition with Multimodal Language Models by Teaching the Flow of Time
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Frank Seide, Yangyang Shi, Morrie Doulaty, Yashesh Gaur, Junteng Jia, Chunyang Wu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="li24t_interspeech.html">
                                <p>
                                    A Transcription Prompt-based Efficient Audio Large Language Model for Robust Speech Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yangze Li, Xiong Wang, Songjun Cao, Yike Zhang, Long Ma, Lei Xie
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="tang24_interspeech.html">
                                <p>
                                    Pinyin Regularization in Error Correction for Chinese Speech Recognition with Large Language Models
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Zhiyuan Tang, Dong Wang, Shen Huang, Shidong Shang
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Vision and Speech"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Vision and Speech</h4>
                            <hr>
                            <a class="w3-text" href="kim24g_interspeech.html">
                                <p>
                                    AVCap: Leveraging Audio-Visual Features as Text Tokens for Captioning
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jongsuk Kim, Jiwon Shin, Junmo Kim
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="ghosh24b_interspeech.html">
                                <p>
                                    LipGER: Visually-Conditioned Generative Error Correction for Robust Automatic Speech Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Sreyan Ghosh, Sonal Kumar, Ashish Seth, Purva Chiniya, Utkarsh Tyagi, Ramani Duraiswami, Dinesh Manocha
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="li24v_interspeech.html">
                                <p>
                                    Joint Speaker Features Learning for Audio-visual Multichannel Speech Separation and Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Guinan Li, Jiajun Deng, Youjun Chen, Mengzhe Geng, Shujie Hu, Zhe Li, Zengrui Jin, Tianzi Wang, Xurong Xie, Helen Meng, Xunying Liu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="chen24y_interspeech.html">
                                <p>
                                    CNVSRC 2023: The First Chinese Continuous Visual Speech Recognition Challenge
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Chen Chen, Zehua Liu, Xiaolou Li, Lantian Li, Dong Wang
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Spoken Document Summarization"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Spoken Document Summarization</h4>
                            <hr>
                            <a class="w3-text" href="kroll24_interspeech.html">
                                <p>
                                    Optimizing the role of human evaluation in LLM-based spoken document summarization systems
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Margaret Kroll, Kelsey Kraus
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="ryu24_interspeech.html">
                                <p>
                                    Key-Element-Informed sLLM Tuning for Document Summarization
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Sangwon Ryu, Heejin Do, Yunsu Kim, Gary Geunbae Lee, Jungseul Ok
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="matsuura24_interspeech.html">
                                <p>
                                    Sentence-wise Speech Summarization: Task, Datasets, and End-to-End Modeling with LM Knowledge Distillation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Kohei Matsuura, Takanori Ashihara, Takafumi Moriya, Masato Mimura, Takatomo Kano, Atsunori Ogawa, Marc Delcroix
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="shang24_interspeech.html">
                                <p>
                                    An End-to-End Speech Summarization Using Large Language Model
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Hengchao Shang, Zongyao Li, Jiaxin Guo, Shaojun Li, Zhiqiang Rao, Yuanchang Luo, Daimeng Wei, Hao Yang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kang24d_interspeech.html">
                                <p>
                                    Prompting Large Language Models with Audio for General-Purpose Speech Summarization
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Wonjune Kang, Deb Roy
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="leduc24_interspeech.html">
                                <p>
                                    Real-time Speech Summarization for Medical Conversations
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Khai Le-Duc, Khai-Nguyen Nguyen, Long Vo-Dang, Truong-Son Hy
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Speech and Language in Health: from Remote Monitoring to Medical Conversations - 2 (Special Sessions)"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Speech and Language in Health: from Remote Monitoring to Medical Conversations - 2 (Special Sessions)</h4>
                            <hr>
                            <a class="w3-text" href="escobargrisales24_interspeech.html">
                                <p>
                                    Itâs Time to Take Action: Acoustic Modeling of Motor Verbs to Detect Parkinsonâs Disease
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Daniel Escobar-Grisales, Cristian David RÃ­os-Urrego, Ilja Baumann, Korbinian Riedhammer, Elmar Noeth, Tobias Bocklet, Adolfo M. Garcia, Juan Rafael Orozco-Arroyave
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="maisonneuve24_interspeech.html">
                                <p>
                                    Towards objective and interpretable speech disorder assessment: a comparative analysis of CNN and transformer-based models
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Malo Maisonneuve, Corinne Fredouille, Muriel Lalain, Alain Ghio, Virginie Woisard
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="botelho24_interspeech.html">
                                <p>
                                    Macro-descriptors for Alzheimer's disease detection using large language models
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Catarina Botelho, John MendonÃ§a, Anna Pompili, Tanja Schultz, Alberto Abad, Isabel Trancoso
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="braun24_interspeech.html">
                                <p>
                                    Infusing Acoustic Pause Context into Text-Based Dementia Assessment
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Franziska Braun, Sebastian P. Bayerl, Florian HÃ¶nig, Hartmut Lehfeld, Thomas Hillemacher, Tobias Bocklet, Korbinian Riedhammer
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="roesler24_interspeech.html">
                                <p>
                                    Towards Scalable Remote Assessment of Mild Cognitive Impairment Via Multimodal Dialog
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Oliver Roesler, Jackson Liscombe, Michael Neumann, Hardik Kothare, Abhishek Hosamath, Lakshmi Arbatti, Doug Habberstad, Christiane Suendermann-Oeft, Meredith Bartlett, Cathy Zhang, Nikhil Sukhdev, Kolja Wilms, Anusha Badathala, Sandrine Istas, Steve Ruhmel, Bryan Hansen, Madeline Hannan, David Henley, Arthur Wallace, Ira Shoulson, David Suendermann-Oeft, Vikram Ramanarayanan
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="barberis24_interspeech.html">
                                <p>
                                    Automatic recognition and detection of aphasic natural speech
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Mara Barberis, Pieter De Clercq, Bastiaan Tamm, Hugo Van hamme, Maaike Vandermosten
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="sanguedolce24_interspeech.html">
                                <p>
                                    When Whisper Listens to Aphasia: Advancing Robust Post-Stroke Speech Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Giulia Sanguedolce, Sophie Brook, Dragos C. Gruia, Patrick A. Naylor, Fatemeh Geranmayeh
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="wang24e_interspeech.html">
                                <p>
                                    Automatic Prediction of Amyotrophic Lateral Sclerosis Progression using Longitudinal Speech Transformer
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Liming Wang, Yuan Gong, Nauman Dawalatabad, Marco Vilela, Katerina Placek, Brian Tracey, Yishu Gong, Alan Premasiri, Fernando Vieira, James Glass
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kothare24_interspeech.html">
                                <p>
                                    How Consistent are Speech-Based Biomarkers in Remote Tracking of ALS Disease Progression Across Languages? A Case Study of English and Dutch
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Hardik Kothare, Michael Neumann, Cathy Zhang, Jackson Liscombe, Jordi W J van Unnik, Lianne C M Botman, Leonard H van den Berg, Ruben P A van Eijk, Vikram Ramanarayanan
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="spiesberger24_interspeech.html">
                                <p>
                                    âSo . . . my child . . . â â How Child ADHD Influences the Way Parents Talk
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Anika A. Spiesberger, Andreas Triantafyllopoulos, Alexander Kathan, Anastasia Semertzidou, Caterina Gawrilow, Tilman Reinelt, Wolfgang A. Rauch, BjÃ¶rn Schuller
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="dineley24_interspeech.html">
                                <p>
                                    Variability of speech timing features across repeated recordings: a comparison of open-source extraction techniques
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Judith Dineley, Ewan Carr, Lauren L. White, Catriona Lucas, Zahia Rahman, Tian Pan, Faith Matcham, Johnny Downs, Richard J. Dobson, Thomas F. Quatieri, Nicholas Cummins
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="labrak24_interspeech.html">
                                <p>
                                    Zero-Shot End-To-End Spoken Question Answering In Medical Domain
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yanis Labrak, Adel Moumen, Richard Dufour, Mickael Rouvier
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="jiang24b_interspeech.html">
                                <p>
                                    Perceiver-Prompt: Flexible Speaker Adaptation in Whisper for Chinese Disordered Speech Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yicong Jiang, Tianzi Wang, Xurong Xie, Juan Liu, Wei Sun, Nan Yan, Hui Chen, Lan Wang, Xunying Liu, Feng Tian
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Show and Tell 2"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Show and Tell 2</h4>
                            <hr>
                            <a class="w3-text" href="v24_interspeech.html">
                                <p>
                                    Custom wake word detection
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Kesavaraj V, Charan Devarkonda, Vamshiraghusimha Narasinga, Anil Kumar Vuppala
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="chen24z_interspeech.html">
                                <p>
                                    Edged based audio-visual speech enhancement demonstrator
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Song Chen, Mandar Gogate, Kia Dashtipour, Jasper Kirton-Wingate, Adeel Hussain, Faiyaz Doctor, Tughrul Arslan, Amir Hussain
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="anway24_interspeech.html">
                                <p>
                                    Real-Time Gaze-directed speech enhancement for audio-visual hearing-aids
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Arif Reza Anway, Bryony Buck, Mandar Gogate, Kia Dashtipour, Michael Akeroyd, Amir Hussain
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kumar24c_interspeech.html">
                                <p>
                                    Detection of background agents speech in contact centers
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Abhishek Kumar, Srikanth Konjeti, Jithendra Vepa
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="koilakuntla24_interspeech.html">
                                <p>
                                    Leveraging large language models for post-transcription correction in contact centers
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Bramhendra Koilakuntla, Prajesh Rana, Paras Ahuja, Srikanth Konjeti, Jithendra Vepa
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="schade24_interspeech.html">
                                <p>
                                    Understanding âunderstandingâ: presenting a richly annotated multimodal corpus of dyadic interaction
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Leonie Schade, Nico Dallmann, Olcay TÃ¼k, Stefan Lazarov, Petra Wagner
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="possamaidemenezes24_interspeech.html">
                                <p>
                                    A demonstrator for articulation-based command word recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Joao Vitor Possamai de Menezes, Arne-Lukas Fietkau, Tom Diener, Steffen Kurbis, Peter Birkholz
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="ward24b_interspeech.html">
                                <p>
                                    Pragmatically similar utterance finder demonstration
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Nigel G. Ward, Andres Segura
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="liu24s_interspeech.html">
                                <p>
                                    Real-time scheme for rapid extraction of speaker embeddings in challenging recording conditions
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Kai Liu, Ziqing Du, Zhou Huan, Xucheng Wan, Naijun Zheng
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="chen24aa_interspeech.html">
                                <p>
                                    TEEMI: a speaking practice tool for L2 English learners
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Szu-Yu Chen, Tien-Hong Lo, Yao-Ting Sung, Ching-Yu Tseng, Berlin Chen
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Prosody"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Prosody</h4>
                            <hr>
                            <a class="w3-text" href="hu24b_interspeech.html">
                                <p>
                                    Automatic pitch accent classification through image classification
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Na Hu, Hugo Schnack, Amalia Arvaniti
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="geng24_interspeech.html">
                                <p>
                                    Form and Function in Prosodic Representation:  In the Case of 'ma' in Tianjin Mandarin
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Tianqi Geng, Hui Feng
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="chakraborty24_interspeech.html">
                                <p>
                                    On Comparing Time- and Frequency-Domain Rhythm Measures in Classifying Assamese Dialects
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Joyshree Chakraborty, Leena Dihingia, Priyankoo Sarmah, Rohit Sinha
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="riegger24_interspeech.html">
                                <p>
                                    The prosody of the verbal prefix ge-: historical and experimental evidence
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Chiara Riegger, Tina BÃ¶gel, George Walkden
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="wu24n_interspeech.html">
                                <p>
                                    Influences of Morphosyntax and Semantics on the Intonation of Mandarin Chinese Wh-indeterminates
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Hongchen Wu, Jiwon Yun
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="mumtaz24_interspeech.html">
                                <p>
                                    Urdu Alternative Questions: A Hat Pattern
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Benazir Mumtaz, Miriam Butt
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Foundational Models for Deepfake and Spoofed Speech Detection"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Foundational Models for Deepfake and Spoofed Speech Detection</h4>
                            <hr>
                            <a class="w3-text" href="tran24_interspeech.html">
                                <p>
                                    Spoofed Speech Detection with a Focus on Speaker Embedding
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Hoan My Tran, David Guennec, Philippe Martin, Aghilas Sini, Damien Lolive, Arnaud Delhay, Pierre-FranÃ§ois Marteau
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="martindonas24_interspeech.html">
                                <p>
                                    Exploring Self-supervised Embeddings and Synthetic Data Augmentation for Robust Audio Deepfake Detection
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Juan M. MartÃ­n-DoÃ±as, Aitor Ãlvarez, Eros Rosello, Angel M. Gomez, Antonio M. Peinado
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="pan24c_interspeech.html">
                                <p>
                                    Attentive Merging of Hidden Embeddings from Pre-trained Speech Model for Anti-spoofing Detection
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Zihan Pan, Tianchi Liu, Hardik B. Sailor, Qiongqiong Wang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="wu24c_interspeech.html">
                                <p>
                                    Adapter Learning from Pre-trained Model for Robust Spoof Speech Detection
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Haochen Wu, Wu Guo, Shengyu Peng, Zhuhai Li, Jie Zhang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="liu24b_interspeech.html">
                                <p>
                                    Speech Formants Integration for Generalized Detection of Synthetic Speech Spoofing Attacks
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Kexu Liu, Yuanxin Wang, Shengchen Li, Xi Shao
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="doan24_interspeech.html">
                                <p>
                                    Balance, Multiple Augmentation, and Re-synthesis: A Triad Training Strategy for Enhanced Audio Deepfake Detection
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Thien-Phuc Doan, Long Nguyen-Vu, Kihun Hong, Souhwan Jung
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Speaker Recognition 1"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Speaker Recognition 1</h4>
                            <hr>
                            <a class="w3-text" href="peng24_interspeech.html">
                                <p>
                                    Fine-tune Pre-Trained Models with Multi-Level Feature Fusion for Speaker Verification
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Shengyu Peng, Wu Guo, Haochen Wu, Zuoliang Li, Jie Zhang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="yu24_interspeech.html">
                                <p>
                                    Speaker Conditional Sinc-Extractor for Personal VAD
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        En-Lun Yu, Kuan-Hsun Ho, Jeih-weih Hung, Shih-Chieh Huang, Berlin Chen
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="liou24_interspeech.html">
                                <p>
                                    Enhancing ECAPA-TDNN with Feature Processing Module and Attention Mechanism for Speaker Verification
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Shiu-Hsiang Liou, Po-Cheng Chan, Chia-Ping Chen, Tzu-Chieh Lin, Chung-Li Lu, Yu-Han Cheng, Hsiang-Feng Chuang, Wei-Yu Chen
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kim24j_interspeech.html">
                                <p>
                                    MR-RawNet: Speaker verification system with multiple temporal resolutions for variable duration utterances using raw waveforms
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Seung-bin Kim, Chan-yeong Lim, Jungwoo Heo, Ju-ho Kim, Hyun-seo Shin, Kyo-Won Koo, Ha-Jin Yu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="nam24b_interspeech.html">
                                <p>
                                    Disentangled Representation Learning for Environment-agnostic Speaker Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        KiHyun Nam, Hee-Soo Heo, Jee-weon Jung, Joonson Chung
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="mosner24_interspeech.html">
                                <p>
                                    Multi-Channel Extension of Pre-trained Models for Speaker Verification
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Ladislav MoÅ¡ner, Romain Serizel, LukÃ¡Å¡ Burget, OldÅich Plchot, Emmanuel Vincent, Junyi Peng, Jan ÄernockÃ½
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="li24la_interspeech.html">
                                <p>
                                    Efficient Integrated Features Based on Pre-trained Models for Speaker Verification
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yishuang Li, Wenhao Guan, Hukai Huang, Shiyu Miao, Qi Su, Lin Li, Qingyang Hong
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="wang24ma_interspeech.html">
                                <p>
                                    SE/BN Adapter: Parametric Efficient Domain Adaptation for Speaker Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Tianhao Wang, Lantian Li, Dong Wang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="xie24b_interspeech.html">
                                <p>
                                    DB-PMAE: Dual-Branch Prototypical Masked AutoEncoder with locality for domain robust speaker verification
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Wei-lin Xie, Yu-Xuan Xi, Yan Song, Jian-tao Zhang, Hao-yu Song, Ian McLoughlin
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="maciejewski24_interspeech.html">
                                <p>
                                    Evaluating the Santa Barbara Corpus: Challenges of the Breadth of Conversational Spoken Language
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Matthew Maciejewski, Dominik Klement, Ruizhe Huang, Matthew Wiesner, Sanjeev Khudanpur
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="zhou24f_interspeech.html">
                                <p>
                                    A Comprehensive Investigation on Speaker Augmentation for Speaker Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Zhenyu Zhou, Shibiao Xu, Shi Yin, Lantian Li, Dong Wang
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Source Separation 1"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Source Separation 1</h4>
                            <hr>
                            <a class="w3-text" href="wang24i_interspeech.html">
                                <p>
                                    Noise-robust Speech Separation with Fast Generative Correction
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Helin Wang, JesÃºs Villalba, Laureano Moro-Velazquez, Jiarui Hai, Thomas Thebaud, Najim Dehak
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="hartanto24_interspeech.html">
                                <p>
                                    MSDET: Multitask Speaker Separation and Direction-of-Arrival Estimation Training
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Roland Hartanto, Sakriani Sakti, Koichi Shinoda
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kealey24_interspeech.html">
                                <p>
                                    Unsupervised Improved MVDR Beamforming for Sound Enhancement
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jacob Kealey, John R. Hershey, FranÃ§ois Grondin
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="chen24h_interspeech.html">
                                <p>
                                    Improving Generalization of Speech Separation in Real-World Scenarios: Strategies in Simulation, Optimization, and Evaluation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Ke Chen, Jiaqi Su, Taylor Berg-Kirkpatrick, Shlomo Dubnov, Zeyu Jin
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kim24m_interspeech.html">
                                <p>
                                    Enhanced Deep Speech Separation in Clustered Ad Hoc Distributed Microphone Environments
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jihyun Kim, Stijn Kindt, Nilesh Madhu, Hong-Goo Kang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="yip24_interspeech.html">
                                <p>
                                    Towards Audio Codec-based Speech Separation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jia Qi Yip, Shengkui Zhao, Dianwen Ng, Eng Siong Chng, Bin Ma
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Audio-Visual and Generative Speech Enhancement"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Audio-Visual and Generative Speech Enhancement</h4>
                            <hr>
                            <a class="w3-text" href="li24d_interspeech.html">
                                <p>
                                    Locally Aligned Rectified Flow Model for Speech Enhancement Towards Single-Step Diffusion
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Zhengxiao Li, Nakamasa Inoue
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="wang24m_interspeech.html">
                                <p>
                                    Diffusion Gaussian Mixture Audio Denoise
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Pu Wang, Junhui Li, Jialu Li, Liangdong Guo, Youshan Zhang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="lay24_interspeech.html">
                                <p>
                                    An Analysis of the Variance of Diffusion-based Speech Enhancement
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Bunlong Lay, Timo Gerkmann
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="jung24b_interspeech.html">
                                <p>
                                    FlowAVSE: Efficient Audio-Visual Speech Enhancement with Conditional Flow Matching
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Chaeyoung Jung, Suyeon Lee, Ji-Hoon Kim, Joon Son Chung
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="chen24g_interspeech.html">
                                <p>
                                    RT-LA-VocE: Real-Time Low-SNR Audio-Visual Speech Enhancement
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Honglie Chen, Rodrigo Mira, Stavros Petridis, Maja Pantic
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="li24m_interspeech.html">
                                <p>
                                    Complex Image-Generative Diffusion Transformer for Audio Denoising
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Junhui Li, Pu Wang, Jialu Li, Youshan Zhang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="hu24c_interspeech.html">
                                <p>
                                    Noise-aware Speech Enhancement using Diffusion Probabilistic Model
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yuchen Hu, Chen Chen, Ruizhe Li, Qiushi Zhu, Eng Siong Chng
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Speech Privacy and Bandwidth Expansion"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Speech Privacy and Bandwidth Expansion</h4>
                            <hr>
                            <a class="w3-text" href="vali24_interspeech.html">
                                <p>
                                    Privacy PORCUPINE: Anonymization of Speaker Attributes Using Occurrence Normalization for Space-Filling Vector Quantization
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Mohammad Hassan Vali, Tom BÃ¤ckstrÃ¶m
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="singh24_interspeech.html">
                                <p>
                                    SilentCipher: Deep Audio Watermarking
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Mayank Kumar Singh, Naoya Takahashi, Weihsiang Liao, Yuki Mitsufuji
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="fan24_interspeech.html">
                                <p>
                                    Frequency-mix Knowledge Distillation for Fake Speech Detection
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Cunhang Fan, Shunbo Dong, Jun Xue, Yujie Chen, Jiangyan Yi, Zhao Lv
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="muller24_interspeech.html">
                                <p>
                                    A New Approach to Voice Authenticity
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Nicolas M. MÃ¼ller, Piotr Kawa, Shen Hu, Matthias Neu, Jennifer Williams, Philip Sperl, Konstantin BÃ¶ttinger
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="zhou24b_interspeech.html">
                                <p>
                                    TraceableSpeech: Towards Proactively Traceable Text-to-Speech with Watermarking
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Junzuo Zhou, Jiangyan Yi, Tao Wang, Jianhua Tao, Ye Bai, Chu Yuan Zhang, Yong Ren, Zhengqi Wen
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="liu24g_interspeech.html">
                                <p>
                                    HarmoNet: Partial DeepFake Detection Network based on Multi-scale HarmoF0 Feature Fusion
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Liwei Liu, Huihui Wei, Dongya Liu, Zhonghua Fu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="moussa24_interspeech.html">
                                <p>
                                    Unmasking Neural Codecs: Forensic Identification of AI-compressed Speech
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Denise Moussa, Sandra Bergmann, Christian Riess
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="lin24c_interspeech.html">
                                <p>
                                    SWiBE: A Parameterized Stochastic Diffusion Process for Noise-Robust Bandwidth Expansion
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yin-Tse Lin, Shreya G. Upadhyay, Bo-Hao Su, Chi-Chun Lee
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="lu24_interspeech.html">
                                <p>
                                    MultiStage Speech Bandwidth Extension with Flexible Sampling Rate Control
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Ye-Xin Lu, Yang Ai, Zheng-Yan Sheng, Zhen-Hua Ling
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="li24ea_interspeech.html">
                                <p>
                                    MaskSR: Masked Language Model for Full-band Speech Restoration
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Xu Li, Qirui Wang, Xiaoyu Liu
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Speech Synthesis: Prosody"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Speech Synthesis: Prosody</h4>
                            <hr>
                            <a class="w3-text" href="korotkova24_interspeech.html">
                                <p>
                                    Word-level Text Markup for Prosody Control in Speech Synthesis
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yuliya Korotkova, Ilya Kalinovskiy, Tatiana Vakhrusheva
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="mehta24b_interspeech.html">
                                <p>
                                    Should you use a probabilistic duration model in TTS? Probably! Especially for spontaneous speech
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Shivam Mehta, Harm Lameris, Rajiv Punmiya, Jonas Beskow, Eva Szekely, Gustav Eje Henter
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="eskimez24_interspeech.html">
                                <p>
                                    Total-Duration-Aware Duration Modeling for Text-to-Speech Systems
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Sefik Emre Eskimez, Xiaofei Wang, Manthan Thakker, Chung-Hsien Tsai, Canrun Li, Zhen Xiao, Hemin Yang, Zirun Zhu, Min Tang, Jinyu Li, Sheng Zhao, Naoyuki Kanda
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="maurya24_interspeech.html">
                                <p>
                                    A Human-in-the-Loop Approach to Improving Cross-Text Prosody Transfer
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Himanshu Maurya, Atli Sigurgeirsson
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="jiang24d_interspeech.html">
                                <p>
                                    Towards Expressive Zero-Shot Speech Synthesis with Hierarchical Prosody Modeling
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yuepeng Jiang, Tao Li, Fengyu Yang, Lei Xie, Meng Meng, Yujun Wang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="zhong24c_interspeech.html">
                                <p>
                                    Multi-Modal Automatic Prosody Annotation with Contrastive Pretraining of Speech-Silence and Word-Punctuation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jinzuomu Zhong, Yang Li, Hui Huang, Korin Richmond, Jie Liu, Zhiba Su, Jing Guo, Benlai Tang, Fengjie Zhu
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Accented Speech, Prosodic Features, Dialect, Emotion, Sound Classification"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Accented Speech, Prosodic Features, Dialect, Emotion, Sound Classification</h4>
                            <hr>
                            <a class="w3-text" href="prabhu24b_interspeech.html">
                                <p>
                                    Improving Self-supervised Pre-training using Accent-Specific Codebooks
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Darshan Prabhu, Abhishek Gupta, Omkar Nitsure, Preethi Jyothi, Sriram Ganapathy
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="afonja24_interspeech.html">
                                <p>
                                    Performant ASR Models for Medical Entities in Accented Speech
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Tejumade Afonja, Tobi Olatunji, Sewade Ogun, Naome A. Etori, Abraham Owodunni, Moshood Yekini
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="javed24_interspeech.html">
                                <p>
                                    LAHAJA: A Robust Multi-accent Benchmark for Evaluating Hindi ASR Systems
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Tahir Javed, Janki Nawale, Sakshi Joshi, Eldho George, Kaushal Bhogale, Deovrat Mehendale, Mitesh M. Khapra
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kim24v_interspeech.html">
                                <p>
                                    LearnerVoice: A Dataset of Non-Native English Learnersâ Spontaneous Speech
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Haechan Kim, Junho Myung, Seoyoung Kim, Sungpah Lee, Dongyeop Kang, Juho Kim
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="lin24m_interspeech.html">
                                <p>
                                    MinSpeech: A Corpus of Southern Min Dialect for Automatic Speech Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jiayan Lin, Shenghui Lu, Hukai Huang, Wenhao Guan, Binbin Xu, Hui Bu, Qingyang Hong, Lin Li
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="hu24e_interspeech.html">
                                <p>
                                    Cross-modal Features Interaction-and-Aggregation Network with Self-consistency Training for Speech Emotion Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Ying Hu, Huamin Yang, Hao Huang, Liang He
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="goel24_interspeech.html">
                                <p>
                                    Exploring Multilingual Unseen Speaker Emotion Recognition: Leveraging Co-Attention Cues in Multitask Learning
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Arnav Goel, Medha Hira, Anubha Gupta
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="bukhari24_interspeech.html">
                                <p>
                                    SELM: Enhancing Speech Emotion Recognition for Out-of-Domain Scenarios
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Hazim Bukhari, Soham Deshmukh, Hira Dhamyal, Bhiksha Raj, Rita Singh
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="bentum24_interspeech.html">
                                <p>
                                    The Processing of Stress in End-to-End Automatic Speech Recognition Models
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Martijn Bentum, Louis ten Bosch, Tom Lentz
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="nguyen24b_interspeech.html">
                                <p>
                                    LingWav2Vec2: Linguistic-augmented wav2vec 2.0 for Vietnamese Mispronunciation Detection
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Tuan Nguyen, Huy Dat Tran
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="mogridge24_interspeech.html">
                                <p>
                                    Learning from memory-based models
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Rhiannon Mogridge, Anton Ragni
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="chen24s_interspeech.html">
                                <p>
                                    Towards End-to-End Unified Recognition for Mandarin and Cantonese
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Meiling Chen, Pengjie Liu, Heng Yang, Haofeng Wang
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Neural Network Adaptation"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Neural Network Adaptation</h4>
                            <hr>
                            <a class="w3-text" href="rolland24b_interspeech.html">
                                <p>
                                    Shared-Adapters: A Novel Transformer-based Parameter Efficient Transfer Learning Approach For Childrenâs Automatic Speech Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Thomas Rolland, Alberto Abad
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="huo24_interspeech.html">
                                <p>
                                    AdaRA: Adaptive Rank Allocation of Residual Adapters for Speech Foundation Model
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Zhouyuan Huo, Dongseong Hwang, Gan Song, Khe Chai Sim, Weiran Wang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="shim24_interspeech.html">
                                <p>
                                    Leveraging Adapter for Parameter-Efficient ASR Encoder
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Kyuhong Shim, Jinkyu Lee, Hyunjae Kim
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kang24_interspeech.html">
                                <p>
                                    Whisper Multilingual Downstream Task Tuning Using Task Vectors
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Ji-Hun Kang, Jae-Hong Lee, Mun-Hak Lee, Joon-Hyuk Chang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="li24ka_interspeech.html">
                                <p>
                                    Speaker-Smoothed kNN Speaker Adaptation for End-to-End ASR
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Shaojun Li, Daimeng Wei, Hengchao Shang, Jiaxin Guo, ZongYao Li, Zhanglin Wu, Zhiqiang Rao, Yuanchang Luo, Xianghui He, Hao Yang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="chen24n_interspeech.html">
                                <p>
                                    Qifusion-Net: Layer-adapted Stream/Non-stream Model for End-to-End Multi-Accent Speech Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jinming Chen, Jingyi Fang, Yuanzhong Zheng, Yaoxuan Wang, Haojun Fei
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="ASR and LLMs"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">ASR and LLMs</h4>
                            <hr>
                            <a class="w3-text" href="yoon24_interspeech.html">
                                <p>
                                    HuBERT-EE: Early Exiting HuBERT for Efficient Speech Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Ji Won Yoon, Beom Jun Woo, Nam Soo Kim
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="yang24f_interspeech.html">
                                <p>
                                    MaLa-ASR: Multimedia-Assisted LLM-Based ASR
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Guanrou Yang, Ziyang Ma, Fan Yu, Zhifu Gao, Shiliang Zhang, Xie Chen
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="choi24_interspeech.html">
                                <p>
                                    Spoken-to-written text conversion with Large Language Model
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        HyunJung Choi, Muyeol Choi, Yohan Lim, Minkyu Lee, Seonhui Kim, Seung Yun, Donghyun Kim, SangHun Kim
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="ai24_interspeech.html">
                                <p>
                                    MM-KWS: Multi-modal Prompts for Multilingual User-defined Keyword Spotting
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Zhiqi Ai, Zhiyong Chen, Shugong Xu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="rouditchenko24_interspeech.html">
                                <p>
                                    Whisper-Flamingo: Integrating Visual Features into Whisper for Audio-Visual Speech Recognition and Translation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Andrew Rouditchenko, Yuan Gong, Samuel Thomas, Leonid Karlinsky, Hilde Kuehne, Rogerio Feris, James Glass
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="prajwal24_interspeech.html">
                                <p>
                                    Speech Recognition Models are Strong Lip-readers
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        K R Prajwal, Triantafyllos Afouras, Andrew Zisserman
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Pathological Speech Analysis 3"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Pathological Speech Analysis 3</h4>
                            <hr>
                            <a class="w3-text" href="baumann24b_interspeech.html">
                                <p>
                                    Towards Self-Attention Understanding for Automatic Articulatory Processes Analysis in Cleft Lip and Palate Speech
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Ilja Baumann, Dominik Wagner, Maria Schuster, Korbinian Riedhammer, Elmar Noeth, Tobias Bocklet
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="liu24f_interspeech.html">
                                <p>
                                    Clever Hans Effect Found in Automatic Detection of Alzheimer's Disease through Speech
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yin-Long Liu, Rui Feng, Jia-Hong Yuan, Zhen-Hua Ling
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="lin24k_interspeech.html">
                                <p>
                                    Leveraging Phonemic Transcription and Whisper toward Clinically Significant Indices for Automatic Child Speech Assessment
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yeh-Sheng Lin, Shu-Chuan Tseng, Jyh-Shing Roger Jang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="dang24b_interspeech.html">
                                <p>
                                    Developing vocal system impaired patient-aimed voice quality assessment approach using ASR representation-included multiple features
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Shaoxiang Dang, Tetsuya Matsumoto, Yoshinori Takeuchi, Takashi Tsuboi, Yasuhiro Tanaka, Daisuke Nakatsubo, Satoshi Maesawa, Ryuta Saito, Masahisa Katsuno, Hiroaki Kudo
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="hsu24_interspeech.html">
                                <p>
                                    A Cluster-based Personalized Federated Learning Strategy for End-to-End ASR of Dementia Patients
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Wei-Tung Hsu, Chin-Po Chen, Yun-Shao Lin, Chi-Chun Lee
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kalabakov24_interspeech.html">
                                <p>
                                    A Comparative Analysis of Federated Learning for Speech-Based Cognitive Decline Detection
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Stefan Kalabakov, Monica Gonzalez-Machorro, Florian Eyben, BjÃ¶rn W. Schuller, Bert Arnrich
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="neumann24_interspeech.html">
                                <p>
                                    Multimodal Digital Biomarkers for Longitudinal Tracking of Speech Impairment Severity in ALS: An Investigation of Clinically Important Differences
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Michael Neumann, Hardik Kothare, Jackson Liscombe, Emma C.L. Leschly, Oliver Roesler, Vikram Ramanarayanan
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Speech Disorders 3"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Speech Disorders 3</h4>
                            <hr>
                            <a class="w3-text" href="gao24c_interspeech.html">
                                <p>
                                    Enhancing Voice Wake-Up for Dysarthria: Mandarin Dysarthria Speech Corpus Release and Customized System Design
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Ming Gao, Hang Chen, Jun Du, Xin Xu, Hongxiao Guo, Hui Bu, Jianxing Yang, Ming Li, Chin-Hui Lee
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="shah24_interspeech.html">
                                <p>
                                    Towards Improving NAM-to-Speech Synthesis Intelligibility using Self-Supervised Speech Models
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Neil Shah, Shirish Karande, Vineet Gandhi
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="um24_interspeech.html">
                                <p>
                                    PARAN: Variational Autoencoder-based End-to-End Articulation-to-Speech System for Speech Intelligibility
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Seyun Um, Doyeon Kim, Hong-Goo Kang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="chen24b_interspeech.html">
                                <p>
                                    Acoustic changes in speech prosody produced by children with autism after robot-assisted speech training
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Si Chen, Bruce Xiao Wang, Yitian Hong, Fang Zhou, Angel Chan, Po-yi Tang, Bin Li, Chunyi Wen, James Cheung, Yan Liu, Zhuoming Chen
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="zheng24c_interspeech.html">
                                <p>
                                    Fine-Tuning Automatic Speech Recognition for People with Parkinson's: An Effective Strategy for Enhancing Speech Technology Accessibility
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Xiuwen Zheng, Bornali Phukon, Mark Hasegawa-Johnson
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="jiang24_interspeech.html">
                                <p>
                                    Learnings from curating a trustworthy, well-annotated, and useful dataset of disordered English speech
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Pan-Pan Jiang, Jimmy Tobin, Katrin Tomanek, Robert MacDonald, Katie Seaver, Richard Cave, Marilyn Ladewig, Rus Heywood, Jordan Green
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="leung24_interspeech.html">
                                <p>
                                    Training Data Augmentation for Dysarthric Automatic Speech Recognition by Text-to-Dysarthric-Speech Synthesis
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Wing-Zin Leung, Mattias Cross, Anton Ragni, Stefan Goetze
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="gosztolya24b_interspeech.html">
                                <p>
                                    Wav2vec 2.0 Embeddings Are No Swiss Army Knife -- A Case Study for Multiple Sclerosis
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        GÃ¡bor Gosztolya, Mercedes VetrÃ¡b, Veronika Svindt, Judit BÃ³na, IldikÃ³ Hoffmann
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Speech Recognition with Large Pretrained Speech Models for Under-represented Languages (Special Session)"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Speech Recognition with Large Pretrained Speech Models for Under-represented Languages (Special Session)</h4>
                            <hr>
                            <a class="w3-text" href="shih24_interspeech.html">
                                <p>
                                    Interface Design for Self-Supervised Speech Models
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yi-Jen Shih, David Harwath
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="xu24d_interspeech.html">
                                <p>
                                    Comparing Discrete and Continuous Space LLMs for Speech Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yaoxun Xu, Shi-Xiong Zhang, Jianwei Yu, Zhiyong Wu, Dong Yu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="li24ia_interspeech.html">
                                <p>
                                    Improving Whisper's Recognition Performance for Under-Represented Language Kazakh Leveraging Unpaired Speech and Text
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jinpeng Li, Yu Pu, Qi Sun, Wei-Qiang Zhang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="bhogale24_interspeech.html">
                                <p>
                                    Empowering Low-Resource Language ASR via Large-Scale Pseudo Labeling
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Kaushal Santosh Bhogale, Deovrat Mehendale, Niharika Parasa, Sathish Kumar Reddy G, Tahir Javed, Pratyush Kumar, Mitesh M. Khapra
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="li24i_interspeech.html">
                                <p>
                                    Interleaved Audio/Audiovisual Transfer Learning for AV-ASR in Low-Resourced Languages
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Zhengyang Li, Patrick Blumenberg, Jing Liu, Thomas Graave, Timo Lohrenz, Siegfried Kunzmann, Tim Fingscheidt
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="udupa24_interspeech.html">
                                <p>
                                    Adapter pre-training for improved speech recognition in unseen domains using low resource adapter tuning of self-supervised models
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Sathvik Udupa, Jesuraj Bandekar, Saurabh Kumar, Deekshitha G, Sandhya B, Abhayjeet S, Savitha Murthy, Priyanka Pai, Srinivasa Raghavan, Raoul Nanavati, Prasanta Kumar Ghosh
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="xu24h_interspeech.html">
                                <p>
                                    Towards Rehearsal-Free Multilingual ASR: A LoRA-based Case Study on Whisper 
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Tianyi Xu, Kaixun Huang, Pengcheng Guo, Yu Zhou, Longtao Huang, Hui Xue, Lei Xie
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="getman24b_interspeech.html">
                                <p>
                                    Exploring adaptation techniques of large speech foundation models for low-resource ASR: a case study on Northern SÃ¡mi
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yaroslav Getman, Tamas Grosz, Katri Hiovain-Asikainen, Mikko Kurimo
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="qian24_interspeech.html">
                                <p>
                                    Learn and Don't Forget: Adding a New Language to ASR Foundation Models
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Mengjie Qian, Siyuan Tang, Rao Ma, Kate M. Knill, Mark J.F. Gales
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Speech Processing Using Discrete Speech Units (Special Session)"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Speech Processing Using Discrete Speech Units (Special Session)</h4>
                            <hr>
                            <a class="w3-text" href="wu24q_interspeech.html">
                                <p>
                                    TokSing: Singing Voice Synthesis based on Discrete Tokens
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yuning Wu, Chunlei Zhang, Jiatong Shi, Yuxun Tang, Shan Yang, Qin Jin
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="mousavi24_interspeech.html">
                                <p>
                                    How Should We Extract Discrete Audio Tokens from Self-Supervised Models?
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Pooneh Mousavi, Jarod Duret, Salah Zaiem, Luca Della Libera, Artem Ploujnikov, Cem Subakan, Mirco Ravanelli
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="chang24b_interspeech.html">
                                <p>
                                    The Interspeech 2024 Challenge on Speech Processing Using Discrete Units
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Xuankai Chang, Jiatong Shi, Jinchuan Tian, Yuning Wu, Yuxun Tang, Yihan Wu, Shinji Watanabe, Yossi Adi, Xie Chen, Qin Jin
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="tang24c_interspeech.html">
                                <p>
                                    SingOMD: Singing Oriented Multi-resolution Discrete Representation Construction from Speech Models
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yuxun Tang, Yuning Wu, Jiatong Shi, Qin Jin
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="shi24h_interspeech.html">
                                <p>
                                    MMM: Multi-Layer Multi-Residual Multi-Stream Discrete Speech Representation from Self-supervised Learning Model
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jiatong Shi, Xutai Ma, Hirofumi Inaguma, Anna Sun, Shinji Watanabe
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="dhawan24_interspeech.html">
                                <p>
                                    Codec-ASR: Training Performant Automatic Speech Recognition Systems with Discrete Speech Representations
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Kunal Dhawan, Nithin Rao Koluguri, Ante JukiÄ, Ryan Langman, Jagadeesh Balam, Boris Ginsburg
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Keynote 3"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Keynote 3</h4>
                            <hr>
                            <a class="w3-text" href="noeth24_interspeech.html">
                                <p>
                                    Analysis of Pathological Speech â Pitfalls along the Way
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Elmar Noeth
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Databases and Progress in Methodology"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Databases and Progress in Methodology</h4>
                            <hr>
                            <a class="w3-text" href="ahn24b_interspeech.html">
                                <p>
                                    VoxSim: A perceptual voice similarity dataset
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Junseok Ahn, Youkyum Kim, Yeunju Choi, Doyeop Kwak, Ji-Hoon Kim, Seongkyu Mun, Joon Son Chung
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="nijat24_interspeech.html">
                                <p>
                                    UY/CH-CHILD -- A Public Chinese L2 Speech Database of Uyghur Children
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Mewlude Nijat, Chen Chen, Dong Wang, Askar Hamdulla
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kumar24b_interspeech.html">
                                <p>
                                    State-of-the-art speech production MRI protocol for new 0.55 Tesla scanners
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Prakash Kumar, Ye Tian, Yongwan Lim, Sophia X. Cui, Christina Hagedorn, Dani Byrd, Uttam K. Sinha, Shrikanth Narayanan, Krishna S. Nayak
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="shi24c_interspeech.html">
                                <p>
                                    DBD-CI: Doubling the Band Density for Bilateral Cochlear Implants
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Mingyue Shi, Huali Zhou, Qinglin Meng, Nengheng Zheng
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="zhong24b_interspeech.html">
                                <p>
                                    Leveraging Large Language Models to Refine Automatic Feedback Generation at Articulatory Level in Computer Aided Pronunciation Training
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Huihang Zhong, Yanlu Xie, ZiJin Yao
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="zhao24e_interspeech.html">
                                <p>
                                    Decoding Human Language Acquisition: EEG Evidence for Predictive Probabilistic Statistics in Word Segmentation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Bin Zhao, Mingxuan Huang, Chenlu Ma, Jinyi Xue, Aijun Li, Kunyu Xu
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Articulation, Convergence and Perception"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Articulation, Convergence and Perception</h4>
                            <hr>
                            <a class="w3-text" href="giroud24_interspeech.html">
                                <p>
                                    Behavioral evidence for higher speech rate convergence following natural than artificial time altered speech
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        JÃ©rÃ©my Giroud, Jessica Lei, Kirsty Phillips, Matthew H. Davis
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="shen24c_interspeech.html">
                                <p>
                                    A novel experimental design for the study of listener-to-listener convergence in phoneme categorization
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Qingye Shen, Leonardo Lancia, Noel Nguyen
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="li24ga_interspeech.html">
                                <p>
                                    Cross-Attention-Guided WaveNet for EEG-to-MEL Spectrogram Reconstruction
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Hao Li, Yuan Fang, Xueliang Zhang, Fei Chen, Guanglai Gao
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="loddo24_interspeech.html">
                                <p>
                                    What if HAL breathed? Enhancing Empathy in Human-AI Interactions with Breathing Speech Synthesis
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        NicolÃ² Loddo, Francisca Pessanha, Almila Akdag
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="svenssonlundmark24_interspeech.html">
                                <p>
                                    Magnitude and timing of acceleration peaks in stressed and unstressed syllables
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Malin Svensson Lundmark
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Speech Emotion Recognition"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Speech Emotion Recognition</h4>
                            <hr>
                            <a class="w3-text" href="amiriparian24_interspeech.html">
                                <p>
                                    ExHuBERT: Enhancing HuBERT Through Block Extension and Fine-Tuning on 37 Emotion Datasets
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Shahin Amiriparian, Filip PackaÅ, Maurice Gerczuk, BjÃ¶rn W. Schuller
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="rittergutierrez24_interspeech.html">
                                <p>
                                    Dataset-Distillation Generative Model for Speech Emotion Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Fabian Ritter-Gutierrez, Kuan-Po Huang, Jeremy H. M. Wong, Dianwen Ng, Hung-yi Lee, Nancy F. Chen, Eng-Siong Chng
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="mai24_interspeech.html">
                                <p>
                                    DropFormer: A Dynamic Noise-Dropping Transformer for Speech Emotion Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jialong Mai, Xiaofen Xing, Weidong Chen, Xiangmin Xu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="niu24d_interspeech.html">
                                <p>
                                    From Text to Emotion: Unveiling the Emotion Annotation Capabilities of LLMs
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Minxue Niu, Mimansa Jaiswal, Emily Mower Provost
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Self-Supervised Models in Speaker Recognition"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Self-Supervised Models in Speaker Recognition</h4>
                            <hr>
                            <a class="w3-text" href="kim24c_interspeech.html">
                                <p>
                                    Self-supervised speaker verification with relational mask prediction
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Ju-ho Kim, Hee-Soo Heo, Bong-Jin Lee, Youngki Kwon, Minjae Lee, Ha-Jin Yu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="miara24_interspeech.html">
                                <p>
                                    Towards Supervised Performance on Speaker Verification with Self-Supervised Learning by Leveraging Large-Scale ASR Models
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Victor Miara, Theo Lepage, Reda Dehak
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="lim24_interspeech.html">
                                <p>
                                    Improving Noise Robustness in Self-supervised Pre-trained Model for Speaker Verification
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Chan-yeong Lim, Hyun-seo Shin, Ju-ho Kim, Jungwoo Heo, Kyo-Won Koo, Seung-bin Kim, Ha-Jin Yu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="fathan24_interspeech.html">
                                <p>
                                    On the impact of several regularization techniques on label noise robustness of self-supervised speaker verification systems
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Abderrahim Fathan, Xiaolin Zhu, Jahangir Alam
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="li24e_interspeech.html">
                                <p>
                                    Parameter-efficient Fine-tuning of Speaker-Aware Dynamic Prompts for Speaker Verification
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Zhe Li, Man-wai Mak, Hung-yi Lee, Helen Meng
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="zhao24f_interspeech.html">
                                <p>
                                    Whisper-PMFA: Partial Multi-Scale Feature Aggregation for Speaker Verification using Whisper Models
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yiyang Zhao, Shuai Wang, Guangzhi Sun, Zehua Chen, Chao Zhang, Mingxing Xu, Thomas Fang Zheng
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Speech Quality Assessment"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Speech Quality Assessment</h4>
                            <hr>
                            <a class="w3-text" href="hu24d_interspeech.html">
                                <p>
                                    Embedding Learning for Preference-based Speech Quality Assessment
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        ChengHung Hu, Yusuke Yasuda, Tomoki Toda
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="udupa24b_interspeech.html">
                                <p>
                                    IndicMOS: Multilingual MOS Prediction for 7 Indian languages
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Sathvik Udupa, Soumi Maiti, Prasanta Kumar Ghosh
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="wells24_interspeech.html">
                                <p>
                                    Experimental evaluation of MOS, AB and BWS listening test designs
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Dan Wells, Andrea Lorena Aldana Blanco, Cassia Valentini, Erica Cooper, Aidan Pine, Junichi Yamagishi, Korin Richmond
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="ta24_interspeech.html">
                                <p>
                                    Enhancing No-Reference Speech Quality Assessment with Pairwise, Triplet Ranking Losses, and ASR Pretraining
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Bao Thang Ta, Minh Tu Le, Van Hai Do, Huynh Thi Thanh Binh
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Privacy and Security in Speech Communication 1"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Privacy and Security in Speech Communication 1</h4>
                            <hr>
                            <a class="w3-text" href="muller24b_interspeech.html">
                                <p>
                                    Harder or Different? Understanding Generalization of Audio Deepfake Detection
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Nicolas M. MÃ¼ller, Nicholas Evans, Hemlata Tak, Philip Sperl, Konstantin BÃ¶ttinger
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="oiso24_interspeech.html">
                                <p>
                                    Prompt Tuning for Audio Deepfake Detection: Computationally Efficient Test-time Domain Adaptation with Limited Target Dataset
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Hideyuki Oiso, Yuto Matsunaga, Kazuya Kakizaki, Taiki Miyagawa
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="looney24_interspeech.html">
                                <p>
                                    Robust spread spectrum speech watermarking using linear prediction and deep spectral shaping
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        David Looney, Nikolay D. Gaubitch
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="chen24k_interspeech.html">
                                <p>
                                    RawBMamba: End-to-End Bidirectional State Space Model for Audio Deepfake Detection
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yujie Chen, Jiangyan Yi, Jun Xue, Chenglong Wang, Xiaohui Zhang, Shunbo Dong, Siding Zeng, Jianhua Tao, Zhao Lv, Cunhang Fan
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="liu24i_interspeech.html">
                                <p>
                                    How Private is Low-Frequency Speech Audio in the Wild? An Analysis of Verbal Intelligibility by Humans and Machines
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Ailin Liu, Pepijn Vunderink, Jose Vargas Quiros, Chirag Raman, Hayley Hung
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="yang24e_interspeech.html">
                                <p>
                                    RW-VoiceShield: Raw Waveform-based Adversarial Attack on One-shot Voice Conversion
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Ching-Yu Yang, Shreya G. Upadhyay, Ya-Tse Wu, Bo-Hao Su, Chi-Chun Lee
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Speech Synthesis: Voice Conversion 2"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Speech Synthesis: Voice Conversion 2</h4>
                            <hr>
                            <a class="w3-text" href="gusev24_interspeech.html">
                                <p>
                                    Improvement Speaker Similarity for Zero-Shot Any-to-Any Voice Conversion of Whispered and Regular Speech
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Aleksei Gusev, Anastasia Avdeeva
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="um24b_interspeech.html">
                                <p>
                                    Utilizing Adaptive Global Response Normalization and Cluster-Based Pseudo Labels for Zero-Shot Voice Conversion
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Ji Sub Um, Hoirin Kim
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="ma24e_interspeech.html">
                                <p>
                                    Vec-Tok-VC+: Residual-enhanced Robust Zero-shot Voice Conversion with Progressive Constraints in a Dual-mode Training Strategy
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Linhan Ma, Xinfa Zhu, Yuanjun Lv, Zhichao Wang, Ziqian Wang, Wendi He, Hongbin Zhou, Lei Xie
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="igarashi24_interspeech.html">
                                <p>
                                    Noise-Robust Voice Conversion by Conditional Denoising Training Using Latent Variables of Recording Quality and Environment
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Takuto Igarashi, Yuki Saito, Kentaro Seki, Shinnosuke Takamichi, Ryuichi Yamamoto, Kentaro Tachibana, Hiroshi Saruwatari
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kanagawa24_interspeech.html">
                                <p>
                                    Pre-training Neural Transducer-based Streaming Voice Conversion for Faster Convergence and Alignment-free Training
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Hiroki Kanagawa, Takafumi Moriya, Yusuke Ijima
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="xu24b_interspeech.html">
                                <p>
                                    Residual Speaker Representation for One-Shot Voice Conversion
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Le Xu, Jiangyan Yi, Tao Wang, Yong Ren, Rongxiu Zhong, Zhengqi Wen, Jianhua Tao
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="gengembre24_interspeech.html">
                                <p>
                                    Disentangling prosody and timbre embeddings via voice conversion
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Nicolas Gengembre, Olivier Le Blouch, CÃ©dric Gendrot
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="chen24e_interspeech.html">
                                <p>
                                    LDM-SVC: Latent Diffusion Model Based Zero-Shot Any-to-Any Singing Voice Conversion with Singer Guidance
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Shihao Chen, Yu Gu, Jie Zhang, Na Li, Rilin Chen, Liping Chen, Lirong Dai
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Speech Synthesis: Text Processing"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Speech Synthesis: Text Processing</h4>
                            <hr>
                            <a class="w3-text" href="roth24_interspeech.html">
                                <p>
                                    A Language Modeling Approach to Diacritic-Free Hebrew TTS
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Amit Roth, Arnon Turetzky, Yossi Adi
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="dekel24_interspeech.html">
                                <p>
                                    Exploring the Benefits of Tokenization of Discrete Acoustic Units
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Avihu Dekel, Raul Fernandez
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="rezackova24_interspeech.html">
                                <p>
                                    Homograph Disambiguation with Text-to-Text Transfer Transformer
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        MarkÃ©ta ÅezÃ¡ÄkovÃ¡, Daniel Tihelka, JindÅich MatouÅ¡ek
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kurihara24_interspeech.html">
                                <p>
                                    Enhancing Japanese Text-to-Speech Accuracy with a Novel Combination Transformer-BERT-based G2P: Integrating Pronunciation Dictionaries and Accent Sandhi
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Kiyoshi Kurihara, Masanori Sano
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="shirahata24_interspeech.html">
                                <p>
                                    Audio-conditioned phonemic and prosodic annotation for building text-to-speech models from unlabeled speech data
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yuma Shirahata, Byeongseon Park, Ryuichi Yamamoto, Kentaro Tachibana
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="yang24_interspeech.html">
                                <p>
                                    G2PA: G2P with Aligned Audio for Mandarin Chinese
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Xingxing Yang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="sun24_interspeech.html">
                                <p>
                                    Learning Pronunciation from Other Accents via Pronunciation Knowledge Transfer
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Siqi Sun, Korin Richmond
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="gupta24d_interspeech.html">
                                <p>
                                    Positional Description for Numerical Normalization 
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Deepanshu Gupta, Javier Latorre
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="tannander24_interspeech.html">
                                <p>
                                    Beyond graphemes and phonemes: continuous phonological features in neural text-to-speech synthesis
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Christina TÃ¥nnander, Shivam Mehta, Jonas Beskow, Jens Edlund
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Training Methods, Self-Supervised Learning, Adaptation"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Training Methods, Self-Supervised Learning, Adaptation</h4>
                            <hr>
                            <a class="w3-text" href="fernandezlopez24_interspeech.html">
                                <p>
                                    MSRS: Training Multimodal Speech Recognition Models from Scratch with Sparse Mask Optimization
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Adriana Fernandez-Lopez, Honglie Chen, Pingchuan Ma, Lu Yin, Qiao Xiao, Stavros Petridis, Shiwei Liu, Maja Pantic
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="prasad24_interspeech.html">
                                <p>
                                    Speech and Language Recognition with Low-rank Adaptation of Pretrained Models
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Amrutha Prasad, Srikanth Madikeri, Driss Khalil, Petr Motlicek, Christof Schuepbach
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kim24s_interspeech.html">
                                <p>
                                    Convolution-Augmented Parameter-Efficient Fine-Tuning for Speech Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Kwangyoun Kim, Suwon Shon, Yi-Te Hsu, Prashant Sridhar, Karen Livescu, Shinji Watanabe
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="meghanani24_interspeech.html">
                                <p>
                                    LASER: Learning by Aligning Self-supervised Representations of Speech for Improving Content-related Tasks
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Amit Meghanani, Thomas Hain
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="flynn24_interspeech.html">
                                <p>
                                    Self-Train Before You Transcribe
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Robert Flynn, Anton Ragni
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="vandereeckt24_interspeech.html">
                                <p>
                                    Unsupervised Online Continual Learning for Automatic Speech Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Steven Vander Eeckt, Hugo Van hamme
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="shi24b_interspeech.html">
                                <p>
                                    Dual-path Adaptation of Pretrained Feature Extraction Module for Robust Automatic Speech Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Hao Shi, Tatsuya Kawahara
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kusunoki24_interspeech.html">
                                <p>
                                    Hierarchical Multi-Task Learning with CTC and Recursive Operation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Nahomi Kusunoki, Yosuke Higuchi, Tetsuji Ogawa, Tetsunori Kobayashi
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="hojo24_interspeech.html">
                                <p>
                                    Boosting CTC-based ASR using inter-layer attention-based CTC loss
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Keigo Hojo, Yukoh Wakabayashi, Kengo Ohta, Atsunori Ogawa, Norihide Kitaoka
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kim24t_interspeech.html">
                                <p>
                                    Self-training ASR Guided by Unsupervised ASR Teacher
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Hyung Yong Kim, Byeong-Yeol Kim, Yunkyu Lim, Jihwan Park, Shukjae Choi, Yooncheol Ju, Jinseok Park, Youshin Lim, Seung Woo Yu, Hanbin Lee, Shinji Watanabe
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="gu24b_interspeech.html">
                                <p>
                                    Personality-memory Gated Adaptation: An Efficient Speaker Adaptation for Personalized End-to-end Automatic Speech Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yue Gu, Zhihao Du, Shiliang Zhang, jiqing Han, Yongjun He
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="joseph24_interspeech.html">
                                <p>
                                    Speaker Personalization for Automatic Speech Recognition using Weight-Decomposed Low-Rank Adaptation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        George Joseph, Arun Baby
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="lee24j_interspeech.html">
                                <p>
                                    Online Subloop Search via Uncertainty Quantization for Efficient Test-Time Adaptation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jae-Hong Lee, Sang-Eon Lee, Dong-Hyun Kim, DoHee Kim, Joon-Hyuk Chang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="singh24c_interspeech.html">
                                <p>
                                    ROAR: Reinforcing Original to Augmented Data Ratio Dynamics for Wav2vec2.0 Based ASR
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Vishwanath Pratap Singh, Federico Malato, Ville HautamÃ¤ki, Md. Sahidullah, Tomi Kinnunen
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="lee24b_interspeech.html">
                                <p>
                                    Online Knowledge Distillation of Decoder-Only Large Language Models for Efficient Speech Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jeehye Lee, Hyeji Seo
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Novel Architectures for ASR"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Novel Architectures for ASR</h4>
                            <hr>
                            <a class="w3-text" href="honda24_interspeech.html">
                                <p>
                                    Efficient and Robust Long-Form Speech Recognition with Hybrid H3-Conformer
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Tomoki Honda, Shinsuke Sakai, Tatsuya Kawahara
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kashiwagi24_interspeech.html">
                                <p>
                                    Rapid Language Adaptation for Multilingual E2E Speech Recognition Using Encoder Prompting
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yosuke Kashiwagi, Hayato Futami, Emiru Tsunoo, Siddhant Arora, Shinji Watanabe
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="shejwalkar24_interspeech.html">
                                <p>
                                    Quantifying Unintended Memorization in BEST-RQ ASR Encoders
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Virat Shejwalkar, Om Thakkar, Arun Narayanan
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kang24b_interspeech.html">
                                <p>
                                    SWAN: SubWord Alignment Network for HMM-free word timing estimation in end-to-end automatic speech recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Woo Hyun Kang, Srikanth Vishnubhotla, Rudolf Braun, Yogesh Virkar, Raghuveer Peri, Kyu J. Han
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Multimodality and Foundation Models"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Multimodality and Foundation Models</h4>
                            <hr>
                            <a class="w3-text" href="cui24_interspeech.html">
                                <p>
                                    Spontaneous Speech-Based Suicide Risk Detection Using Whisper and Large Language Models
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Ziyun Cui, Chang Lei, Wen Wu, Yinan Duan, Diyang Qu, Ji Wu, Runsen Chen, Chao Zhang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="sayeed24_interspeech.html">
                                <p>
                                    Spoken Word2Vec: Learning Skipgram Embeddings from Speech
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Mohammad Amaan Sayeed, Hanan Aldarmaki
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="bujnowski24_interspeech.html">
                                <p>
                                    SAMSEMO: New dataset for multilingual and multimodal emotion recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Pawel Bujnowski, Bartlomiej Kuzma, Bartlomiej Paziewski, Jacek Rutkowski, Joanna Marhula, Zuzanna Bordzicka, Piotr Andruszkiewicz
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="jia24_interspeech.html">
                                <p>
                                    LLM-Driven Multimodal Opinion Expression Identification
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Bonian Jia, Huiyao Chen, Yueheng Sun, Meishan Zhang, Min Zhang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="li24ta_interspeech.html">
                                <p>
                                    Zero-Shot Fake Video Detection by Audio-Visual Consistency
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Xiaolou Li, Zehua Liu, Chen Chen, Lantian Li, Li Guo, Dong Wang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="eungi24_interspeech.html">
                                <p>
                                    Enhancing Speech-Driven 3D Facial Animation with Audio-Visual Guidance from Lip Reading Expert
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Han EunGi, Oh Hyun-Bin, Kim Sung-Bin, Corentin Nivelet Etcheberry, Suekyeong Nam, Janghoon Ju, Tae-Hyun Oh
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Spoken Dialogue Systems and Conversational Analysis 1"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Spoken Dialogue Systems and Conversational Analysis 1</h4>
                            <hr>
                            <a class="w3-text" href="mcneill24_interspeech.html">
                                <p>
                                    Autoregressive cross-interlocutor attention scores meaningfully capture conversational dynamics
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Matthew McNeill, Rivka Levitan
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="atkins24_interspeech.html">
                                <p>
                                    ConvoCache: Smart Re-Use of Chatbot Responses
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Conor Atkins, Ian Wood, Mohamed Ali Kaafar, Hassan Asghar, Nardine Basta, Michal Kepkowski
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="qian24b_interspeech.html">
                                <p>
                                    Joint Learning of Context and Feedback Embeddings in Spoken Dialogue
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Livia Qian, Gabriel Skantze
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="sahipjohn24_interspeech.html">
                                <p>
                                    DubWise: Video-Guided Speech Duration Control in Multimodal LLM-based Text-to-Speech for Dubbing
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Neha Sahipjohn, Ashishkumar Gudmalwar, Nirmesh Shah, Pankaj Wasnik, Rajiv Ratn Shah
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="wang24t_interspeech.html">
                                <p>
                                    Contextual Interactive Evaluation of TTS Models in Dialogue Systems
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Siyang Wang, Ãva SzÃ©kely, Joakim Gustafson
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="shih24b_interspeech.html">
                                <p>
                                    GSQA: An End-to-End Model for Generative Spoken Question Answering
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Min-Han Shih, Ho-Lam Chung, Yu-Chi Pai, Ming-Hao Hsu, Guan-Ting Lin, Shang-Wen Li, Hung-yi Lee
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Speech Technology"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Speech Technology</h4>
                            <hr>
                            <a class="w3-text" href="nilsson24_interspeech.html">
                                <p>
                                    Resource-Efficient Speech Quality Prediction through Quantization Aware Training and Binary Activation Maps
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Mattias Nilsson, Riccardo Miccini, Clement Laroche, Tobias Piechowiak, Friedemann Zenke
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="naderi24_interspeech.html">
                                <p>
                                    Towards interfacing large language models with ASR systems using confidence measures and prompting
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Maryam Naderi, Enno Hermann, Alexandre Nanchen, Sevada Hovsepyan, Mathew Magimai.-Doss
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="meng24d_interspeech.html">
                                <p>
                                    Text Injection for Neural Contextual Biasing
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Zhong Meng, Zelin Wu, Rohit Prabhavalkar, Cal Peyser, Weiran Wang, Nanxin Chen, Tara N. Sainath, Bhuvana Ramabhadran
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="wu24l_interspeech.html">
                                <p>
                                    Prompting Large Language Models with Mispronunciation Detection and Diagnosis Abilities
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Minglin Wu, Jing Xu, Xixin Wu, Helen Meng
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="sun24d_interspeech.html">
                                <p>
                                    Acceleration of Posteriorgram-based DTW by Distilling the Class-to-class Distances Encoded in the Classifier Used to Calculate Posteriors
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Haitong Sun, Jaehyun Choi, Nobuaki Minematsu, Daisuke Saito
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="gudmalwar24_interspeech.html">
                                <p>
                                    VECL-TTS: Voice identity and Emotional style controllable Cross-Lingual Text-to-Speech
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Ashishkumar Gudmalwar, Nirmesh Shah, Sai Akarsh, Pankaj Wasnik, Rajiv Ratn Shah
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="wu24g_interspeech.html">
                                <p>
                                    Transferable speech-to-text large language model alignment module
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Boyong Wu, Chao Yan, Haoran Pu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="svirsky24_interspeech.html">
                                <p>
                                    Sparse Binarization for Fast Keyword Spotting
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jonathan Svirsky, Uri Shaham, Ofir Lindenbaum
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Pathological Speech Analysis 2"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Pathological Speech Analysis 2</h4>
                            <hr>
                            <a class="w3-text" href="halpern24_interspeech.html">
                                <p>
                                    Quantifying the effect of speech pathology on automatic and human speaker verification
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Bence Mark Halpern, Thomas Tienkamp, Wen-Chin Huang, Lester Phillip Violeta, Teja Rebernik, Sebastiaan de Visscher, Max Witjes, Martijn Wieling, Defne Abur, Tomoki Toda
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="maji24_interspeech.html">
                                <p>
                                    Investigation of Layer-Wise Speech Representations in Self-Supervised Learning Models: A Cross-Lingual Study in Detecting Depression
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Bubai Maji, Rajlakshmi Guha, Aurobinda Routray, Shazia Nasreen, Debabrata Majumdar
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="talkar24_interspeech.html">
                                <p>
                                    Detection of Cognitive Impairment And Alzheimer's Disease Using a Speech- and Language-Based Protocol
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Tanya Talkar, Sherman Charles, Chelsea Krantsevich, Kan Kawabata
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="lin24l_interspeech.html">
                                <p>
                                    Analyzing Multimodal Features of Spontaneous Voice Assistant Commands for Mild Cognitive Impairment Detection
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Nana Lin, Youxiang Zhu, Xiaohui Liang, John A. Batsis, Caroline Summerour
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="woszczyk24_interspeech.html">
                                <p>
                                    Prosody-Driven Privacy-Preserving Dementia Detection
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Dominika Woszczyk, Ranya Aloufi, Soteris Demetriou
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="koudounas24_interspeech.html">
                                <p>
                                    Voice Disorder Analysis: a Transformer-based Approach
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Alkis Koudounas, Gabriele Ciravegna, Marco Fantini, Erika Crosetti, Giovanni Succo, Tania Cerquitelli, Elena Baralis
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Speech Science, Speech Technology, and Gender (Special Session)"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Speech Science, Speech Technology, and Gender (Special Session)</h4>
                            <hr>
                            <a class="w3-text" href="schubert24_interspeech.html">
                                <p>
                                    Challenges of German Speech Recognition: A Study on Multi-ethnolectal Speech Among Adolescents
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Martha Schubert, Daniel Duran, Ingo Siegert
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="sigurgeirsson24_interspeech.html">
                                <p>
                                    Just Because We Camp, Doesn't Mean We Should: The Ethics of Modelling Queer Voices.
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Atli Sigurgeirsson, Eddie L. Ungless
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="pelloin24_interspeech.html">
                                <p>
                                    Automatic Classification of News Subjects in Broadcast News: Application to a Gender Bias Representation Analysis
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Valentin Pelloin, LÃ©na Dodson, Ãmile Chapuis, Nicolas HervÃ©, David Doukhan
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="doukhan24_interspeech.html">
                                <p>
                                    Gender Representation in TV and Radio: Automatic Information Extraction methods versus Manual Analyses
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        David Doukhan, Lena Dodson, Manon Conan, Valentin Pelloin, AurÃ©lien Clamouse, MÃ©lina Lepape, GÃ©raldine Van Hille, CÃ©cile MÃ©adel, MarlÃ¨ne Coulomb-Gully
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="hughes24_interspeech.html">
                                <p>
                                    Acoustic Effects of Facial Feminisation Surgery on Speech and Singing: A Case Study
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Cliodhna Hughes, Guy Brown, Ning Ma, Nicola Dibben
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="szekely24_interspeech.html">
                                <p>
                                    An inclusive approach to creating a palette of synthetic voices for gender diversity
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Eva Szekely, Maxwell Hope
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="netzorg24_interspeech.html">
                                <p>
                                    Speech After Gender: A Trans-Feminine Perspective on Next Steps for Speech Science and Technology
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Robin Netzorg, Alyssa Cote, Sumi Koshin, Klo Vivienne Garoute, Gopala Krishna Anumanchipalli
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="lai24_interspeech.html">
                                <p>
                                    Voice Quality Variation in AAE: An Additional Challenge for Addressing Bias in ASR Models?
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Li-Fang Lai, Nicole Holliday
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="elie24b_interspeech.html">
                                <p>
                                    Articulatory Configurations across Genders and Periods in French Radio and TV archives
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Benjamin Elie, David Doukhan, RÃ©mi Uro, Lucas Ondel-Yang, Albert Rilliard, Simon Devauchelle
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="krishnan24_interspeech.html">
                                <p>
                                    On the Encoding of Gender in Transformer-based ASR Representations
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Aravind Krishnan, Badr M. Abdullah, Dietrich Klakow
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Speech Production and Perception"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Speech Production and Perception</h4>
                            <hr>
                            <a class="w3-text" href="fan24c_interspeech.html">
                                <p>
                                    Towards a Quantitative Analysis of Coarticulation with a Phoneme-to-Articulatory Model
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Chaofei Fan, Jaimie M. Henderson, Chris Manning, Francis R. Willett
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="sharma24_interspeech.html">
                                <p>
                                    A comparative study of the impact of voiceless alveolar and palato-alveolar sibilants in English on lip aperture and protrusion during VCV production
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Chetan Sharma, Vaishnavi Chandwanshi, Prasanta Kumar Ghosh
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="birkholz24_interspeech.html">
                                <p>
                                    Measurement and simulation of pressure losses due to airflow in vocal tract models
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Peter Birkholz, Patrick HÃ¤sner
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="fang24_interspeech.html">
                                <p>
                                    On The Performance of EMA-synchronized Speech and Stand-alone Speech in Acoustic-to-articulatory Inversion
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Qiang Fang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="freixes24_interspeech.html">
                                <p>
                                    Glottal inverse filtering and vocal tract tuning for the numerical simulation of vowel /a/ with different levels of vocal effort
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Marc Freixes, Marc Arnela, Joan Claudi SocorÃ³, Luis Joglar-Ongay, Oriol Guasch, Francesc AlÃ­as-Pujol
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="friedrichs24_interspeech.html">
                                <p>
                                    Temporal Co-Registration of Simultaneous Electromagnetic Articulography and Electroencephalography for Precise Articulatory and Neural Data Alignment
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Daniel Friedrichs, Monica Lancheros, Sam Kirkham, Lei He, Andrew Clark, Clemens Lutz, Volker Dellwo, Steven Moran
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Phonetics and Phonology: Segmentals and Suprasegmentals"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Phonetics and Phonology: Segmentals and Suprasegmentals</h4>
                            <hr>
                            <a class="w3-text" href="miodonska24_interspeech.html">
                                <p>
                                    Frication noise features of Polish voiceless dental fricative and affricate produced by children with and without speech disorder
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Zuzanna Miodonska, Michal KrÄcichwost, Ewa KwaÅniok, Agata Sage, Pawel Badura
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="hu24_interspeech.html">
                                <p>
                                    Key Acoustic Cues for the Realization of Metrical Prominence in Tone Languages: A Cross-Dialect Study
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yiying Hu, Hui Feng
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="watkins24_interspeech.html">
                                <p>
                                    Revisiting Pitch Jumps: F0 Ratio in Seoul Korean
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Michaela Watkins, Paul Boersma, Silke Hamann
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="maselli24_interspeech.html">
                                <p>
                                    Aerodynamics of Sakata labial-velar oral stops
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Lorenzo Maselli, VÃ©ronique Delvaux
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="erickson24_interspeech.html">
                                <p>
                                    Collecting Mandible Movement in Brazilian Portuguese
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Donna Erickson, Albert Rilliard, Malin Svensson Lundmark, Adelaide Silva, Leticia Rebollo Couto, Oliver Niebuhr, JoÃ£o Antonio de Moraes
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="chan24_interspeech.html">
                                <p>
                                    Pitch-driven adjustments in tongue positions: Insights from ultrasound imaging
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        May Pik Yu Chan, Jianjing Kuang
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Topics in Paralinguistics"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Topics in Paralinguistics</h4>
                            <hr>
                            <a class="w3-text" href="bn24_interspeech.html">
                                <p>
                                    Speaking of Health: Leveraging Large Language Models to assess Exercise Motivation and Behavior of Rehabilitation Patients
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Suhas BN, Amanda Rebar, Saeed Abdullah
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="wu24e_interspeech.html">
                                <p>
                                    Confidence Estimation for Automatic Detection of Depression and Alzheimerâs Disease Based on Clinical Interviews
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Wen Wu, Chao Zhang, Philip C. Woodland
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="suda24_interspeech.html">
                                <p>
                                    Who Finds This Voice Attractive? A Large-Scale Experiment Using In-the-Wild Data
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Hitoshi Suda, Aya Watanabe, Shinnosuke Takamichi
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="setoguchi24_interspeech.html">
                                <p>
                                    Acoustical analysis of the initial phones in speech-laugh
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Ryo Setoguchi, Yoshiko Arimoto
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="hao24_interspeech.html">
                                <p>
                                    On Calibration of Speech Classification Models: Insights from Energy-Based Model Investigations
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yaqian Hao, Chenguang Hu, Yingying Gao, Shilei Zhang, Junlan Feng
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="liu24r_interspeech.html">
                                <p>
                                    Emotion-Aware Speech Self-Supervised Representation Learning with Intensity Knowledge
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Rui Liu, Zening Ma
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Emotion Recognition: Fairness, Variability, Uncertainty"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Emotion Recognition: Fairness, Variability, Uncertainty</h4>
                            <hr>
                            <a class="w3-text" href="wu24_interspeech.html">
                                <p>
                                    Dual-Constrained Dynamical Neural ODEs for Ambiguity-aware Continuous Emotion Prediction
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jingyao Wu, Ting Dang, Vidhyasaharan Sethu, Eliathamby Ambikairajah
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="chou24_interspeech.html">
                                <p>
                                    An Inter-Speaker Fairness-Aware Speech Emotion Regression Framework
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Hsing-Hang Chou, Woan-Shiuan Chien, Ya-Tse Wu, Chi-Chun Lee
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="tavernor24_interspeech.html">
                                <p>
                                    The Whole Is Bigger Than the Sum of Its Parts: Modeling Individual Annotators to Capture Emotional Variability
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        James Tavernor, Yara El-Tawil, Emily Mower Provost
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="sun24e_interspeech.html">
                                <p>
                                    Iterative Prototype Refinement for Ambiguous Speech Emotion Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Haoqin Sun, Shiwan Zhao, Xiangyu Kong, Xuechen Wang, Hui Wang, Jiaming Zhou, Yong Qin
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="chien24_interspeech.html">
                                <p>
                                    An Investigation of Group versus Individual Fairness in Perceptually Fair Speech Emotion Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Woan-Shiuan Chien, Chi-Chun Lee
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="schrufer24_interspeech.html">
                                <p>
                                    Are you sure? Analysing Uncertainty Quantification Approaches for Real-world Speech Emotion Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Oliver SchrÃ¼fer, Manuel Milling, Felix Burkhardt, Florian Eyben, BjÃ¶rn Schuller
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="garcia24_interspeech.html">
                                <p>
                                    Speech emotion recognition with deep learning beamforming  on a distant human-robot interaction scenario
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Ricardo GarcÃ­a, Rodrigo Mahu, NicolÃ¡s GrÃ¡geda, Alejandro Luzanto, Nicolas Bohmer, Carlos Busso, NÃ©stor Becerra Yoma
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Speaker Verification"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Speaker Verification</h4>
                            <hr>
                            <a class="w3-text" href="stafylakis24_interspeech.html">
                                <p>
                                    Challenging margin-based speaker embedding extractors by using the variational information bottleneck
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Themos Stafylakis, Anna Silnova, Johan Rohdin, OldÅich Plchot, LukÃ¡Å¡ Burget
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="chien24c_interspeech.html">
                                <p>
                                    Collaborative Contrastive Learning for Hypothesis Domain Adaptation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jen-Tzung Chien, I-Ping Yeh, Man-Wai Mak
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="benamor24_interspeech.html">
                                <p>
                                    Extraction of interpretable and shared speaker-specific speech attributes through binary auto-encoder
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Imen Ben-Amor, Jean-Francois Bonastre, Salima Mdhaffar
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="yakovlev24_interspeech.html">
                                <p>
                                    Reshape Dimensions Network for Speaker Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Ivan Yakovlev, Rostislav Makarov, Andrei Balykin, Pavel Malov, Anton Okhotnikov, Nikita Torgashov
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="jung24d_interspeech.html">
                                <p>
                                    To what extent can ASV systems naturally defend against spoofing attacks?
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jee-weon Jung, Xin Wang, Nicholas Evans, Shinji Watanabe, Hye-jin Shim, Hemlata Tak, Siddhant Arora, Junichi Yamagishi, Joon Son Chung
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="chen24l_interspeech.html">
                                <p>
                                    ERes2NetV2: Boosting Short-Duration Speaker Verification Performance with Computational Efficiency
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yafeng Chen, Siqi Zheng, Hui Wang, Luyao Cheng, Qian Chen, Shiliang Zhang, Junjie Li
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Spatial Audio and Acoustics"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Spatial Audio and Acoustics</h4>
                            <hr>
                            <a class="w3-text" href="khokhlov24_interspeech.html">
                                <p>
                                    Classification of Room Impulse Responses and its application for channel verification and diarization
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yuri Khokhlov, Tatiana Prisyach, Anton Mitrofanov, Dmitry Dutov, Igor Agafonov, Tatiana Timofeeva, Aleksei Romanenko, Maxim Korenevsky
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kelley24_interspeech.html">
                                <p>
                                    RIR-in-a-Box: Estimating Room Acoustics from 3D Mesh Data through Shoebox Approximation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Liam Kelley, Diego Di Carlo, Aditya Arie Nugraha, Mathieu Fontaine, Yoshiaki Bando, Kazuyoshi Yoshii
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="ahn24c_interspeech.html">
                                <p>
                                    Novel-view Acoustic Synthesis From 3D Reconstructed Rooms
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Byeongjoo Ahn, Karren Yang, Brian Hamilton, Jonathan Sheaffer, Anurag Ranjan, Miguel Sarabia, Oncel Tuzel, Jen-Hao Rick Chang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="tao24_interspeech.html">
                                <p>
                                    Spatial Acoustic Enhancement Using Unbiased Relative Harmonic Coefficients
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Liang Tao, Maoshen Jia, Yonggang Hu, Changchun Bao
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="bayestehtashk24_interspeech.html">
                                <p>
                                    Design of Feedback Active Noise Cancellation Filter Using Nested Recurrent Neural Networks
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Alireza Bayestehtashk, Amit Kumar, Mike Wurtz
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="yarga24_interspeech.html">
                                <p>
                                    Neuromorphic Keyword Spotting with Pulse Density Modulation MEMS Microphones
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Sidi Yaya Arnaud Yarga, Sean U N Wood
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="bitterman24_interspeech.html">
                                <p>
                                    RevRIR: Joint Reverberant Speech and Room Impulse Response Embedding using Contrastive Learning with Application to Room Shape Classification
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jacob Bitterman, Daniel Levi, Hilel Hagai Diamandi, Sharon Gannot, Tal Rosenwein
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Generative Models for Speech and Audio"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Generative Models for Speech and Audio</h4>
                            <hr>
                            <a class="w3-text" href="bai24b_interspeech.html">
                                <p>
                                    ConsistencyTTA: Accelerating Diffusion-Based Text-to-Audio Generation with Consistency Distillation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yatong Bai, Trung Dang, Dung Tran, Kazuhito Koishida, Somayeh Sojoudi
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="paissan24b_interspeech.html">
                                <p>
                                    Audio Editing with Non-Rigid Text Prompts
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Francesco Paissan, Luca Della Libera, Zhepei Wang, Paris Smaragdis, Mirco Ravanelli, Cem Subakan
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="gupta24b_interspeech.html">
                                <p>
                                    Phoneme Discretized Saliency Maps for Explainable Detection of AI-Generated Voice
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Shubham Gupta, Mirco Ravanelli, Pascal Germain, Cem Subakan
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="moschopoulos24_interspeech.html">
                                <p>
                                    Exploring compressibility of transformer based text-to-music (TTM) models
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Vasileios Moschopoulos, Thanasis Kotsiopoulos, Pablo Peso Parada, Konstantinos Nikiforidis, Alexandros Stergiadis, Gerasimos Papakostas, Md Asif Jalal, Jisi Zhang, Anastasios Drosou, Karthikeyan Saravanan
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kim24n_interspeech.html">
                                <p>
                                    Sound of Vision: Audio Generation from Visual Text Embedding through Training Domain Discriminator
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jaewon Kim, Won-Gook Choi, Seyun Ahn, Joon-Hyuk Chang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="choi24c_interspeech.html">
                                <p>
                                    Retrieval-Augmented Classifier Guidance for Audio Generation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Ho-Young Choi, Won-Gook Choi, Joon-Hyuk Chang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="cappellazzo24_interspeech.html">
                                <p>
                                    Efficient Fine-tuning of Audio Spectrogram Transformers via Soft Mixture of Adapters
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Umberto Cappellazzo, Daniele Falavigna, Alessio Brutti
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="deshmukh24b_interspeech.html">
                                <p>
                                    PAM: Prompting Audio-Language Models for Audio Quality Assessment
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Soham Deshmukh, Dareen Alharthi, Benjamin Elizalde, Hannes Gamper, Mahmoud Al Ismail, Rita Singh, Bhiksha Raj, Huaming Wang
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Speech and Audio Modelling"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Speech and Audio Modelling</h4>
                            <hr>
                            <a class="w3-text" href="gao24_interspeech.html">
                                <p>
                                    GenDistiller: Distilling Pre-trained Language Models based on an Autoregressive Generative Model
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yingying Gao, Shilei Zhang, Chao Deng, Junlan Feng
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="guillaume24_interspeech.html">
                                <p>
                                    Gender and Language Identification in Multilingual Models of Speech: Exploring the Genericity and Robustness of Speech Representations
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        SÃ©verine Guillaume, Maxime Fily, Alexis Michaud, Guillaume Wisniewski
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="wang24u_interspeech.html">
                                <p>
                                    Neural Compression Augmentation for Contrastive Audio Representation Learning
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Zhaoyu Wang, Haohe Liu, Harry Coppock, BjÃ¶rn Schuller, Mark D. Plumbley
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="aluru24_interspeech.html">
                                <p>
                                    Post-Net: A linguistically inspired sequence-dependent transformed neural architecture for automatic syllable stress detection
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Sai Harshitha Aluru, Jhansi Mallela, Chiranjeevi Yarra
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Multi-Channel Speech Enhancement"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Multi-Channel Speech Enhancement</h4>
                            <hr>
                            <a class="w3-text" href="tammen24_interspeech.html">
                                <p>
                                    Array Geometry-Robust Attention-Based Neural Beamformer for Moving Speakers
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Marvin Tammen, Tsubasa Ochiai, Marc Delcroix, Tomohiro Nakatani, Shoko Araki, Simon Doclo
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="xu24i_interspeech.html">
                                <p>
                                    FoVNet: Configurable Field-of-View Speech Enhancement with Low Computation and Distortion for Smart Glasses
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Zhongweiyang Xu, Ali Aroudi, Ke Tan, Ashutosh Pandey, Jung-Suk Lee, Buye Xu, Francesco Nesta
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="aziz24_interspeech.html">
                                <p>
                                    Audio Enhancement from Multiple Crowdsourced Recordings: A Simple and Effective Baseline
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Shiran Aziz, Yossi Adi, Shmuel Peleg
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="lee24g_interspeech.html">
                                <p>
                                    DeFTAN-AA: Array Geometry Agnostic Multichannel Speech Enhancement
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Dongheon Lee, Jung-Woo Choi
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="wang24_interspeech.html">
                                <p>
                                    SA-MF: A Novel Self-Attention Mechanism for Multifeature Fusion in Speech Enhancement Networks
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Ruizhe Wang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="zhou24d_interspeech.html">
                                <p>
                                    PLDNet: PLD-Guided Lightweight Deep Network Boosted by Efï¬cient Attention for Handheld Dual-Microphone Speech Enhancement
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Nan Zhou, Youhai Jiang, Jialin Tan, Chongmin Qi
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Speech Synthesis: Paradigms and Methods 1"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Speech Synthesis: Paradigms and Methods 1</h4>
                            <hr>
                            <a class="w3-text" href="mcghee24_interspeech.html">
                                <p>
                                    Highly Intelligible Speaker-Independent Articulatory Synthesis
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Charles McGhee, Kate Knill, Mark Gales
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="murata24_interspeech.html">
                                <p>
                                    An Attribute Interpolation Method in Speech Synthesis by Model Merging
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Masato Murata, Koichi Miyazaki, Tomoki Koriyama
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="nishihara24_interspeech.html">
                                <p>
                                    Low-dimensional Style Token Control for Hyperarticulated Speech Synthesis
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Miku Nishihara, Dan Wells, Korin Richmond, Aidan Pine
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="li24ba_interspeech.html">
                                <p>
                                    Single-Codec: Single-Codebook Speech Codec towards High-Performance Speech Generation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Hanzhao Li, Liumeng Xue, Haohan Guo, Xinfa Zhu, Yuanjun Lv, Lei Xie, Yunlin Chen, Hao Yin, Zhifei Li
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="dang24_interspeech.html">
                                <p>
                                    LiveSpeech: Low-Latency Zero-shot Text-to-Speech via Autoregressive Modeling of Audio Discrete Codes
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Trung Dang, David Aponte, Dung Tran, Kazuhito Koishida
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kim24h_interspeech.html">
                                <p>
                                    ClariTTS: Feature-ratio Normalization and Duration Stabilization for Code-mixed Multi-speaker Speech Synthesis
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Changhwan Kim
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="janiczek24_interspeech.html">
                                <p>
                                    Multi-modal Adversarial Training for Zero-Shot Voice Cloning
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        John Janiczek, Dading Chong, Dongyang Dai, Arlo Faria, Chao Wang, Tao Wang, Yuzong Liu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="chien24b_interspeech.html">
                                <p>
                                    Learning Fine-Grained Controllability on Speech Generation via Efficient Fine-Tuning
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Chung-Ming Chien, Andros Tjandra, Apoorv Vyas, Matt Le, Bowen Shi, Wei-Ning Hsu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="wu24o_interspeech.html">
                                <p>
                                    Modeling Vocal Tract Like Acoustic Tubes Using the Immersed Boundary Method
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Rongshuai Wu, Debasish Ray Mohapatra, Sidney Fels
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Speech Synthesis: Paradigms and Methods 2"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Speech Synthesis: Paradigms and Methods 2</h4>
                            <hr>
                            <a class="w3-text" href="lemerle24_interspeech.html">
                                <p>
                                    Small-E: Small Language Model with Linear Attention for Efficient Speech Synthesis
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        ThÃ©odor Lemerle, Nicolas Obin, Axel Roebel
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="neekhara24_interspeech.html">
                                <p>
                                    Improving Robustness of LLM-based Speech Synthesis by Learning Monotonic Alignment
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Paarth Neekhara, Shehzeen Hussain, Subhankar Ghosh, Jason Li, Boris Ginsburg
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="lai24b_interspeech.html">
                                <p>
                                    Synthesizing Long-Form Speech merely from Sentence-Level Corpus with Content Extrapolation and LLM Contextual Enrichment
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Shijie Lai, Minglu He, Zijing Zhao, Kai Wang, Hao Huang, Jichen Yang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="liu24p_interspeech.html">
                                <p>
                                    FluentEditor: Text-based Speech Editing by Considering Acoustic and Prosody Consistency
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Rui Liu, Jiatian Xi, Ziyue Jiang, Haizhou Li
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="zhou24_interspeech.html">
                                <p>
                                    Phonetic Enhanced Language Modeling for Text-to-Speech Synthesis
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Kun Zhou, Shengkui Zhao, Yukun Ma, Chong Zhang, Hao Wang, Dianwen Ng, Chongjia Ni, Trung Hieu Nguyen, Jia Qi Yip, Bin Ma
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="lee24f_interspeech.html">
                                <p>
                                    High Fidelity Text-to-Speech Via Discrete Tokens Using Token Transducer and Group Masked Language Model
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Joun Yeop Lee, Myeonghun Jeong, Minchan Kim, Ji-Hyun Lee, Hoon-Young Cho, Nam Soo Kim
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="lenglet24_interspeech.html">
                                <p>
                                    FastLips: an End-to-End Audiovisual Text-to-Speech System with Lip Features Prediction for Virtual Avatars
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Martin Lenglet, Olivier Perrotin, Gerard Bailly
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Neural Network Architectures for ASR 1"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Neural Network Architectures for ASR 1</h4>
                            <hr>
                            <a class="w3-text" href="yang24g_interspeech.html">
                                <p>
                                    Contemplative Mechanism for Speech Recognition: Speech Encoders can Think
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Tien-Ju Yang, Andrew Rosenberg, Bhuvana Ramabhadran
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="parcollet24_interspeech.html">
                                <p>
                                    SummaryMixing: A Linear-Complexity Alternative to Self-Attention for Speech Recognition and Understanding
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Titouan Parcollet, Rogier van Dalen, Shucong Zhang, Sourav Bhattacharya
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="moriya24_interspeech.html">
                                <p>
                                    Boosting Hybrid Autoregressive Transducer-based ASR with Internal Acoustic Model Training and Dual Blank Thresholding
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Takafumi Moriya, Takanori Ashihara, Masato Mimura, Hiroshi Sato, Kohei Matsuura, Ryo Masumura, Taichi Asami
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kundu24_interspeech.html">
                                <p>
                                    RepCNN: Micro-sized, Mighty Models for Wakeword Detection
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Arnav Kundu, Prateeth Nayak, Priyanka Padmanabhan, Devang Naik
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="vankeirsbilck24_interspeech.html">
                                <p>
                                    Conformer without Convolutions
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Matthijs Van keirsbilck, Alexander Keller
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="zhang24e_interspeech.html">
                                <p>
                                    Linear-Complexity Self-Supervised Learning for Speech Processing
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Shucong Zhang, Titouan Parcollet, Rogier van Dalen, Sourav Bhattacharya
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Error Correction and Rescoring"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Error Correction and Rescoring</h4>
                            <hr>
                            <a class="w3-text" href="mittal24_interspeech.html">
                                <p>
                                    SALSA: Speedy ASR-LLM Synchronous Aggregation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Ashish Mittal, Darshan Prabhu, Sunita Sarawagi, Preethi Jyothi
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="yoon24c_interspeech.html">
                                <p>
                                    LI-TTA: Language Informed Test-Time Adaptation for Automatic Speech Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Eunseop Yoon, Hee Suk Yoon, John Harvill, Mark Hasegawa-Johnson, Chang D. Yoo
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="wang24j_interspeech.html">
                                <p>
                                    HypR: A comprehensive study for ASR hypothesis revising with a reference corpus
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yi-Wei Wang, Ke-Han Lu, Kuan-Yu Chen
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="shu24_interspeech.html">
                                <p>
                                    Error Correction by Paying Attention to Both Acoustic and Confidence References for Automatic Speech Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yuchun Shu, Bo Hu, Yifeng He, Hao Shi, Longbiao Wang, Jianwu Dang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kang24c_interspeech.html">
                                <p>
                                    Transformer-based Model for ASR N-Best Rescoring and Rewriting
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Iwen E Kang, Christophe Van Gysel, Man-Hung Siu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="yang24b_interspeech.html">
                                <p>
                                    RASU: Retrieval Augmented Speech Understanding through Generative Modeling
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Hao Yang, Min Zhang, Minghan Wang, Jiaxin Guo
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Spoken Language Understanding"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Spoken Language Understanding</h4>
                            <hr>
                            <a class="w3-text" href="yang24p_interspeech.html">
                                <p>
                                    Towards Unified Evaluation of Continual Learning in Spoken Language Understanding
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Muqiao Yang, Xiang Li, Umberto Cappellazzo, Shinji Watanabe, Bhiksha Raj
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="zheng24b_interspeech.html">
                                <p>
                                    Convolutional gated MLP and attention improve end-to-end spoken language understanding
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Beida Zheng, Mijit Ablimit, Hankiz Yilahun, Askar Hamdulla
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="aimaiti24_interspeech.html">
                                <p>
                                    An Uyghur Extension to the MASSIVE Multi-lingual Spoken Language Understanding Corpus with Comprehensive Evaluations
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Ainikaerjiang Aimaiti, Di Wu, Liting Jiang, Gulinigeer Abudouwaili, Hao Huang, Wushour Silamu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="christ24_interspeech.html">
                                <p>
                                    This Paper Had the Smartest Reviewers - Flattery Detection Utilising an Audio-Textual Transformer-Based Approach
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Lukas Christ, Shahin Amiriparian, Friederike Hawighorst, Ann-Kathrin Schill, Angelo Boutalikakis, Lorenz Graf-Vlachy, Andreas KÃ¶nig, BjÃ¶rn Schuller
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="akani24_interspeech.html">
                                <p>
                                    Unified Framework for Spoken Language Understanding and Summarization in Task-Based Human Dialog processing
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Eunice Akani, Frederic Bechet, BenoÃ®t Favre, Romain Gemignani
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="anderson24_interspeech.html">
                                <p>
                                    Automated Human-Readable Label Generation in Open Intent Discovery
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Grant Anderson, Emma Hart, Dimitra Gkatzia, Ian Beaver
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="chang24_interspeech.html">
                                <p>
                                    Applying Reinforcement Learning and Multi-Generators for Stage Transition in an Emotional Support Dialogue System
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jeremy Chang, Kuan-Yu Chen, Chung-Hsien Wu
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Spoken Dialogue Systems and Conversational Analysis 2"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Spoken Dialogue Systems and Conversational Analysis 2</h4>
                            <hr>
                            <a class="w3-text" href="chen24d_interspeech.html">
                                <p>
                                    Target conversation extraction: Source separation using turn-taking dynamics
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Tuochao Chen, Qirui Wang, Bohan Wu, Malek Itani, Emre Sefik Eskimez, Takuya Yoshioka, Shyamnath Gollakota
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="ng24b_interspeech.html">
                                <p>
                                    Investigating the Influence of Stance-Taking on Conversational Timing of Task-Oriented Speech
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Sara Ng, Gina-Anne Levow, Mari Ostendorf, Richard Wright
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="uro24_interspeech.html">
                                <p>
                                    Detecting the terminality of speech-turn boundary for spoken interactions in French TV and Radio content
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        RÃ©mi Uro, Marie Tahon, David Doukhan, Antoine Laurent, Albert Rilliard
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="watanabe24_interspeech.html">
                                <p>
                                    Utilization of Text Data for Response Timing Detection in Attentive Listening
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yu Watanabe, Koichiro Ito, Shigeki Matsubara
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="park24b_interspeech.html">
                                <p>
                                    Backchannel prediction, based on who, when and what
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yo-Han Park, Wencke Liermann, Yong-Seok Choi, Seung Hi Kim, Jeong-Uk Bang, Seung Yun, Kong Joo Lee
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="hutin24_interspeech.html">
                                <p>
                                    Uh, um and mh: Are filled pauses prone to conversational converge?
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Mathilde Hutin, Junfei Hu, Liesbeth Degand
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="ohagi24_interspeech.html">
                                <p>
                                    Investigation of look-ahead techniques to improve response time in spoken dialogue system
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Masaya Ohagi, Tomoya Mizumoto, Katsumasa Yoshikawa
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Computational Models of Human Language Acquisition, Perception, and Production (Special Session)"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Computational Models of Human Language Acquisition, Perception, and Production (Special Session)</h4>
                            <hr>
                            <a class="w3-text" href="heuser24b_interspeech.html">
                                <p>
                                    Information-theoretic hypothesis generation of relative cue weighting for the voicing contrast
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Annika Heuser, Jianjing Kuang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="hovsepyan24_interspeech.html">
                                <p>
                                    Neurocomputational model of speech recognition for pathological speech detection: a case study on Parkinson's disease speech detection
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Sevada Hovsepyan, Mathew Magimai.-Doss
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="ortiztandazo24_interspeech.html">
                                <p>
                                    Simulating articulatory trajectories with phonological feature interpolation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Angelo Ortiz Tandazo, Thomas Schatz, Thomas Hueber, Emmanuel Dupoux
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="onda24_interspeech.html">
                                <p>
                                    A Pilot Study of GSLM-based Simulation of Foreign Accentuation Only Using Native Speech Corpora
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Kentaro Onda, Joonyong Park, Nobuaki Minematsu, Daisuke Saito
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="bonafos24_interspeech.html">
                                <p>
                                    Dirichlet process mixture model based on topologically augmented signal representation for clustering infant vocalizations
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Guillem Bonafos, Clara Bourot, Pierre Pudlo, Jean-Marc Freyermuth, Laurence Reboul, Samuel TronÃ§on, Arnaud Rey
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="elie24_interspeech.html">
                                <p>
                                    A data-driven model of acoustic speech intelligibility for optimization-based models of speech production
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Benjamin Elie, Juraj Simko, Alice Turk
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="coffey24_interspeech.html">
                                <p>
                                    The Difficulty and Importance of Estimating the Lower and Upper Bounds of Infant Speech Exposure
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Joseph Coffey, Okko RÃ¤sÃ¤nen, Camila Scaff, Alejandrina Cristia
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="vanniekerk24_interspeech.html">
                                <p>
                                    Spoken-Term Discovery using Discrete Speech Units
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Benjamin van Niekerk, Julian ZaÃ¯di, Marc-AndrÃ© Carbonneau, Herman Kamper
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="mohamed24_interspeech.html">
                                <p>
                                    Orthogonality and isotropy of speaker and phonetic information in self-supervised speech representations
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Mukhtar Mohamed, Oli Danyi Liu, Hao Tang, Sharon Goldwater
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Show and Tell 3"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Show and Tell 3</h4>
                            <hr>
                            <a class="w3-text" href="ryumina24_interspeech.html">
                                <p>
                                    OCEAN-AI: open multimodal framework for personality traits assessment and HR-processes automatization
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Elena Ryumina, Dmitry Ryumin, Alexey Karpov
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="mundra24_interspeech.html">
                                <p>
                                    VoxMed: one-step respiratory disease classifier using digital stethoscope sounds
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Paridhi Mundra, Manik Sharma, Yashwardhan Chaudhuri, Orchid Chetia Phukan, Arun Balaji Buduru
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="sharma24b_interspeech.html">
                                <p>
                                    AVR: synergizing foundation models for audio-visual humor detection
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Sarthak Sharma, Orchid Chetia Phukan, Drishti Singh, Arun Balaji Buduru, Rajesh Sharma
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="chaudhuri24_interspeech.html">
                                <p>
                                    ASGIR: audio spectrogram transformer guided classification and information retrieval for birds
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yashwardhan Chaudhuri, Paridhi Mundra, Arnesh Batra, Orchid Chetia Phukan, Arun Balaji Buduru
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="koshal24_interspeech.html">
                                <p>
                                    PERSONA: an application for emotion recognition, gender recognition and age estimation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Devyani Koshal, Orchid Chetia Phukan, Sarthak Jain, Arun Balaji Buduru, Rajesh Sharma
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="akhtar24_interspeech.html">
                                <p>
                                    NeuRO: an application for code-switched autism detection in children
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Mohd Mujtaba Akhtar,  Girish, Orchid Chetia Phukan, Muskaan Singh
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="phukan24c_interspeech.html">
                                <p>
                                    ComFeAT: combination of neural and spectral features for improved depression detection
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Orchid Chetia Phukan, Sarthak Jain, Shubham Singh, Muskaan Singh, Arun Balaji Buduru, Rajesh Sharma
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="jain24b_interspeech.html">
                                <p>
                                    The reasonable effectiveness of speaker embeddings for violence detection
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Sarthak Jain, Orchid Chetia Phukan, Arun Balaji Buduru, Rajesh Sharma
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="obukhov24_interspeech.html">
                                <p>
                                    ATTEST: an analytics tool for the testing and evaluation of speech technologies
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Dmitrii Obukhov, Marcel de Korte, Andrey Adaschik
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="masson24_interspeech.html">
                                <p>
                                    PhoneViz: exploring alignments at a glance
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Margot Masson, Erfan A. Shams, Iona Gessinger, Julie Carson-Berndsen
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="pages24_interspeech.html">
                                <p>
                                    Gryannote open-source speaker diarization labeling tool
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        ClÃ©ment Pages, HervÃ© Bredin
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="morrone24_interspeech.html">
                                <p>
                                    A toolkit for joint speaker diarization and identification with application to speaker-attributed ASR
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Giovanni Morrone, Enrico Zovato, Fabio Brugnara, Enrico Sartori, Leonardo Badino
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Phonetics, Phonology and Prosody"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Phonetics, Phonology and Prosody</h4>
                            <hr>
                            <a class="w3-text" href="kinnunen24_interspeech.html">
                                <p>
                                    Speaker Detection by the Individual Listener and the Crowd: Parametric Models Applicable to Bonafide and Deepfake Speech
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Tomi H. Kinnunen, Rosa Gonzalez HautamÃ¤ki, Xin Wang, Junichi Yamagishi
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="deluca24_interspeech.html">
                                <p>
                                    NumberLie: a game-based experiment to understand the acoustics of deception and truthfulness
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Alessandro De Luca, Andrew Clark, Volker Dellwo
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="loiacono24_interspeech.html">
                                <p>
                                    Preservation, conservation and phonetic study of the voices of Italian poets: A study on the seven years of the VIP archive
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Federico Lo Iacono, Valentina Colonna, Antonio Romano
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="audibert24_interspeech.html">
                                <p>
                                    Do Speaker-dependent Vowel Characteristics depend on Speech Style?
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Nicolas Audibert, Cecile Fougeron, Christine Meunier
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="liu24q_interspeech.html">
                                <p>
                                    A comparison of voice similarity through acoustics, human perception and deep neural network (DNN) speaker verification systems
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Suyuan Liu, Molly Babel, Jian Zhu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="jones24_interspeech.html">
                                <p>
                                    Evaluating Italian Vowel Variation with the Recurrent Neural Network Phonet
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Austin Jones, Margaret E. L. Renwick
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="tulchynska24_interspeech.html">
                                <p>
                                    Prosodic marking of syntactic boundaries in Khoekhoe
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Kira Tulchynska, Sylvanus Job, Alena Witzlack-Makarevich, Margaret Zellers
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Segmentals"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Segmentals</h4>
                            <hr>
                            <a class="w3-text" href="cronenberg24_interspeech.html">
                                <p>
                                    Crosslinguistic Comparison of Acoustic Variation in the Vowel Sequences /ia/ and /io/ in Four Romance Languages
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Johanna Cronenberg, Ioana Chitoran, Lori Lamel, Ioana Vasilescu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="vegarodriguez24_interspeech.html">
                                <p>
                                    Nasal Air Flow During Speech Production In Korebaju
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jenifer Vega Rodriguez, Nathalie VallÃ©e, Christophe Savariaux, Silvain Gerber
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kye24_interspeech.html">
                                <p>
                                    Affricates in Lushootseed
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Ted Kye
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="terhiija24_interspeech.html">
                                <p>
                                    Voiced and voiceless laterals in Angami
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Viyazonuo Terhiija, Priyankoo Sarmah
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="yang24n_interspeech.html">
                                <p>
                                    Intrusive schwa within French stop-liquid clusters: An acoustic analysis
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Minmin Yang, Rachid Ridouane
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="New Avenues in Emotion Recognition"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">New Avenues in Emotion Recognition</h4>
                            <hr>
                            <a class="w3-text" href="wu24d_interspeech.html">
                                <p>
                                    Can Modelling Inter-Rater Ambiguity Lead To Noise-Robust Continuous Emotion Predictions?
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Ya-Tse Wu, Jingyao Wu, Vidhyasaharan Sethu, Chi-Chun Lee
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="zhao24g_interspeech.html">
                                <p>
                                    MFDR: Multiple-stage Fusion and Dynamically Refined Network for Multimodal Emotion Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Ziping Zhao, Tian Gao, Haishuai Wang, BjÃ¶rn Schuller
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="shi24i_interspeech.html">
                                <p>
                                    Multimodal Fusion of Music Theory-Inspired and Self-Supervised Representations for Improved Emotion Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Xiaohan Shi, Xingfeng Li, Tomoki Toda
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="triantafyllopoulos24c_interspeech.html">
                                <p>
                                    Enrolment-based personalisation for improving individual-level fairness in speech emotion recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Andreas Triantafyllopoulos, BjÃ¶rn Schuller
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="leem24_interspeech.html">
                                <p>
                                    Keep, Delete, or Substitute: Frame Selection Strategy for Noise-Robust Speech Emotion Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Seong-Gyun Leem, Daniel Fulford, Jukka-Pekka Onnela, David Gard, Carlos Busso
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="lu24e_interspeech.html">
                                <p>
                                    Hierarchical Distribution Adaptation for Unsupervised Cross-corpus Speech Emotion Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Cheng Lu, Yuan Zong, Yan Zhao, Hailun Lian, Tianhua Qi, BjÃ¶rn Schuller, Wenming Zheng
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Speaker Diarization 2"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Speaker Diarization 2</h4>
                            <hr>
                            <a class="w3-text" href="zhang24b_interspeech.html">
                                <p>
                                    Variable Segment Length and Domain-Adapted Feature Optimization for Speaker Diarization
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Chenyuan Zhang, Linkai Luo, Hong Peng, Wei Wen
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="choi24d_interspeech.html">
                                <p>
                                    Efficient Speaker Embedding Extraction Using a Twofold Sliding Window Algorithm for Speaker Diarization
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jeong-Hwan Choi, Ye-Rin Jeoung, Ilseok Kim, Joon-Hyuk Chang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="wang24h_interspeech.html">
                                <p>
                                    DiarizationLM: Speaker Diarization Post-Processing with Large Language Models
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Quan Wang, Yiling Huang, Guanlong Zhao, Evan Clark, Wei Xia, Hank Liao
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="blatt24_interspeech.html">
                                <p>
                                    Joint vs Sequential Speaker-Role Detection and Automatic Speech Recognition for Air-traffic Control
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Alexander Blatt, Aravind Krishnan, Dietrich Klakow
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="plaquet24_interspeech.html">
                                <p>
                                    On the calibration of powerset speaker diarization models
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Alexis Plaquet, HervÃ© Bredin
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="baroudi24_interspeech.html">
                                <p>
                                    Specializing Self-Supervised Speech Representations for Speaker Segmentation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        SÃ©verin Baroudi, Thomas Pellegrini, HervÃ© Bredin
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Speaker Recognition 2"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Speaker Recognition 2</h4>
                            <hr>
                            <a class="w3-text" href="loweimi24_interspeech.html">
                                <p>
                                    On the Usefulness of Speaker Embeddings for Speaker Retrieval in the Wild: A Comparative Study of x-vector and ECAPA-TDNN Models
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Erfan Loweimi, Mengjie Qian, Kate Knill, Mark Gales
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="jin24b_interspeech.html">
                                <p>
                                    W-GVKT: Within-Global-View Knowledge Transfer for Speaker Verification
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Zezhong Jin, Youzhi Tu, Man-Wai Mak
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="shen24_interspeech.html">
                                <p>
                                    CEC: A Noisy Label Detection Method for Speaker Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yao Shen, Yingying Gao, Yaqian Hao, Chenguang Hu, Fulin Zhang, Junlan Feng, Shilei Zhang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="zhang24c_interspeech.html">
                                <p>
                                    Disentangling Age and Identity with a Mutual Information Minimization for Cross-Age Speaker Verification
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Fengrun Zhang, Wangjin Zhou, Yiming Liu, Wang Geng, Yahui Shan, Chen Zhang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="li24u_interspeech.html">
                                <p>
                                    Contrastive Learning and Inter-Speaker Distribution Alignment Based Unsupervised Domain Adaptation for Robust Speaker Verification
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Zuoliang Li, Wu Guo, Bin Gu, Shengyu Peng, Jie Zhang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="nguyen24_interspeech.html">
                                <p>
                                    Identifying Speakers in Dialogue Transcripts: A Text-based Approach Using Pretrained Language Models
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Minh Nguyen, Franck Dernoncourt, Seunghyun Yoon, Hanieh Deilamsalehy, Hao Tan, Ryan Rossi, Quan Hung Tran, Trung Bui, Thien Huu Nguyen
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kc24_interspeech.html">
                                <p>
                                    Attention-augmented X-vectors for the Evaluation of Mimicked Speech Using Sparse Autoencoder-LSTM framework
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Bhasi K. C., Rajeev Rajan, Noumida A
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Speech and Audio Analysis"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Speech and Audio Analysis</h4>
                            <hr>
                            <a class="w3-text" href="almudevar24_interspeech.html">
                                <p>
                                    Predefined Prototypes for Intra-Class Separation and Disentanglement
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Antonio AlmudÃ©var, ThÃ©o Mariotte, Alfonso Ortega, Marie Tahon, Luis Vicente, Antonio Miguel, Eduardo Lleida
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="koriyama24_interspeech.html">
                                <p>
                                    VAE-based Phoneme Alignment Using Gradient Annealing and SSL Acoustic Features
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Tomoki Koriyama
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="karan24_interspeech.html">
                                <p>
                                    A Transformer-Based Voice Activity Detector
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Biswajit Karan, Joshua Jansen van VÃ¼ren, Febe de Wet, Thomas Niesler
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="dumpala24_interspeech.html">
                                <p>
                                    XANE: eXplainable Acoustic Neural Embeddings
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Sri Harsha Dumpala, Dushyant Sharma, Chandramouli Shama Sastry, Stanislav Kruchinin, James Fosburgh, Patrick A. Naylor
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="mallela24_interspeech.html">
                                <p>
                                    A comparative analysis of sequential models that integrate syllable dependency for automatic syllable stress detection
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jhansi Mallela, Sai Harshitha Aluru, Chiranjeevi Yarra
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="li24p_interspeech.html">
                                <p>
                                    Motion Based Audio-Visual Segmentation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jiahao Li, Miao Liu, Shu Yang, Jing Wang, Xiang Xie
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Speech Quality and Intelligibility: Prediction and Enhancement"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Speech Quality and Intelligibility: Prediction and Enhancement</h4>
                            <hr>
                            <a class="w3-text" href="best24_interspeech.html">
                                <p>
                                    Transfer Learning from Whisper for Microscopic Intelligibility Prediction
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Paul Best, Santiago Cuervo, Ricard Marxer
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="zezario24_interspeech.html">
                                <p>
                                    Non-Intrusive Speech Intelligibility Prediction for Hearing Aids using Whisper and Metadata
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Ryandhimas E. Zezario, Fei Chen, Chiou-Shann Fuh, Hsin-Min Wang, Yu Tsao
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="wang24y_interspeech.html">
                                <p>
                                    No-Reference Speech Intelligibility Prediction Leveraging a Noisy-Speech ASR Pre-Trained Model
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Haolan Wang, Amin Edraki, Wai-Yip Chan, IvÃ¡n LÃ³pez-Espejo, Jesper Jensen
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="deoliveira24_interspeech.html">
                                <p>
                                    The PESQetarian: On the Relevance of Goodhart's Law for Speech Enhancement
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Danilo de Oliveira, Simon Welker, Julius Richter, Timo Gerkmann
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="ta24b_interspeech.html">
                                <p>
                                    Enhancing Non-Matching Reference Speech Quality Assessment through Dynamic Weight Adaptation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Bao Thang Ta, Van Hai Do, Huynh Thi Thanh Binh
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="chen24j_interspeech.html">
                                <p>
                                    Exploring Sentence Type Effects on the Lombard Effect and Intelligibility Enhancement: A Comparative Study of Natural and Grid Sentences
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Hongyang Chen, Yuhong Yang, Zhongyuan Wang, Weiping Tu, Haojun Ai, Cedar Lin
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Speech Synthesis: Vocoders"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Speech Synthesis: Vocoders</h4>
                            <hr>
                            <a class="w3-text" href="lv24_interspeech.html">
                                <p>
                                    FreeV: Free Lunch For Vocoders Through Pseudo Inversed Mel Filter
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yuanjun Lv, Hai Li, Ying Yan, Junhui Liu, Danming Xie, Lei Xie
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="chaudhary24b_interspeech.html">
                                <p>
                                    QGAN: Low Footprint Quaternion Neural Vocoder for Speech Synthesis
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Aryan Chaudhary, Vinayak Abrol
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="cho24b_interspeech.html">
                                <p>
                                    JenGAN: Stacked Shifted Filters in GAN-Based Speech Synthesis
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Hyunjae Cho, Junhyeok Lee, Wonbin Jung
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="shen24b_interspeech.html">
                                <p>
                                    FA-GAN: Artifacts-free and Phase-aware High-fidelity GAN-based Vocoder
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Rubing Shen, Yanzhen Ren, Zongkun Sun
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="chen24x_interspeech.html">
                                <p>
                                    QHM-GAN: Neural Vocoder based on Quasi-Harmonic Modeling
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Shaowen Chen, Tomoki Toda
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="du24_interspeech.html">
                                <p>
                                    BiVocoder: A Bidirectional Neural Vocoder Integrating Feature Extraction and Waveform Generation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Hui-Peng Du, Ye-Xin Lu, Yang Ai, Zhen-Hua Ling
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="ASR Model Training Methods"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">ASR Model Training Methods</h4>
                            <hr>
                            <a class="w3-text" href="raissi24_interspeech.html">
                                <p>
                                    Investigating the Effect of Label Topology and Training Criterion on ASR Performance and Alignment Quality
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Tina Raissi, Christoph LÃ¼scher, Simon Berger, Ralf SchlÃ¼ter, Hermann Ney
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="gaur24_interspeech.html">
                                <p>
                                    ASTRA: Aligning Speech and Text Representations for Asr without Sampling
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Neeraj Gaur, Rohan Agrawal, Gary Wang, Parisa Haghani, Andrew Rosenberg, Bhuvana Ramabhadran
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="shakeel24_interspeech.html">
                                <p>
                                    Contextualized End-to-end Automatic Speech Recognition with Intermediate Biasing Loss
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Muhammad Shakeel, Yui Sudo, Yifan Peng, Shinji Watanabe
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="chiu24_interspeech.html">
                                <p>
                                    Learnable Layer Selection and Model Fusion for Speech Self-Supervised Learning Models
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Sheng-Chieh Chiu, Chia-Hua Wu, Jih-Kang Hsieh, Yu Tsao, Hsin-Min Wang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kulshreshtha24_interspeech.html">
                                <p>
                                    Sequential Editing for Lifelong Training of Speech Recognition Models
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Devang Kulshreshtha, Nikolaos Pappas, Brady Houston, Saket Dingliwal, Srikanth Ronanki
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="yeh24_interspeech.html">
                                <p>
                                    Cross-Modality Diffusion Modeling and Sampling for Speech Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Chia-Kai Yeh, Chih-Chun Chen, Ching-Hsien Hsu, Jen-Tzung Chien
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Cross-Lingual and Multilingual Processing"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Cross-Lingual and Multilingual Processing</h4>
                            <hr>
                            <a class="w3-text" href="liu24l_interspeech.html">
                                <p>
                                    A Parameter-efficient Language Extension Framework for Multilingual ASR
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Wei Liu, Jingyong Hou, Dong Yang, Muyong Cao, Tan Lee
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="song24_interspeech.html">
                                <p>
                                    LoRA-Whisper: Parameter-Efficient and Extensible Multilingual ASR
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Zheshu Song, Jianheng Zhuo, Yifan Yang, Ziyang Ma, Shixiong Zhang, Xie Chen
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="zanonboito24_interspeech.html">
                                <p>
                                    mHuBERT-147: A Compact Multilingual HuBERT Model
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Marcely Zanon Boito, Vivek Iyer, Nikolaos Lagos, Laurent Besacier, Ioan Calapodescu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="lodagala24_interspeech.html">
                                <p>
                                    All Ears: Building Self-Supervised Learning based ASR models for Indian Languages at scale
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Vasista Sai Lodagala, Abhishek Biswas, Shoutrik Das, Jordan F, S Umesh
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="jakhar24_interspeech.html">
                                <p>
                                    A Unified Approach to Multilingual Automatic Speech Recognition with Improved Language Identification for Indic Languages
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Nikhil Jakhar, Sudhanshu Srivastava, Arun Baby
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="dong24_interspeech.html">
                                <p>
                                    Integrating Speech Self-Supervised Learning Models and Large Language Models for ASR
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Ling Dong, Zhengtao Yu, Wenjun Wang, Yuxin Huang, Shengxiang Gao, Guojiang Zhou
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="tian24_interspeech.html">
                                <p>
                                    On the Effects of Heterogeneous Data Sources on Speech-to-Text Foundation Models
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jinchuan Tian, Yifan Peng, William Chen, Kwanghee Choi, Karen Livescu, Shinji Watanabe
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="puvvada24_interspeech.html">
                                <p>
                                    Less is More: Accurate Speech Recognition &amp; Translation without Web-Scale Data
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Krishna C. Puvvada, Piotr Å»elasko, He Huang, Oleksii Hrinchuk, Nithin Rao Koluguri, Kunal Dhawan, Somshubra Majumdar, Elena Rastorgueva, Zhehuai Chen, Vitaly Lavrukhin, Jagadeesh Balam, Boris Ginsburg
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="paraskevopoulos24_interspeech.html">
                                <p>
                                    The Greek podcast corpus: Competitive speech models for low-resourced languages with weakly supervised data
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Georgios Paraskevopoulos, Chara Tsoukala, Athanasios Katsamanis, Vassilis Katsouros
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="vakirtzian24_interspeech.html">
                                <p>
                                    Speech Recognition for Greek Dialects: A Challenging Benchmark
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Socrates Vakirtzian, Chara Tsoukala, Stavros Bompolas, Katerina Mouzou, Vivian Stamou, Georgios Paraskevopoulos, Antonios Dimakis, Stella Markantonatou, Angela Ralli, Antonios Anastasopoulos
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="liu24k_interspeech.html">
                                <p>
                                    LUPET: Incorporating Hierarchical Information Path into Multilingual ASR
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Wei Liu, Jingyong Hou, Dong Yang, Muyong Cao, Tan Lee
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kummervold24_interspeech.html">
                                <p>
                                    Whispering in Norwegian: Navigating Orthographic and Dialectic Challenges
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Per E Kummervold, Javier de la Rosa, Freddy Wetjen, Rolv-Arild Braaten, Per Erik Solberg
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="srivastava24_interspeech.html">
                                <p>
                                    EFFUSE: Efficient Self-Supervised Feature Fusion for E2E ASR in Low Resource and Multilingual Scenarios
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Tejes Srivastava, Jiatong Shi, William Chen, Shinji Watanabe
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="hussein24_interspeech.html">
                                <p>
                                    Enhancing Neural Transducer for Multilingual ASR with Synchronized Language Diarization
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Amir Hussein, Desh Raj, Matthew Wiesner, Daniel Povey, Paola Garcia, Sanjeev Khudanpur
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="ye24_interspeech.html">
                                <p>
                                    SC-MoE: Switch Conformer Mixture of Experts for Unified Streaming and Non-streaming Code-Switching ASR
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Shuaishuai Ye, Shunfei Chen, Xinhui Hu, Xinkang Xu
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Speech Assessment"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Speech Assessment</h4>
                            <hr>
                            <a class="w3-text" href="wu24i_interspeech.html">
                                <p>
                                    Optimizing Automatic Speech Assessment: W-RankSim Regularization and Hybrid Feature Fusion Strategies
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Chung-Wen Wu, Berlin Chen
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="cheng24b_interspeech.html">
                                <p>
                                    Context-Aware Speech Recognition Using Prompts for Language Learners
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jian Cheng
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="gothi24_interspeech.html">
                                <p>
                                    A Dataset and Two-pass System for Reading Miscue Detection
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Raj Gothi, Rahul Kumar, Mildred Pereira, Nagesh Nayak, Preeti Rao
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="lun24_interspeech.html">
                                <p>
                                    Oversampling, Augmentation and Curriculum Learning for Speaking Assessment with Limited Training Data
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Tin Mei Lun, Ekaterina Voskoboinik, Ragheb Al-Ghezi, Tamas Grosz, Mikko Kurimo
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="tomita24_interspeech.html">
                                <p>
                                    Analysis and Visualization of Directional Diversity in Listening Fluency of World Englishes Speakers in the Framework of Mutual Shadowing
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yu Tomita, Yingxiang Gao, Nobuaki Minematsu, Noriko Nakanishi, Daisuke Saito
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="robertson24_interspeech.html">
                                <p>
                                    Quantifying the Role of Textual Predictability in Automatic Speech Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Sean Robertson, Gerald Penn, Ewan Dunbar
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Question Answering from Speech and Spoken Dialogue Systems"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Question Answering from Speech and Spoken Dialogue Systems</h4>
                            <hr>
                            <a class="w3-text" href="rajkhowa24_interspeech.html">
                                <p>
                                    TM-PATHVQA: 90000+ Textless Multilingual Questions for Medical Visual Question Answering
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Tonmoy Rajkhowa, Amartya Roy Chowdhury, Sankalp Nagaonkar, Achyut Mani Tripathi, Mahadeva Prasanna
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="phukan24_interspeech.html">
                                <p>
                                    Towards Multilingual Audio-Visual Question Answering
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Orchid Chetia Phukan, Priyabrata Mallick, Swarup Ranjan Behera, Aalekhya Satya Narayani, Arun Balaji Buduru, Rajesh Sharma
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="nguyen24c_interspeech.html">
                                <p>
                                    Reinforcement Learning from Answer Reranking Feedback for Retrieval-Augmented Answer Generation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Minh Nguyen, Toan Quoc Nguyen, Kishan KC, Zeyu Zhang, Thuy Vu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="noroozi24_interspeech.html">
                                <p>
                                    Instruction Data Generation and Unsupervised Adaptation for Speech Language Models
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Vahid Noroozi, Zhehuai Chen, Somshubra Majumdar, Steve Huang, Jagadeesh Balam, Boris Ginsburg
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="dibratto24_interspeech.html">
                                <p>
                                    On the Use of Plausible Arguments in Explainable Conversational AI
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Martina Di Bratto, Maria Di Maro, Antonio Origlia
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="baihaqi24_interspeech.html">
                                <p>
                                    Rapport-Driven Virtual Agent: Rapport Building Dialogue Strategy for Improving User Experience at First Meeting
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Muhammad Yeza Baihaqi, Angel Garcia Contreras, Seiya Kawano, Koichiro Yoshino
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="zhou24c_interspeech.html">
                                <p>
                                    Cross-Modal Denoising: A Novel Training Paradigm for Enhancing Speech-Image Retrieval
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Lifeng Zhou, Yuke Li, Rui Deng, Yuting Yang, Haoqi Zhu
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Spoken Dialogue Systems and Conversational Analysis 3"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Spoken Dialogue Systems and Conversational Analysis 3</h4>
                            <hr>
                            <a class="w3-text" href="huang24b_interspeech.html">
                                <p>
                                    MM-NodeFormer: Node Transformer Multimodal Fusion for Emotion Recognition in Conversation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Zilong Huang, Man-Wai Mak, Kong Aik Lee
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="shi24d_interspeech.html">
                                <p>
                                    Emotional Cues Extraction and Fusion for Multi-modal Emotion Prediction and Recognition in Conversation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Haoxiang Shi, Ziqi Liang, Jun Yu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="suzuki24_interspeech.html">
                                <p>
                                    Participant-Pair-Wise Bottleneck Transformer for Engagement Estimation from Video Conversation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Keita Suzuki, Nobukatsu Hojo, Kazutoshi Shinoda, Saki Mizuno, Ryo Masumura
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="omahony24_interspeech.html">
                                <p>
                                    Well, what can you do with messy data? Exploring the prosody and pragmatic function of the discourse marker &quot;well&quot; with found data and speech synthesis
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Johannah O'Mahony, Catherine Lai, Ãva SzÃ©kely
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="shinoda24_interspeech.html">
                                <p>
                                    Learning from Multiple Annotator Biased Labels in Multimodal Conversation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Kazutoshi Shinoda, Nobukatsu Hojo, Saki Mizuno, Keita Suzuki, Satoshi Kobashikawa, Ryo Masumura
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="hoscilowicz24_interspeech.html">
                                <p>
                                    Non-Linear Inference Time Intervention: Improving LLM Truthfulness
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jakub Hoscilowicz, Adam Wiacek, Jan Chojnacki, Adam Cieslak, Leszek Michon, Artur Janicki
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="liu24c_interspeech.html">
                                <p>
                                    Evaluating Speech Recognition Performance Towards Large Language Model Based Voice Assistants
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Zhe Liu, Suyoun Kim, Ozlem Kalinli
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Dysarthric Speech Assessment"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Dysarthric Speech Assessment</h4>
                            <hr>
                            <a class="w3-text" href="zaheera24_interspeech.html">
                                <p>
                                    Automatic Assessment of Dysarthria using Speech and synthetically generated Electroglottograph signal
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Fathima Zaheera, Supritha Shetty, Gayadhar Pradhan, Deepak K T
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="wan24b_interspeech.html">
                                <p>
                                    CDSD: Chinese Dysarthria Speech Database
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yan Wan, Mengyi Sun, Xinchen Kang, Jingting Li, Pengfei Guo, Ming Gao, Su-Jing Wang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="samptur24_interspeech.html">
                                <p>
                                    Exploring Syllable Discriminability during Diadochokinetic Task with Increasing Dysarthria Severity for Patients with Amyotrophic Lateral Sclerosis
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Neelesh Samptur, Tanuka Bhattacharjee, Anirudh Chakravarty K, Seena Vengalil, Yamini Belur, Atchayaram Nalini, Prasanta Kumar Ghosh
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="perez24_interspeech.html">
                                <p>
                                    Beyond Binary: Multiclass Paraphasia Detection with Generative Pretrained Transformers and End-to-End Models
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Matthew Perez, Aneesha Sampath, Minxue Niu, Emily Mower Provost
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="daoudi24_interspeech.html">
                                <p>
                                    Electroglottography for the assessment of dysphonia in Parkinson's disease and multiple system atrophy
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Khalid Daoudi, Solange MilhÃ© de Saint Victor, Alexandra Foubert-Samier, Margherita Fabbri, Anne Pavy-Le Traon, Olivier Rascol, Virginie Woisard, Wassilios G. Meissner
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="chen24t_interspeech.html">
                                <p>
                                    CoLM-DSR: Leveraging Neural Codec Language Modeling for Multi-Modal Dysarthric Speech Reconstruction
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Xueyuan Chen, Dongchao Yang, Dingdong Wang, Xixin Wu, Zhiyong Wu, Helen Meng
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Spoken Language Models for Universal Speech Processing (Special Session)"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Spoken Language Models for Universal Speech Processing (Special Session)</h4>
                            <hr>
                            <a class="w3-text" href="li24qa_interspeech.html">
                                <p>
                                    On the Effectiveness of Acoustic BPE in Decoder-Only TTS
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Bohan Li, Feiyu Shen, Yiwei Guo, Shuai Wang, Xie Chen, Kai Yu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="chang24c_interspeech.html">
                                <p>
                                    Exploring In-Context Learning of Textless Speech Language Model for Speech Classification Tasks
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Kai-Wei Chang, Ming-Hao Hsu, Shan-Wen Li, Hung-yi Lee
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kuan24_interspeech.html">
                                <p>
                                    Understanding Sounds, Missing the Questions: The Challenge of Object Hallucination in Large Audio-Language Models
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Chun-Yi Kuan, Wei-Ping Huang, Hung-yi Lee
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="tang24d_interspeech.html">
                                <p>
                                    Can Large Language Models Understand Spatial Audio?
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Changli Tang, Wenyi Yu, Guangzhi Sun, Xianzhao Chen, Tian Tan, Wei Li, Jun Zhang, Lu Lu, Zejun Ma, Yuxuan Wang, Chao Zhang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="shon24_interspeech.html">
                                <p>
                                    DiscreteSLU: A Large Language Model with Self-Supervised Discrete Speech Units for Spoken Language Understanding
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Suwon Shon, Kwangyoun Kim, Yi-Te Hsu, Prashant Sridhar, Shinji Watanabe, Karen Livescu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="lu24c_interspeech.html">
                                <p>
                                    DeSTA: Enhancing Speech Language Models through Descriptive Speech-Text Alignment
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Ke-Han Lu, Zhehuai Chen, Szu-Wei Fu, He Huang, Boris Ginsburg, Yu-Chiang Frank Wang, Hung-yi Lee
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="pan24b_interspeech.html">
                                <p>
                                    COSMIC: Data Efficient Instruction-tuning For Speech In-Context Learning
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jing Pan, Jian Wu, Yashesh Gaur, Sunit Sivasankaran, Zhuo Chen, Shujie Liu, Jinyu Li
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="messica24_interspeech.html">
                                <p>
                                    NAST: Noise Aware Speech Tokenization for Speech Language Models
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Shoval Messica, Yossi Adi
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="shechtman24_interspeech.html">
                                <p>
                                    Low Bitrate High-Quality RVQGAN-based Discrete Speech Tokenizer
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Slava Shechtman, Avihu Dekel
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Keynote 4"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Keynote 4</h4>
                            <hr>
                            <a class="w3-text" href="tillmann24_interspeech.html">
                                <p>
                                    Perception of music and speech: Focus on rhythm processing
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Barbara Tillmann
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="L1/L2 Acquisition and Cross-Linguistic Factors"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">L1/L2 Acquisition and Cross-Linguistic Factors</h4>
                            <hr>
                            <a class="w3-text" href="hwang24b_interspeech.html">
                                <p>
                                    Acquisition of high vowel devoicing in Japanese: A production experiment with three and four year olds
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Hyun Kyung Hwang, Manami Hirayama
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="li24fa_interspeech.html">
                                <p>
                                    The Production of Contrastive Focus by  7 to 13-year-olds Learning Mandarin Chinese
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Zimeng Li, Zhongxuan Mao, Shengting Shen, Ivan Yuen, Ping Tang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="zaitova24_interspeech.html">
                                <p>
                                    Cross-Linguistic Intelligibility of Non-Compositional Expressions in Spoken Context
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Iuliia Zaitova, Irina Stenger, Wei Xue, Tania Avgustinova, Bernd MÃ¶bius, Dietrich Klakow
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="demaere24_interspeech.html">
                                <p>
                                    On the relationship between speech production and vocabulary size in 3-5 year olds
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Alexis DeMaere, Nicole van Rootselaar, Fangfang Li, Robbin Gibb, Claudia L. R. Gonzalez
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="polzehl24_interspeech.html">
                                <p>
                                    Towards Classifying Mother Tongue from Infant Cries - Findings Substantiating Prenatal Learning Theory
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Tim Polzehl, Tim Herzig, Friedrich Wicke, Kathleen Wermke, Razieh Khamsehashari, Michiko Dahlem, Sebastian MÃ¶ller
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="li24n_interspeech.html">
                                <p>
                                    Effect of Complex Boundary Tones on Tone Identification: An Experimental Study with Mandarin-speaking Preschool Children
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Aijun Li, Jun Gao, Zhiwei Wang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="truong24_interspeech.html">
                                <p>
                                    Ethnolinguistic Identification of Vietnamese-German Heritage Speech
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Thanh Lan Truong, Andrea Weber
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Speaker Stance, Emotion and Language-External Factors"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Speaker Stance, Emotion and Language-External Factors</h4>
                            <hr>
                            <a class="w3-text" href="hoffner24_interspeech.html">
                                <p>
                                    Joint prediction of subjective listening effort and speech intelligibility based on end-to-end learning
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Dirk Eike Hoffner, Jana RoÃbach, Bernd T. Meyer
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="wu24j_interspeech.html">
                                <p>
                                    Depression Enhances Internal Inconsistency between Spoken and Semantic Emotion: Evidence from the Analysis of Emotion Expression in Conversation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Xinyi Wu, Changqing Xu, Nan Li, Rongfeng Su, Lan Wang, Nan Yan
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="simantiraki24_interspeech.html">
                                <p>
                                    Listeners' F0 preferences in quiet and stationary noise
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Olympia Simantiraki, Martin Cooke
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="hodoshima24_interspeech.html">
                                <p>
                                    Effects of talker and playback rate of reverberation-induced speech on speech intelligibility of older adults
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Nao Hodoshima
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Experimental Phonetics and Laboratory Phonology"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Experimental Phonetics and Laboratory Phonology</h4>
                            <hr>
                            <a class="w3-text" href="zhao24i_interspeech.html">
                                <p>
                                    Age-related Differences in Acoustic Cues for the Perception of Checked Syllables in Shengzhou Wu
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Bingliang Zhao, Jiangping Kong, Xiyu Wu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kaland24b_interspeech.html">
                                <p>
                                    Quantity-sensitivity affects recall performance of word stress
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Constantijn Kaland, Maria Lialiou
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="tokac24_interspeech.html">
                                <p>
                                    Phonological Symmetry Does Not Predict Generalization of Perceptual Adaptation to Vowels
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Zuheyra Tokac, Jennifer Cole
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="reitsema24_interspeech.html">
                                <p>
                                    Perceptual Learning in Lexical Tone: Phonetic Similarity vs. Phonological Categories
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        AriÃ«lle Reitsema, Chenxin Li, Leanne van Lambalgen, Laura Preining, Saskia Galindo Jong, Qing Yang, Xinyi Wen, Yiya Chen
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="stein24_interspeech.html">
                                <p>
                                    Modeling probabilistic reduction across domains with Naive Discriminative Learning
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Anna Stein, Kevin Tang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="lee24l_interspeech.html">
                                <p>
                                    Do we EXPECT TO find phonetic traces for syntactic traces?
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jonathan Him Nok Lee, Mark Liberman, Martin Salzmann
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Speaker recognition evaluation and resources"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Speaker recognition evaluation and resources</h4>
                            <hr>
                            <a class="w3-text" href="lin24j_interspeech.html">
                                <p>
                                    VoxBlink2: A 100K+ Speaker Recognition Corpus and the Open-Set Speaker-Identification Benchmark
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yuke Lin, Ming Cheng, Fulin Zhang, Yingying Gao, Shilei Zhang, Ming Li
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="hutiri24_interspeech.html">
                                <p>
                                    As Biased as You Measure: Methodological Pitfalls of Bias Evaluations in Speaker Verification Research
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Wiebke Hutiri, Tanvina Patel, Aaron Yi Ding, Odette Scharenborg
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="wang24fa_interspeech.html">
                                <p>
                                    WeSep: A Scalable and Flexible Toolkit Towards Generalizable Target Speaker Extraction
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Shuai Wang, Ke Zhang, Shaoxiong Lin, Junjie Li, Xuefei Wang, Meng Ge, Jianwei Yu, Yanmin Qian, Haizhou Li
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="jung24c_interspeech.html">
                                <p>
                                    ESPnet-SPK: full pipeline speaker embedding toolkit with reproducible recipes, self-supervised front-ends, and off-the-shelf models
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jee-weon Jung, Wangyou Zhang, Jiatong Shi, Zakaria Aldeneh, Takuya Higuchi, Alex Gichamba, Barry-John Theobald, Ahmed Hussen Abdelaziz, Shinji Watanabe
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="huang24g_interspeech.html">
                                <p>
                                    Active Speaker Detection in Fisheye Meeting Scenes with Scene Spatial Spectrums
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Xinghao Huang, Weiwei Jiang, Long Rao, Wei Xu, Wenqing Cheng
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="hoang24b_interspeech.html">
                                <p>
                                    VSASV: a Vietnamese Dataset for Spoofing-Aware Speaker Verification
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Vu Hoang, Viet Thanh Pham, Hoa Nguyen Xuan, Pham Nhi, Phuong Dat, Thi Thu Trang Nguyen
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Speech Type Classification"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Speech Type Classification</h4>
                            <hr>
                            <a class="w3-text" href="ma24_interspeech.html">
                                <p>
                                    E-ODN: An Emotion Open Deep Network for Generalised and Adaptive Speech Emotion Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Liuxian Ma, Lin Shen, Ruobing Li, Haojie Zhang, Kun Qian, Bin Hu, BjÃ¶rn W. Schuller, Yoshiharu Yamamoto
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="liu24h_interspeech.html">
                                <p>
                                    Enhancing Multilingual Voice Toxicity Detection with Speech-Text Alignment
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Joseph Liu, Mahesh Kumar Nandwana, Janne PylkkÃ¶nen, Hannes Heikinheimo, Morgan McGuire
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="nafea24_interspeech.html">
                                <p>
                                    AraOffence: Detecting Offensive Speech Across Dialects in Arabic Media
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Youssef Nafea, Shady Shehata, Zeerak Talat, Ahmed Aboeitta, Ahmed Sharshar, Preslav Nakov
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="cheng24c_interspeech.html">
                                <p>
                                    CogniVoice: Multimodal and Multilingual Fusion Networks for Mild Cognitive Impairment Assessment from Spontaneous Speech
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jiali Cheng, Mohamed Elgaar, Nidhi Vakil, Hadi Amiri
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="niu24b_interspeech.html">
                                <p>
                                    Speech Topic Classification Based on Multi-Scale and Graph Attention Networks
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Fangjing Niu, Xiaozhe Qi, Xinya Chen, Liang He
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="chen24r_interspeech.html">
                                <p>
                                    Enhancing Speech and Music Discrimination Through the Integration of Static and Dynamic Features
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Liangwei Chen, Xiren Zhou, Qiang Tu, Huanhuan Chen
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Target Speaker Extraction"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Target Speaker Extraction</h4>
                            <hr>
                            <a class="w3-text" href="meng24b_interspeech.html">
                                <p>
                                    Binaural Selective Attention Model for Target Speaker Extraction
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Hanyu Meng, Qiquan Zhang, Xiangyu Zhang, Vidhyasaharan Sethu, Eliathamby Ambikairajah
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="pandey24_interspeech.html">
                                <p>
                                    All Neural Low-latency Directional Speech Extraction
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Ashutosh Pandey, Sanha Lee, Juan Azcarreta, Daniel Wong, Buye Xu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="heo24_interspeech.html">
                                <p>
                                    Centroid Estimation with Transformer-Based Speaker Embedder for Robust Target Speaker Extraction
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Woon-Haeng Heo, Joongyu Maeng, Yoseb Kang, Namhyun Cho
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="srinivas24_interspeech.html">
                                <p>
                                    Knowledge boosting during low-latency inference
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Vidya Srinivas, Malek Itani, Tuochao Chen, Emre Sefik Eskimez, Takuya Yoshioka, Shyamnath Gollakota
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="wu24h_interspeech.html">
                                <p>
                                    Unified Audio Visual Cues for Target Speaker Extraction
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Tianci Wu, Shulin He, Jiahui Pan, Haifeng Huang, Zhijian Mo, Xueliang Zhang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="liu24j_interspeech.html">
                                <p>
                                    Target Speaker Extraction with Curriculum Learning
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yun Liu, Xuechen Liu, Xiaoxiao Miao, Junichi Yamagishi
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Speech Synthesis: Voice Conversion 3"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Speech Synthesis: Voice Conversion 3</h4>
                            <hr>
                            <a class="w3-text" href="bai24_interspeech.html">
                                <p>
                                    SPA-SVC: Self-supervised Pitch Augmentation for Singing Voice Conversion
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Bingsong Bai, Fengping Wang, Yingming Gao, Ya Li
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="salman24_interspeech.html">
                                <p>
                                    Towards Naturalistic Voice Conversion: NaturalVoices Dataset with an Automatic Processing Pipeline
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Ali N. Salman, Zongyang Du, Shreeram Suresh Chandra, Ä°smail Rasim Ãlgen, Carlos Busso, Berrak Sisman
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="tanaka24_interspeech.html">
                                <p>
                                    PRVAE-VC2: Non-Parallel Voice Conversion by Distillation of Speech Representations
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Kou Tanaka, Hirokazu Kameoka, Takuhiro Kaneko, Yuto Kondo
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="niu24_interspeech.html">
                                <p>
                                    HybridVC: Efficient Voice Style Conversion with Text and Audio Prompts
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Xinlei Niu, Jing Zhang, Charles Patrick Martin
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="hai24_interspeech.html">
                                <p>
                                    DreamVoice: Text-Guided Voice Conversion
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jiarui Hai, Karan Thakkar, Helin Wang, Zengyi Qin, Mounya Elhilali
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="lee24d_interspeech.html">
                                <p>
                                    Hear Your Face: Face-based voice conversion with F0 estimation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jaejun Lee, Yoori Oh, Injune Hwang, Kyogu Lee
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="siriwardena24_interspeech.html">
                                <p>
                                    Accent Conversion with Articulatory Representations
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yashish M. Siriwardena, Nathan Swedlow, Audrey Howard, Evan Gitterman, Dan Darcy, Carol Espy-Wilson, Andrea Fanelli
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="huang24e_interspeech.html">
                                <p>
                                    USD-AC: Unsupervised Speech Disentanglement for Accent Conversion
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jen-Hung Huang, Wei-Tsung Lee, Chung-Hsien Wu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kanagawa24b_interspeech.html">
                                <p>
                                    Knowledge Distillation from Self-Supervised Representation Learning Model with Discrete Speech Units for Any-to-Any Streaming Voice Conversion
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Hiroki Kanagawa, Yusuke Ijima
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Speech Synthesis: Paradigms and Methods 3"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Speech Synthesis: Paradigms and Methods 3</h4>
                            <hr>
                            <a class="w3-text" href="yang24l_interspeech.html">
                                <p>
                                    SimpleSpeech: Towards Simple and Efficient Text-to-Speech with Scalar Latent Transformer Diffusion Models
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Dongchao Yang, Dingdong Wang, Haohan Guo, Xueyuan Chen, Xixin Wu, Helen Meng
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="lovelace24_interspeech.html">
                                <p>
                                    Sample-Efficient Diffusion for Text-To-Speech Synthesis
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Justin Lovelace, Soham Ray, Kwangyoun Kim, Kilian Q. Weinberger, Felix Wu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="feng24d_interspeech.html">
                                <p>
                                    Exploring the Robustness of Text-to-Speech Synthesis Based on Diffusion Probabilistic Models to Heavily Noisy Transcriptions
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jingyi Feng, Yusuke Yasuda, Tomoki Toda
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kim24_interspeech.html">
                                <p>
                                    VoiceTailor: Lightweight Plug-In Adapter for Diffusion-Based Personalized Text-to-Speech
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Heeseung Kim, Sang-gil Lee, Jiheum Yeom, Che Hyun Lee, Sungwon Kim, Sungroh Yoon
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="sadekova24_interspeech.html">
                                <p>
                                    PitchFlow: adding pitch control to a Flow-matching based TTS model
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Tasnima Sadekova, Mikhail Kudinov, Vadim Popov, Assel Yermekova, Artem Khrapov
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="yang24q_interspeech.html">
                                <p>
                                    DualSpeech: Enhancing Speaker-Fidelity and Text-Intelligibility Through Dual Classifier-Free Guidance
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jinhyeok Yang, Junhyeok Lee, Hyeong-Seok Choi, Seunghoon Ji, Hyeongju Kim, Juheon Lee
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="chen24q_interspeech.html">
                                <p>
                                    Generating Speakers by Prompting Listener Impressions for Pre-trained Multi-Speaker Text-to-Speech Systems
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Zhengyang Chen, Xuechen Liu, Erica Cooper, Junichi Yamagishi, Yanmin Qian
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="song24b_interspeech.html">
                                <p>
                                    TacoLM: GaTed Attention Equipped Codec Language Model are Efficient Zero-Shot Text to Speech Synthesizers
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yakun Song, Zhuo Chen, Xiaofei Wang, Ziyang Ma, Guanrou Yang, Xie Chen
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Privacy and Security in Speech Communication 2"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Privacy and Security in Speech Communication 2</h4>
                            <hr>
                            <a class="w3-text" href="ghosh24_interspeech.html">
                                <p>
                                    Anonymising Elderly and Pathological Speech: Voice Conversion Using DDSP and Query-by-Example
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Suhita Ghosh, Melanie Jouaiti, Arnab Das, Yamini Sinha, Tim Polzehl, Ingo Siegert, Sebastian Stober
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="wang24ha_interspeech.html">
                                <p>
                                    Asynchronous Voice Anonymization Using Adversarial Perturbation On Speaker Embedding
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Rui Wang, Liping Chen, Kong Aik Lee, Zhen-Hua Ling
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="meyer24_interspeech.html">
                                <p>
                                    Probing the Feasibility of Multilingual Speaker Anonymization
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Sarina Meyer, Florian Lux, Ngoc Thang Vu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="huang24_interspeech.html">
                                <p>
                                    DiffVC+: Improving Diffusion-based Voice Conversion for Speaker Anonymization
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Fan Huang, Kun Zeng, Wei Zhu
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Streaming ASR"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Streaming ASR</h4>
                            <hr>
                            <a class="w3-text" href="yang24m_interspeech.html">
                                <p>
                                    Learning from Back Chunks: Acquiring More Future Knowledge for Streaming ASR Models via Self Distillation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yuting Yang, Guodong Ma, Yuke Li, Binbin Du, Haoqi Zhu, Liang Ruan
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="tsunoo24_interspeech.html">
                                <p>
                                    Decoder-only Architecture for Streaming End-to-end Speech Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Emiru Tsunoo, Hayato Futami, Yosuke Kashiwagi, Siddhant Arora, Shinji Watanabe
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="chen24u_interspeech.html">
                                <p>
                                    Streaming Decoder-Only Automatic Speech Recognition with Discrete Speech Units: A Pilot Study
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Peikun Chen, Sining Sun, Changhao Shan, Qing Yang, Lei Xie
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="heitkaemper24_interspeech.html">
                                <p>
                                    TfCleanformer: A streaming, array-agnostic, full- and sub-band modeling front-end for robust ASR
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jens Heitkaemper, Joe Caroselli, Arun Narayanan, Nathan Howard
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="le24_interspeech.html">
                                <p>
                                    Improving Streaming Speech Recognition With Time-Shifted Contextual Attention And Dynamic Right Context Masking
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Khanh Le, Duc Chau
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="wang24ea_interspeech.html">
                                <p>
                                    Simul-Whisper: Attention-Guided Streaming Whisper with Truncation Detection
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Haoyu Wang, Guoqiang Hu, Guodong Lin, Wei-Qiang Zhang, Jian Li
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Computational Resource Constrained ASR"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Computational Resource Constrained ASR</h4>
                            <hr>
                            <a class="w3-text" href="xiao24b_interspeech.html">
                                <p>
                                    Dynamic Data Pruning for Automatic Speech Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Qiao Xiao, Pingchuan Ma, Adriana Fernandez-Lopez, Boqian Wu, Lu Yin, Stavros Petridis, Mykola Pechenizkiy, Maja Pantic, Decebal Constantin Mocanu, Shiwei Liu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kim24k_interspeech.html">
                                <p>
                                    Mitigating Overfitting in Structured Pruning of ASR Models with Gradient-Guided Parameter Regularization
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Dong-Hyun Kim, Joon-Hyuk Chang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="gu24_interspeech.html">
                                <p>
                                    SparseWAV: Fast and Accurate One-Shot Unstructured Pruning for Large Speech Foundation Models
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Tianteng Gu, Bei Liu, Hang Shao, Yanmin Qian
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="li24o_interspeech.html">
                                <p>
                                    One-pass Multiple Conformer and Foundation Speech Systems Compression and Quantization Using An All-in-one Neural Model
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Zhaoqing Li, Haoning Xu, Tianzi Wang, Shoukang Hu, Zengrui Jin, Shujie Hu, Jiajun Deng, Mingyu Cui, Mengzhe Geng, Xunying Liu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="rybakov24_interspeech.html">
                                <p>
                                    USM RNN-T model weights binarization
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Oleg Rybakov, Dmitriy Serdyuk, Chengjian Zheng
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="lin24d_interspeech.html">
                                <p>
                                    DAISY: Data Adaptive Self-Supervised Early Exit for Speech Representation Models
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Tzu-Quan Lin, Hung-yi Lee, Hao Tang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="park24_interspeech.html">
                                <p>
                                    RepTor: Re-parameterizable Temporal Convolution for Keyword Spotting via Differentiable Kernel Search
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Eunik Park, Daehyun Ahn, Hyungjun Kim
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="wang24p_interspeech.html">
                                <p>
                                    Global-Local Convolution with Spiking Neural Networks for Energy-efficient Keyword Spotting
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Shuai Wang, Dehao Zhang, Kexin Shi, Yuchen Wang, Wenjie Wei, Jibin Wu, Malu Zhang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="song24c_interspeech.html">
                                <p>
                                    ED-sKWS: Early-Decision Spiking Neural Networks for Rapid, and Energy-Efficient Keyword Spotting
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Zeyang Song, Qianhui Liu, Qu Yang, Yizhou Peng, Haizhou Li
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="ling24_interspeech.html">
                                <p>
                                    A Small and Fast BERT for Chinese Medical Punctuation Restoration
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Tongtao Ling, Yutao Lai, Lei Chen, Shilei Huang, Yi Liu
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Evaluation of Speech Technology Systems"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Evaluation of Speech Technology Systems</h4>
                            <hr>
                            <a class="w3-text" href="heuser24_interspeech.html">
                                <p>
                                    Quantification of stylistic differences in human- and ASR-produced transcripts of African American English
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Annika Heuser, Tyler Kendall, Miguel del Rio, Quinn McNamara, Nishchal Bhandari, Corey Miller, MigÃ¼el JettÃ©
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kuhn24_interspeech.html">
                                <p>
                                    Beyond Levenshtein: Leveraging Multiple Algorithms for Robust Word Error Rate Computations And Granular Error Classifications
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Korbinian Kuhn, Verena Kersken, Gottfried Zimmermann
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="teleki24_interspeech.html">
                                <p>
                                    Comparing ASR Systems in the Context of Speech Disfluencies
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Maria Teleki, Xiangjue Dong, Soohwan Kim, James Caverlee
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="lu24d_interspeech.html">
                                <p>
                                    Deep Prosodic Features in Tandem with Perceptual Judgments of Word Reduction for Tone Recognition in Conversed Speech
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Xiang-Li Lu, Yi-Fen Liu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="sasindran24_interspeech.html">
                                <p>
                                    SeMaScore: A new evaluation metric for automatic speech recognition tasks
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Zitha Sasindran, Harsha Yelchuri, T. V. Prabhakar
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Neural Network Training for Speech Recognition"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Neural Network Training for Speech Recognition</h4>
                            <hr>
                            <a class="w3-text" href="xu24_interspeech.html">
                                <p>
                                    Dynamic Encoder Size Based on Data-Driven Layer-wise Pruning for Speech Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jingjing Xu, Wei Zhou, Zijian Yang, Eugen Beck, Ralf SchlÃ¼ter
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="hou24_interspeech.html">
                                <p>
                                    Revisiting Convolution-free Transformer for Speech Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Zejiang Hou, Goeric Huybrechts, Anshu Bhatia, Daniel Garcia-Romero, Kyu J. Han, Katrin Kirchhoff
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="huang24c_interspeech.html">
                                <p>
                                    Optimizing Large-Scale Context Retrieval for End-to-End ASR
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Zhiqi Huang, Diamantino Caseiro, Kandarp Joshi, Christopher Li, Pat Rondon, Zelin Wu, Petr Zadrazil, Lillian Zhou
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="choi24b_interspeech.html">
                                <p>
                                    Self-Supervised Speech Representations are More Phonetic than Semantic
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Kwanghee Choi, Ankita Pasad, Tomohiko Nakamura, Satoru Fukayama, Karen Livescu, Shinji Watanabe
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="han24_interspeech.html">
                                <p>
                                    Enhancing CTC-based speech recognition with diverse modeling units
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Shiyi Han, Mingbin Xu, Zhihong Lei, Zhen Huang, Xingyu Na
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kim24d_interspeech.html">
                                <p>
                                    Guiding Frame-Level CTC Alignments Using Self-knowledge Distillation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Eungbeom Kim, Hantae Kim, Kyogu Lee
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Leveraging Large Language Models and Contextual Features for Phonetic Analysis (Special Session)"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Leveraging Large Language Models and Contextual Features for Phonetic Analysis (Special Session)</h4>
                            <hr>
                            <a class="w3-text" href="deheerkloots24_interspeech.html">
                                <p>
                                    Human-like Linguistic Biases in Neural Speech Models: Phonetic Categorization and Phonotactic Constraints in Wav2Vec2.0
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Marianne de Heer Kloots, Willem Zuidema
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="lin24e_interspeech.html">
                                <p>
                                    Exploring Pre-trained Speech Model for Articulatory Feature Extraction in Dysarthric Speech Using ASR
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yuqin Lin, Longbiao Wang, Jianwu Dang, Nobuaki Minematsu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="hao24c_interspeech.html">
                                <p>
                                    Exploring Self-Supervised Speech Representations for Cross-lingual Acoustic-to-Articulatory Inversion
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yun Hao, Reihaneh Amooie, Wietse de Vries, Thomas Tienkamp, Rik van Noord, Martijn Wieling
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="shams24_interspeech.html">
                                <p>
                                    Are Articulatory Feature Overlaps Shrouded in Speech Embeddings?
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Erfan A. Shams, Iona Gessinger, Patrick Cormac English, Julie Carson-Berndsen
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="english24_interspeech.html">
                                <p>
                                    Searching for Structure: Appraising the Organisation of Speech Features in wav2vec 2.0 Embeddings
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Patrick Cormac English, John D. Kelleher, Julie Carson-Berndsen
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Responsible Speech Foundation Models (Special Session)"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Responsible Speech Foundation Models (Special Session)</h4>
                            <hr>
                            <a class="w3-text" href="wiepert24_interspeech.html">
                                <p>
                                    Speech foundation models in healthcare: Effect of layer selection on pathological speech feature prediction
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Daniela A. Wiepert, Rene L. Utianski, Joseph R. Duffy, John L. Stricker, Leland R. Barnard, David T. Jones, Hugo Botha
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="wagner24_interspeech.html">
                                <p>
                                    Outlier Reduction with Gated Attention for Improved Post-training Quantization in Large Sequence-to-sequence Speech Foundation Models
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Dominik Wagner, Ilja Baumann, Korbinian Riedhammer, Tobias Bocklet
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kulkarni24_interspeech.html">
                                <p>
                                    Unveiling Biases while Embracing Sustainability: Assessing the Dual Challenges of Automatic Speech Recognition Systems
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Ajinkya Kulkarni, Atharva Kulkarni, Miguel Couceiro, Isabel Trancoso
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="lin24i_interspeech.html">
                                <p>
                                    Emo-bias: A Large Scale Evaluation of Social Bias on Speech Emotion Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yi-Cheng Lin, Haibin Wu, Huang-Cheng Chou, Chi-Chun Lee, Hung-yi Lee
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="lin24b_interspeech.html">
                                <p>
                                    On the social bias of speech self-supervised models
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yi-Cheng Lin, Tzu-Quan Lin, Hsi-Che Lin, Andy T. Liu, Hung-yi Lee
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="chang24d_interspeech.html">
                                <p>
                                    Self-supervised Speech Representations Still Struggle with African American Vernacular English
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Kalvin Chang, Yi-Hui Chou, Jiatong Shi, Hsuan-Ming Chen, Nicole Holliday, Odette Scharenborg, David R. Mortensen
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="aldeneh24_interspeech.html">
                                <p>
                                    Can you Remove the Downstream Model for Speaker Recognition with Self-Supervised Speech Features?
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Zakaria Aldeneh, Takuya Higuchi, Jee-weon Jung, Skyler Seto, Tatiana Likhomanenko, Stephen Shum, Ahmed Hussen Abdelaziz, Shinji Watanabe, Barry-John Theobald
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="meng24c_interspeech.html">
                                <p>
                                    Empowering Whisper as a Joint Multi-Talker and Target-Talker Speech Recognition System
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Lingwei Meng, Jiawen Kang, Yuejiao Wang, Zengrui Jin, Xixin Wu, Xunying Liu, Helen Meng
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Multimodal Paralinguistics"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Multimodal Paralinguistics</h4>
                            <hr>
                            <a class="w3-text" href="cai24b_interspeech.html">
                                <p>
                                    LoRA-MER: Low-Rank Adaptation of Pre-Trained Speech Models for Multimodal Emotion Recognition Using Mutual Information
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yunrui Cai, Zhiyong Wu, Jia Jia, Helen Meng
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="li24z_interspeech.html">
                                <p>
                                    Enhancing Modal Fusion by Alignment and Label Matching for Multimodal Emotion Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Qifei Li, Yingming Gao, Yuhua Wen, Cong Wang, Ya Li
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="zhu24_interspeech.html">
                                <p>
                                    Prompt Link Multimodal Fusion in Multimodal Sentiment Analysis
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Kang Zhu, Cunhang Fan, Jianhua Tao, Zhao Lv
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="wang24r_interspeech.html">
                                <p>
                                    A multimodal analysis of different types of laughter expression in conversational dialogues
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Kexin Wang, Carlos Ishi, Ryoko Hayashi
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="chochlakis24_interspeech.html">
                                <p>
                                    Tackling Missing Modalities in Audio-Visual Representation Learning Using Masked Autoencoders
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Georgios Chochlakis, Chandrashekhar Lavania, Prashant Mathur, Kyu J. Han
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kyung24_interspeech.html">
                                <p>
                                    Enhancing Multimodal Emotion Recognition through ASR Error Compensation and LLM Fine-Tuning
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jehyun Kyung, Serin Heo, Joon-Hyuk Chang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="goncalves24_interspeech.html">
                                <p>
                                    Bridging Emotions Across Languages: Low Rank Adaptation for Multilingual Speech Emotion Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Lucas Goncalves, Donita Robinson, Elizabeth Richerson, Carlos Busso
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Automatic Emotion Recognition"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Automatic Emotion Recognition</h4>
                            <hr>
                            <a class="w3-text" href="upadhyay24_interspeech.html">
                                <p>
                                    A Layer-Anchoring Strategy for Enhancing Cross-Lingual Speech Emotion Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Shreya G. Upadhyay, Carlos Busso, Chi-Chun Lee
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="phukan24b_interspeech.html">
                                <p>
                                    Are Paralinguistic Representations all that is needed for Speech Emotion Recognition?
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Orchid Chetia Phukan, Gautam Siddharth Kashyap, Arun Balaji Buduru, Rajesh Sharma
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="sun24b_interspeech.html">
                                <p>
                                    MFSN: Multi-perspective Fusion Search Network For Pre-training Knowledge in Speech Emotion Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Haiyang Sun, Fulin Zhang, Yingying Gao, Shilei Zhang, Zheng Lian, Junlan Feng
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="khaertdinov24_interspeech.html">
                                <p>
                                    Exploring Self-Supervised Multi-view Contrastive Learning for Speech Emotion Recognition with Limited Annotations
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Bulat Khaertdinov, Pedro Jeruis, Annanda Sousa, Enrique Hortal
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Self and Weakly-Labelled Speaker Verification"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Self and Weakly-Labelled Speaker Verification</h4>
                            <hr>
                            <a class="w3-text" href="wang24z_interspeech.html">
                                <p>
                                    Self-Supervised Speaker Verification with Mini-Batch Prediction Correction
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Junxu Wang, Zhihua Fang, Liang He
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="li24q_interspeech.html">
                                <p>
                                    SCDNet: Self-supervised Learning Feature based Speaker Change Detection
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yue Li, Xinsheng Wang, Li Zhang, Lei Xie
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="jin24c_interspeech.html">
                                <p>
                                    Self-Supervised Learning with Multi-Head Multi-Mode Knowledge Distillation for Speaker Verification
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Zezhong Jin, Youzhi Tu, Man-Wai Mak
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="selvakumar24_interspeech.html">
                                <p>
                                    Getting More for Less: Using Weak Labels and AV-Mixup for Robust Audio-Visual Speaker Verification
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Anith Selvakumar, Homa Fashandi
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Acoustic Event Detection, Segmentation and Classification"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Acoustic Event Detection, Segmentation and Classification</h4>
                            <hr>
                            <a class="w3-text" href="behera24_interspeech.html">
                                <p>
                                    FastAST: Accelerating Audio Spectrogram Transformer via Token Merging and Cross-Model Knowledge Distillation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Swarup Ranjan Behera, Abhishek Dhiman, Karthik Gowda, Aalekhya Satya Narayani
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="xiao24_interspeech.html">
                                <p>
                                    LungAdapter: Efficient Adapting Audio Spectrogram Transformer for Lung Sound Classification
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Li Xiao, Lucheng Fang, Yuhong Yang, Weiping Tu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="feng24c_interspeech.html">
                                <p>
                                    ElasticAST: An Audio Spectrogram Transformer for All Length and Resolutions
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jiu Feng, Mehmet Hamza Erol, Joon Son Chung, Arda Senocak
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="omine24_interspeech.html">
                                <p>
                                    Robust Laughter Segmentation with Automatic Diverse Data Synthesis
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Taisei Omine, Kenta Akita, Reiji Tsuruno
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="lebourdais24_interspeech.html">
                                <p>
                                    Explainable by-design Audio Segmentation through Non-Negative Matrix Factorization and Probing
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Martin Lebourdais, ThÃ©o Mariotte, Antonio AlmudÃ©var, Marie Tahon, Alfonso Ortega
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="elbanna24_interspeech.html">
                                <p>
                                    Predicting Heart Activity from Speech using Data-driven and Knowledge-based features
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Gasser Elbanna, Zohreh Mostaani, Mathew Magimai.-Doss
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="morozova24_interspeech.html">
                                <p>
                                    Measuring acoustic dissimilarity of hierarchical markers in task-oriented dialogue with MFCC-based dynamic time warping
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Natalia Morozova, Guanghao You, Sabine Stoll, Adrian Bangerter
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="buddi24_interspeech.html">
                                <p>
                                    Comparative Analysis of Personalized Voice Activity Detection Systems: Assessing Real-World Effectiveness
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Sai Srujana Buddi, Satyam Kumar, Utkarsh Sarawgi, Vineet Garg, Shivesh Ranjan, Ognjen Rudovic, Ahmed Hussen Abdelaziz, Saurabh Adya
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="wang24ca_interspeech.html">
                                <p>
                                    Generalized Fake Audio Detection via Deep Stable Learning
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Zhiyong Wang, Ruibo Fu, Zhengqi Wen, Yuankun Xie, Yukun Liu, Xiaopeng Wang, Xuefei Liu, Yongwei Li, Jianhua Tao, Xin Qi, Yi Lu, Shuchen Shi
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="palaskar24_interspeech.html">
                                <p>
                                    Multimodal Large Language Models with Fusion Low Rank Adaptation for Device Directed Speech Detection
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Shruti Palaskar, Ognjen Rudovic, Sameer Dharur, Florian Pesce, Gautam Krishna, Aswin Sivaraman, Jack Berkowitz, Ahmed Hussen Abdelaziz, Saurabh Adya, Ahmed Tewfik
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="zang24_interspeech.html">
                                <p>
                                    CtrSVDD: A Benchmark Dataset and Baseline Analysis for Controlled Singing Voice Deepfake Detection
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yongyi Zang, Jiatong Shi, You Zhang, Ryuichi Yamamoto, Jionghao Han, Yuxun Tang, Shengyuan Xu, Wenxiao Zhao, Jing Guo, Tomoki Toda, Zhiyao Duan
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="si24_interspeech.html">
                                <p>
                                    Fully Few-shot Class-incremental Audio Classification Using Expandable Dual-embedding Extractor
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yongjie Si, Yanxiong Li, Jialong Li, Jiaxin Tan, Qianhua He
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="a24_interspeech.html">
                                <p>
                                    Multi-label Bird Species Classification from Field Recordings using Mel_Graph-GCN Framework
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Noumida A, Rajeev Rajan
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Speech and Audio Modelling"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Speech and Audio Modelling</h4>
                            <hr>
                            <a class="w3-text" href="li24ha_interspeech.html">
                                <p>
                                    DiveSound: LLM-Assisted Automatic Taxonomy Construction for Diverse Audio Generation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Baihan Li, Zeyu Xie, Xuenan Xu, Yiwei Guo, Ming Yan, Ji Zhang, Kai Yu, Mengyue Wu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="wang24d_interspeech.html">
                                <p>
                                    Leveraging Language Model Capabilities for Sound Event Detection
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Hualei Wang, Jianguo Mao, Zhifang Guo, Jiarui Wan, Hong Liu, Xiangdong Wang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="xu24f_interspeech.html">
                                <p>
                                    Enhancing Zero-shot Audio Classification using Sound Attribute Knowledge from Large Language Models
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Xuenan Xu, Pingyue Zhang, Ming Yan, Ji Zhang, Mengyue Wu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="guan24b_interspeech.html">
                                <p>
                                    LAFMA: A Latent Flow Matching Model for Text-to-Audio Generation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Wenhao Guan, Kaidi Wang, Wangjin Zhou, Yang Wang, Feng Deng, Hui Wang, Lin Li, Qingyang Hong, Yong Qin
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="cumlin24_interspeech.html">
                                <p>
                                    DNSMOS Pro: A Reduced-Size DNN for Probabilistic MOS of Speech
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Fredrik Cumlin, Xinyu Liang, Victor Ungureanu, Chandan K. A. Reddy, Christian SchÃ¼ldt, Saikat Chatterjee
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="boukun24_interspeech.html">
                                <p>
                                    Blind Zero-Shot Audio Restoration: A Variational Autoencoder Approach for Denoising and Inpainting
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Veranika Boukun, Jakob Drefs, JÃ¶rg LÃ¼cke
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Fake Audio Detection"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Fake Audio Detection</h4>
                            <hr>
                            <a class="w3-text" href="pascu24_interspeech.html">
                                <p>
                                    Towards generalisable and calibrated audio deepfake detection with self-supervised representations
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Octavian Pascu, Adriana Stan, Dan Oneata, Elisabeta Oneata, Horia Cucu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="xie24_interspeech.html">
                                <p>
                                    Generalized Source Tracing: Detecting Novel Audio Deepfake Algorithm with Real Emphasis and Fake Dispersion Strategy
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yuankun Xie, Ruibo Fu, Zhengqi Wen, Zhiyong Wang, Xiaopeng Wang, Haonnan Cheng, Long Ye, Jianhua Tao
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="zhong24_interspeech.html">
                                <p>
                                    Enhancing Partially Spoofed Audio Localization with Boundary-aware Attention Mechanism
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jiafeng Zhong, Bin Li, Jiangyan Yi
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="chen24o_interspeech.html">
                                <p>
                                    Singing Voice Graph Modeling for SingFake Detection
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Xuanjun Chen, Haibin Wu, Roger Jang, Hung-yi Lee
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="wang24ga_interspeech.html">
                                <p>
                                    Genuine-Focused Learning using Mask AutoEncoder for Generalized Fake Audio Detection
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Xiaopeng Wang, Ruibo Fu, Zhengqi Wen, Zhiyong Wang, Yuankun Xie, Yukun Liu, Jianhua Tao, Xuefei Liu, Yongwei Li, Xin Qi, Yi Lu, Shuchen Shi
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kim24b_interspeech.html">
                                <p>
                                    One-class learning with adaptive centroid shift for audio deepfake detection
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Hyun Myung Kim, Kangwook Jang, Hoirin Kim
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Deep Learning-Based Speech Enhancement: Approaches, Scalability, and Evaluation"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Deep Learning-Based Speech Enhancement: Approaches, Scalability, and Evaluation</h4>
                            <hr>
                            <a class="w3-text" href="cao24_interspeech.html">
                                <p>
                                    VoiCor: A Residual Iterative Voice Correction Framework for Monaural Speech Enhancement
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Rui Cao, Tianrui Wang, Meng Ge, Andong Li, Longbiao Wang, Jianwu Dang, Yungang Jia
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="parnamaa24_interspeech.html">
                                <p>
                                    Personalized Speech Enhancement Without a Separate Speaker Embedding Model
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Tanel PÃ¤rnamaa, Ando Saabas
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="zhang24h_interspeech.html">
                                <p>
                                    URGENT Challenge: Universality, Robustness, and Generalizability For Speech Enhancement
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Wangyou Zhang, Robin Scheibler, Kohei Saijo, Samuele Cornell, Chenda Li, Zhaoheng Ni, Jan Pirklbauer, Marvin Sach, Shinji Watanabe, Tim Fingscheidt, Yanmin Qian
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="richter24_interspeech.html">
                                <p>
                                    EARS: An Anechoic Fullband Speech Dataset Benchmarked for Speech Enhancement and Dereverberation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Julius Richter, Yi-Chiao Wu, Steven Krenn, Simon Welker, Bunlong Lay, Shinji Watanabe, Alexander Richard, Timo Gerkmann
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Speech Synthesis: Other Topics 1"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Speech Synthesis: Other Topics 1</h4>
                            <hr>
                            <a class="w3-text" href="tan24c_interspeech.html">
                                <p>
                                    LiteFocus: Accelerated Diffusion Inference for Long Audio Synthesis
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Zhenxiong Tan, Xinyin Ma, Gongfan Fang, Xinchao Wang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kim24e_interspeech.html">
                                <p>
                                    Speak in the Scene: Diffusion-based Acoustic Scene Transfer toward Immersive Speech Generation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Miseul Kim, Soo-Whan Chung, Youna Ji, Hong-Goo Kang, Min-Seok Choi
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="li24y_interspeech.html">
                                <p>
                                    PL-TTS: A Generalizable Prompt-based Diffusion TTS Augmented by Large Language Model
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Shuhua Li, Qirong Mao, Jiatong Shi
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="abel24_interspeech.html">
                                <p>
                                    Towards realtime co-speech gestures synthesis using STARGATE
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Louis Abel, Vincent Colotte, Slim Ouni
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="shi24f_interspeech.html">
                                <p>
                                    PPPR: Portable Plug-in Prompt Refiner for Text to Audio Generation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Shuchen Shi, Ruibo Fu, Zhengqi Wen, Jianhua Tao, Tao Wang, Chunyu Qiang, Yi Lu, Xin Qi, Xuefei Liu, Yukun Liu, Yongwei Li, Zhiyong Wang, Xiaopeng Wang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="lee24m_interspeech.html">
                                <p>
                                    Neural ATSM: Fully Neural Network-based Adaptive Time-Scale Modification Using Sentence-Specific Dynamic Control
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jaeuk Lee, Sohee Jang, Joon-Hyuk Chang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="guo24c_interspeech.html">
                                <p>
                                    FLY-TTS: Fast, Lightweight and High-Quality End-to-End Text-to-Speech Synthesis
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yinlin Guo, Yening Lv, Jinqiao Dou, Yan Zhang, Yuehai Wang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kunesova24_interspeech.html">
                                <p>
                                    Zero-shot Out-of-domain is No Joke: Lessons Learned in the VoiceMOS 2023 MOS Prediction Challenge
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Marie KuneÅ¡ovÃ¡, Jan LeheÄka, Josef MichÃ¡lek, Jindrich Matousek, Jan Å vec
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="ward24_interspeech.html">
                                <p>
                                    Towards a General-Purpose Model of Perceived Pragmatic Similarity
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Nigel G. Ward, Andres Segura, Alejandro Ceballos, Divette Marco
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Speech Synthesis: Other Topics 2"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Speech Synthesis: Other Topics 2</h4>
                            <hr>
                            <a class="w3-text" href="ratsep24_interspeech.html">
                                <p>
                                    Enabling Conversational Speech Synthesis using Noisy Spontaneous Data
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Liisa RÃ¤tsep, Rasmus Lellep, Mark Fishel
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="yang24c_interspeech.html">
                                <p>
                                    Frame-Wise Breath Detection with Self-Training: An Exploration of Enhancing Breath Naturalness in Text-to-Speech
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Dong Yang, Tomoki Koriyama, Yuki Saito
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="seong24_interspeech.html">
                                <p>
                                    H4C-TTS: Leveraging Multi-Modal Historical Context for Conversational Text-to-Speech
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Donghyun Seong, Joon-Hyuk Chang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="yang24i_interspeech.html">
                                <p>
                                    Bilingual and Code-switching TTS Enhanced with Denoising Diffusion Model and GAN
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Huai-Zhe Yang, Chia-Ping Chen, Shan-Yun He, Cheng-Ruei Li
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="saeki24_interspeech.html">
                                <p>
                                    SpeechBERTScore: Reference-Aware Automatic Evaluation of Speech Generation Leveraging NLP Evaluation Metrics
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Takaaki Saeki, Soumi Maiti, Shinnosuke Takamichi, Shinji Watanabe, Hiroshi Saruwatari
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="yoon24b_interspeech.html">
                                <p>
                                    UNIQUE : Unsupervised Network for Integrated Speech Quality Evaluation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Juhwan Yoon, WooSeok Ko, Seyun Um, Sungwoong Hwang, Soojoong Hwang, Changhwan Kim, Hong-Goo Kang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="lee24_interspeech.html">
                                <p>
                                    FVTTS : Face Based Voice Synthesis for Text-to-Speech
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Minyoung Lee, Eunil Park, Sungeun Hong
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Speech synthesis: Cross-lingual and multilingual aspects"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Speech synthesis: Cross-lingual and multilingual aspects</h4>
                            <hr>
                            <a class="w3-text" href="lux24_interspeech.html">
                                <p>
                                    Meta Learning Text-to-Speech Synthesis in over 7000 Languages
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Florian Lux, Sarina Meyer, Lyonel Behringer, Frank Zalkow, Phat Do, Matt Coler, EmanuÃ«l A. P. Habets, Ngoc Thang Vu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="gong24c_interspeech.html">
                                <p>
                                    An Initial Investigation of Language Adaptation for TTS Systems under Low-resource Scenarios
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Cheng Gong, Erica Cooper, Xin Wang, Chunyu Qiang, Mengzhe Geng, Dan Wells, Longbiao Wang, Jianwu Dang, Marc Tessier, Aidan Pine, Korin Richmond, Junichi Yamagishi
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="wu24f_interspeech.html">
                                <p>
                                    Improving Multilingual Text-to-Speech with Mixture-of-Language-Experts and Accent Disentanglement
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jing Wu, Ting Chen, Minchuan Chen, Wei Hu, Shaojun Wang, Jing Xiao
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="xu24g_interspeech.html">
                                <p>
                                    Seamless Language Expansion: Enhancing Multilingual Mastery in Self-Supervised Models
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jing Xu, Minglin Wu, Xixin Wu, Helen Meng
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="casanova24_interspeech.html">
                                <p>
                                    XTTS: a Massively Multilingual Zero-Shot Text-to-Speech Model
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Edresson Casanova, Kelly Davis, Eren GÃ¶lge, GÃ¶rkem GÃ¶knar, Iulian Gulea, Logan Hart, Aya Aljafari, Joshua Meyer, Reuben Morais, Samuel Olayemi, Julian Weber
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="guo24b_interspeech.html">
                                <p>
                                    X-E-Speech: Joint Training Framework of Non-Autoregressive Cross-lingual Emotional Text-to-Speech and Voice Conversion
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Houjian Guo, Chaoran Liu, Carlos Toshinori Ishi, Hiroshi Ishiguro
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Noise, Far-Field, Multi-Talker, Enhancement, Audio Classification"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Noise, Far-Field, Multi-Talker, Enhancement, Audio Classification</h4>
                            <hr>
                            <a class="w3-text" href="shao24_interspeech.html">
                                <p>
                                    RIR-SF: Room Impulse Response Based Spatial Feature for Target Speech Recognition in Multi-Channel Multi-Speaker Scenarios
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yiwen Shao, Shi-Xiong Zhang, Dong Yu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="shao24b_interspeech.html">
                                <p>
                                    Multi-Channel Multi-Speaker ASR Using Target Speakerâs Solo Segment
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yiwen Shao, Shi-Xiong Zhang, Yong Xu, Meng Yu, Dong Yu, Daniel Povey, Sanjeev Khudanpur
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="ravenscroft24_interspeech.html">
                                <p>
                                    Transcription-Free Fine-Tuning of Speech Separation Models for Noisy and Reverberant Multi-Speaker Automatic Speech Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        William Ravenscroft, George Close, Stefan Goetze, Thomas Hain, Mohammad Soleymanpour, Anurag Chowdhury, Mark C. Fuhs
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="vinnikov24_interspeech.html">
                                <p>
                                    NOTSOFAR-1 Challenge: New Datasets, Baseline, and Tasks for Distant Meeting Transcription
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Alon Vinnikov, Amir Ivry, Aviv Hurvitz, Igor Abramovski, Sharon Koubi, Ilya Gurvich, Shai Peer, Xiong Xiao, Benjamin Martinez Elizalde, Naoyuki Kanda, Xiaofei Wang, Shalev Shaer, Stav Yagev, Yossi Asher, Sunit Sivasankaran, Yifan Gong, Min Tang, Huaming Wang, Eyal Krupka
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="dissen24_interspeech.html">
                                <p>
                                    Enhanced ASR Robustness to Packet Loss with a Front-End Adaptation Network
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yehoshua Dissen, Shiry Yonash, Israel Cohen, Joseph Keshet
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="haider24_interspeech.html">
                                <p>
                                    Hold Me Tight: Stable Encoder-Decoder Design for Speech Enhancement
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Daniel Haider, Felix Perfler, Vincent Lostanlen, Martin Ehler, Peter Balazs
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="wang24da_interspeech.html">
                                <p>
                                    DGSRN: Noise-Robust Speech Recognition Method with Dual-Path Gated Spectral Refinement Network
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Wenjun Wang, Shangbin Mo, Ling Dong, Zhengtao Yu, Junjun Guo, Yuxin Huang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="singh24b_interspeech.html">
                                <p>
                                    Towards Robust Few-shot Class Incremental Learning in Audio Classification using Contrastive Representation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Riyansha Singh, Parinita Nema, Vinod K Kurmi
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="sheikh24_interspeech.html">
                                <p>
                                    Bird Whisperer: Leveraging Large Pre-trained Acoustic Model for Bird Call Classification
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Muhammad Umer Sheikh, Hassan Abid, Bhuiyan Sanjid Shafique, Asif Hanif, Muhammad Haris Khan
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="sato24_interspeech.html">
                                <p>
                                    SpeakerBeam-SS: Real-time Target Speaker Extraction with Lightweight Conv-TasNet and State Space Modeling
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Hiroshi Sato, Takafumi Moriya, Masato Mimura, Shota Horiguchi, Tsubasa Ochiai, Takanori Ashihara, Atsushi Ando, Kentaro Shinayama, Marc Delcroix
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="borsdorf24_interspeech.html">
                                <p>
                                    wTIMIT2mix: A Cocktail Party Mixtures Database to Study Target Speaker Extraction for Normal and Whispered Speech
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Marvin Borsdorf, Zexu Pan, Haizhou Li, Tanja Schultz
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Self-Supervised Learning for ASR"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Self-Supervised Learning for ASR</h4>
                            <hr>
                            <a class="w3-text" href="getman24_interspeech.html">
                                <p>
                                    What happens in continued pre-training? Analysis of self-supervised speech models with continued pre-training for colloquial Finnish ASR
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yaroslav Getman, Tamas Grosz, Mikko Kurimo
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kato24_interspeech.html">
                                <p>
                                    Self-Supervised Learning for ASR Pre-Training with Uniquely Determined Target Labels and Controlling Cepstrum Truncation for Speech Augmentation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Akihiro Kato, Hiroyuki Nagano, Kohei Chike, Masaki Nose
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="yadav24b_interspeech.html">
                                <p>
                                    MS-HuBERT: Mitigating Pre-training and Inference Mismatch in Masked Language Modelling methods for learning Speech Representations
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Hemant Yadav, Sunayana Sitaram, Rajiv Ratn Shah
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="lee24k_interspeech.html">
                                <p>
                                    Balanced-Wav2Vec: Enhancing Stability and Robustness of Representation Learning Through Sample Reweighting Techniques
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Mun-Hak Lee, Jae-Hong Lee, DoHee Kim, Ye-Eun Ko, Joon-Hyuk Chang
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Spoken Term Detection and Speech Retrieval"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Spoken Term Detection and Speech Retrieval</h4>
                            <hr>
                            <a class="w3-text" href="yuan24b_interspeech.html">
                                <p>
                                    Few-Shot Keyword Spotting from Mixed Speech
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Junming Yuan, Ying Shi, LanTian Li, Dong Wang, Askar Hamdulla
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="yusuf24b_interspeech.html">
                                <p>
                                    Pretraining End-to-End Keyword Search with Automatically Discovered Acoustic Units
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Bolaji Yusuf, Jan Honza Cernocky, Murat SaraÃ§lar
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="he24_interspeech.html">
                                <p>
                                    2DP-2MRC: 2-Dimensional Pointer-based Machine Reading Comprehension Method for Multimodal Moment Retrieval
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jiajun He, Tomoki Toda
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="xie24c_interspeech.html">
                                <p>
                                    GPA: Global and Prototype Alignment for Audio-Text Retrieval
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yuxin Xie, Zhihong Zhu, Xianwei Zhuang, Liming Liang, Zhichang Wang, Yuexian Zou
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kim24r_interspeech.html">
                                <p>
                                    Few-Shot Keyword-Incremental Learning with Total Calibration
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Ilseok Kim, Ju-Seok Seong, Joon-Hyuk Chang
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="tapo24_interspeech.html">
                                <p>
                                    Leveraging Speech Data Diversity to Document Indigenous Heritage and Culture
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Allahsera Tapo, Ãric Le Ferrand, Zoey Liu, Christopher Homan, Emily Prud'hommeaux
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Speech Disorders 1"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Speech Disorders 1</h4>
                            <hr>
                            <a class="w3-text" href="mohapatra24_interspeech.html">
                                <p>
                                    Missingness-resilient Video-enhanced Multimodal Disfluency Detection
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Payal Mohapatra, Shamika Likhite, Subrata Biswas, Bashima Islam, Qi Zhu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="gong24_interspeech.html">
                                <p>
                                    AS-70: A Mandarin stuttered speech dataset for automatic speech recognition and stuttering event detection
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Rong Gong, Hongfei Xue, Lezhi Wang, Xin Xu, Qisheng Li, Lei Xie, Hui Bu, Shaomei Wu, Jiaming Zhou, Yong Qin, Binbin Zhang, Jun Du, Jia Bin, Ming Li
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="zulfikar24_interspeech.html">
                                <p>
                                    Analyzing Speech Motor Movement using Surface Electromyography in Minimally Verbal Adults with Autism Spectrum Disorder
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Wazeer Zulfikar, Nishat Protyasha, Camila Canales, Heli Patel, James Williamson, Laura Sarnie, Lisa Nowinski, Nataliya Kosmyna, Paige Townsend, Sophia Yuditskaya, Tanya Talkar, Utkarsh Oggy Sarawgi, Christopher McDougle, Thomas Quatieri, Pattie Maes, Maria Mody
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="zhang24f_interspeech.html">
                                <p>
                                    Prosody of speech production in latent post-stroke aphasia
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Cong Zhang, Tong Li, Gayle DeDe, Christos Salis
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="nie24_interspeech.html">
                                <p>
                                    MMSD-Net: Towards Multi-modal Stuttering Detection
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Liangyu Nie, Sudarsana Reddy Kadiri, Ruchit Agrawal
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="wagner24b_interspeech.html">
                                <p>
                                    Large Language Models for Dysfluency Detection in Stuttered Speech
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Dominik Wagner, Sebastian P. Bayerl, Ilja Baumann, Elmar Noeth, Korbinian Riedhammer, Tobias Bocklet
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Connecting Speech-science and Speech-technology for Childrenâs Speech (Special Session)"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Connecting Speech-science and Speech-technology for Childrenâs Speech (Special Session)</h4>
                            <hr>
                            <a class="w3-text" href="demopoulos24_interspeech.html">
                                <p>
                                    Preliminary Investigation of Psychometric Properties of a Novel Multimodal Dialog Based Affect Production Task in Children and Adolescents with Autism
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Carly Demopoulos, Linnea Lampinen, Cristian Preciado, Hardik Kothare, Vikram Ramanarayanan
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="charuau24_interspeech.html">
                                <p>
                                    Training speech-breathing coordination in computer-assisted reading
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Delphine Charuau, Andrea Briglia, Erika Godde, GÃ©rard Bailly
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="kadambi24_interspeech.html">
                                <p>
                                    How Does Alignment Error Affect Automated Pronunciation Scoring in Children's Speech?
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Prad Kadambi, Tristan Mahr, Lucas Annear, Henry Nomeland, Julie Liss, Katherine Hustad, Visar Berisha
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="benway24_interspeech.html">
                                <p>
                                    Examining Vocal Tract Coordination in Childhood Apraxia of Speech with Acoustic-to-Articulatory Speech Inversion Feature Sets
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Nina R. Benway, Jonathan L. Preston, Carol Espy-Wilson
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="sukhadia24_interspeech.html">
                                <p>
                                    Childrenâs Speech Recognition through Discrete Token Enhancement
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Vrunda N. Sukhadia, Shammur Absar Chowdhury
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="wang24f_interspeech.html">
                                <p>
                                    Bridging Child-Centered Speech Language Identification and Language Diarization via Phonetics
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yujia Wang, Hexin Liu, Leibny Paola Garcia
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="gao24d_interspeech.html">
                                <p>
                                    Reading Miscue Detection in Primary School through Automatic Speech Recognition
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Lingyun Gao, Cristian Tejedor-Garcia, Helmer Strik, Catia Cucchiarini
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="baumann24_interspeech.html">
                                <p>
                                    Automatic Evaluation of a Sentence Memory Test for Preschool Children
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Ilja Baumann, Nicole Unger, Dominik Wagner, Korbinian Riedhammer, Tobias Bocklet
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="li24j_interspeech.html">
                                <p>
                                    Enhancing Child Vocalization Classification with  Phonetically-Tuned Embeddings for Assisting Autism Diagnosis
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jialu Li, Mark Hasegawa-Johnson, Karrie Karahalios
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="blockmedin24_interspeech.html">
                                <p>
                                    Self-Supervised Models for Phoneme Recognition: Applications in Children's Speech for Reading Learning
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Lucas Block Medin, Thomas Pellegrini, Lucile Gelin
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="fan24b_interspeech.html">
                                <p>
                                    Benchmarking Children's ASR with Supervised and Self-supervised Speech Foundation Models
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Ruchao Fan, Natarajan Balaji Shankar, Abeer Alwan
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="rolland24_interspeech.html">
                                <p>
                                    Introduction To Partial Fine-tuning: A Comprehensive Evaluation Of End-to-end Childrenâs Automatic Speech Recognition Adaptation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Thomas Rolland, Alberto Abad
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="zhang24d_interspeech.html">
                                <p>
                                    Improving child speech recognition with augmented child-like speech
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Yuanyuan Zhang, Zhengjun Yue, Tanvina Patel, Odette Scharenborg
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="graave24_interspeech.html">
                                <p>
                                    Mixed Children/Adult/Childrenized Fine-Tuning for Childrenâs ASR: How to Reduce Age Mismatch and Speaking Style Mismatch
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Thomas Graave, Zhengyang Li, Timo Lohrenz, Tim Fingscheidt
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="xu24c_interspeech.html">
                                <p>
                                    Exploring Speech Foundation Models for Speaker Diarization in Child-Adult Dyadic Interactions
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Anfeng Xu, Kevin Huang, Tiantian Feng, Lue Shen, Helen Tager-Flusberg, Shrikanth Narayanan
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                    <div class="w3-content" style="height:10px"  id="Show and Tell 4"></div>
                    <div class="w3-card w3-round w3-white w3-padding">
                        <div class="w3-container"  style="margin-top:40px">
                            <h4 class="w3-center">Show and Tell 4</h4>
                            <hr>
                            <a class="w3-text" href="sirigiraju24_interspeech.html">
                                <p>
                                    IIITH Ucchar e-Sudharak: an automatic English pronunciation corrector for school-going children with a teacher in the loop
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Meenakshi Sirigiraju, Arjun Rajasekar, Abhishikth Meejuri, Chiranjeevi Yarra
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="yap24_interspeech.html">
                                <p>
                                    Speech enabled visual acuity test
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Boon Peng Yap, Kok Liang Tan, Zhenghao Li, Rong Tong
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="aiba24_interspeech.html">
                                <p>
                                    A ChatGPT-based oral Q&A practice system for first-time student participants in international conferences
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Mayuko Aiba, Daisuke Saito, Nobuaki Minematsu
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="sridaran24_interspeech.html">
                                <p>
                                    Visual scene display application for augmentative and alternative communication
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Karthik Venkat Sridaran, Raja Praveen, Reuben T Varghese, Ajish K Abraham, Shankar R, Winnie Rachel Cherian
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="masudakatsuse24_interspeech.html">
                                <p>
                                    CALL system using pitch-accent feature representations reflecting listenersâ subjective adequacy
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Ikuyo Masuda-Katsuse, Ayako Shirose
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="preston24_interspeech.html">
                                <p>
                                    The speech motor chaining web app for speech motor learning
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Jonathan L Preston, Nina R Benway, Nathan Prestopnik, Nathan Preston
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="yoder24_interspeech.html">
                                <p>
                                    Visualization for improving foreign language pronunciation
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Charlotte Yoder, Karrie Karahalios, Mark Hasegawa-Johnson, Shreyansh Agrawal
                                    </span>
                                </p>
                            </a>
                            <a class="w3-text" href="phan24b_interspeech.html">
                                <p>
                                    CaptainA self-study mobile app for practising speaking: task completion assessment and feedback with generative AI
                                    <br>
                                    <span class="w3-text w3-text-theme">
                                        Nhan Phan, Anna von Zansen, Maria Kautonen, TamÃ¡s GrÃ³sz, Mikko Kurimo
                                    </span>
                                </p>
                            </a>
                        </div>
                    </div>
                    <br>
                </div>
            </div>



            <!-- Paper search table -->
            <div class="w3-container" id="bypaper">
                <div class="w3-content" style="max-width:1200px;margin-top:60px">
                    <div class="w3-container w3-card w3-padding w3-white">
                        <div class="w3-text w3-center">
                            <span class='w3-large'>
                                <b>Search papers</b>
                            </span>
                            <button class='w3-text w3-button w3-right'
                                    onclick="document.getElementById('help_papers').style.display='block'">
                                <i class='icon-question-circle'></i>
                            </button>
                        </div>
                        <table id="paper_table" class="display" style="width:95%">
                            <thead>
                                <tr>
                                    <th width="100%">Article</th>
                                    <th width="0%"></th>
                                    <th width="0%"></th>
                                    <th width="0%"></th>
                                </tr>
                            </thead>
                        </table>
                    </div>
                    <!-- <p class="w3-small" style="margin-bottom: 50px"></p>   -->
                </div>
            </div>
        </div>

        <!-- Session chooser -->
        <div id="sessionchooser" class="w3-modal" >
            <div class="w3-modal-content w3-card-4 w3-greyscale w3-theme-d4 w3-padding w3-bordered" onclick="document.getElementById('sessionchooser').style.display='none'">
                <span onclick="document.getElementById('sessionchooser').style.display='none'"
                      class="w3-button w3-display-topright">&times;</span>
                <p><a class="w3-text" href="#Keynote 1 ISCA Medallist">Keynote 1 ISCA Medallist</a></p>
                <p><a class="w3-text" href="#L2 Speech, Bilingualism and Code-Switching">L2 Speech, Bilingualism and Code-Switching</a></p>
                <p><a class="w3-text" href="#Speaker Diarization 1">Speaker Diarization 1</a></p>
                <p><a class="w3-text" href="#Speech and Audio Analysis and Representations">Speech and Audio Analysis and Representations</a></p>
                <p><a class="w3-text" href="#Acoustic Event Detection and Classification 2">Acoustic Event Detection and Classification 2</a></p>
                <p><a class="w3-text" href="#Detection and Classification of Bioacoustic Signals">Detection and Classification of Bioacoustic Signals</a></p>
                <p><a class="w3-text" href="#Acoustic Echo Cancellation">Acoustic Echo Cancellation</a></p>
                <p><a class="w3-text" href="#Speech Synthesis: Voice Conversion 1">Speech Synthesis: Voice Conversion 1</a></p>
                <p><a class="w3-text" href="#Neural Network Architectures for ASR 2">Neural Network Architectures for ASR 2</a></p>
                <p><a class="w3-text" href="#Decoding Algorithms">Decoding Algorithms</a></p>
                <p><a class="w3-text" href="#Pronunciation Assessment">Pronunciation Assessment</a></p>
                <p><a class="w3-text" href="#Spoken Language Processing">Spoken Language Processing</a></p>
                <p><a class="w3-text" href="#Spoken Machine Translation 2">Spoken Machine Translation 2</a></p>
                <p><a class="w3-text" href="#Biosignal-enabled Spoken Communication">Biosignal-enabled Spoken Communication</a></p>
                <p><a class="w3-text" href="#Individual and Social Factors in Phonetics">Individual and Social Factors in Phonetics</a></p>
                <p><a class="w3-text" href="#Paralinguistics">Paralinguistics</a></p>
                <p><a class="w3-text" href="#Speaker Recognition: Adversarial and Spoofing Attacks">Speaker Recognition: Adversarial and Spoofing Attacks</a></p>
                <p><a class="w3-text" href="#Audio Event Detection and Classification 1">Audio Event Detection and Classification 1</a></p>
                <p><a class="w3-text" href="#Source Separation 2">Source Separation 2</a></p>
                <p><a class="w3-text" href="#Noise Reduction, Dereverberation, and Echo Cancellation">Noise Reduction, Dereverberation, and Echo Cancellation</a></p>
                <p><a class="w3-text" href="#Computationally-Efficient Speech Enhancement">Computationally-Efficient Speech Enhancement</a></p>
                <p><a class="w3-text" href="#Zero-shot TTS">Zero-shot TTS</a></p>
                <p><a class="w3-text" href="#Noise Robustness, Far-Field, and Multi-Talker ASR">Noise Robustness, Far-Field, and Multi-Talker ASR</a></p>
                <p><a class="w3-text" href="#Contextual Biasing and Adaptation">Contextual Biasing and Adaptation</a></p>
                <p><a class="w3-text" href="#Spoken Language Understanding">Spoken Language Understanding</a></p>
                <p><a class="w3-text" href="#Spoken Machine Translation 1">Spoken Machine Translation 1</a></p>
                <p><a class="w3-text" href="#Hearing Disorders">Hearing Disorders</a></p>
                <p><a class="w3-text" href="#Speech Disorders 2">Speech Disorders 2</a></p>
                <p><a class="w3-text" href="#TAUKADIAL Challenge: Speech-Based Cognitive Assessment in Chinese and English (Special Session)">TAUKADIAL Challenge: Speech-Based Cognitive Assessment in Chinese and English (Special Session)</a></p>
                <p><a class="w3-text" href="#Show and Tell 1">Show and Tell 1</a></p>
                <p><a class="w3-text" href="#Keynote 2">Keynote 2</a></p>
                <p><a class="w3-text" href="#Phonetics and Phonology of Second Language Acquisition">Phonetics and Phonology of Second Language Acquisition</a></p>
                <p><a class="w3-text" href="#Corpora-based Approaches in Automatic Emotion Recognition">Corpora-based Approaches in Automatic Emotion Recognition</a></p>
                <p><a class="w3-text" href="#Analysis of Speakers States and Traits">Analysis of Speakers States and Traits</a></p>
                <p><a class="w3-text" href="#Spoofing and Deepfake Detection">Spoofing and Deepfake Detection</a></p>
                <p><a class="w3-text" href="#Audio Captioning, Tagging, and Audio-Text Retrieval">Audio Captioning, Tagging, and Audio-Text Retrieval</a></p>
                <p><a class="w3-text" href="#Generative Speech Enhancement">Generative Speech Enhancement</a></p>
                <p><a class="w3-text" href="#Speech Synthesis: Evaluation">Speech Synthesis: Evaluation</a></p>
                <p><a class="w3-text" href="#Multilingual ASR">Multilingual ASR</a></p>
                <p><a class="w3-text" href="#General Topics in ASR">General Topics in ASR</a></p>
                <p><a class="w3-text" href="#Spoken Language Understanding">Spoken Language Understanding</a></p>
                <p><a class="w3-text" href="#Speech and Multimodal Resources">Speech and Multimodal Resources</a></p>
                <p><a class="w3-text" href="#Pathological Speech Analysis 1">Pathological Speech Analysis 1</a></p>
                <p><a class="w3-text" href="#Speech and Language in Health: from Remote Monitoring to Medical Conversations - 1 (Special Session)">Speech and Language in Health: from Remote Monitoring to Medical Conversations - 1 (Special Session)</a></p>
                <p><a class="w3-text" href="#Speech and Brain">Speech and Brain</a></p>
                <p><a class="w3-text" href="#Innovative Methods in Phonetics and Phonology">Innovative Methods in Phonetics and Phonology</a></p>
                <p><a class="w3-text" href="#Voice, Tones and F0">Voice, Tones and F0</a></p>
                <p><a class="w3-text" href="#Emotion Recognition: Resources and Benchmarks">Emotion Recognition: Resources and Benchmarks</a></p>
                <p><a class="w3-text" href="#Speaker and Language Identification and Diarization">Speaker and Language Identification and Diarization</a></p>
                <p><a class="w3-text" href="#Audio-Text Retrieval">Audio-Text Retrieval</a></p>
                <p><a class="w3-text" href="#Speech Enhancement">Speech Enhancement</a></p>
                <p><a class="w3-text" href="#Speech Coding">Speech Coding</a></p>
                <p><a class="w3-text" href="#Speech Synthesis: Expressivity and Emotion">Speech Synthesis: Expressivity and Emotion</a></p>
                <p><a class="w3-text" href="#Speech Synthesis: Tools and Data">Speech Synthesis: Tools and Data</a></p>
                <p><a class="w3-text" href="#Speech Synthesis: Singing Voice Synthesis">Speech Synthesis: Singing Voice Synthesis</a></p>
                <p><a class="w3-text" href="#LLM in ASR">LLM in ASR</a></p>
                <p><a class="w3-text" href="#Vision and Speech">Vision and Speech</a></p>
                <p><a class="w3-text" href="#Spoken Document Summarization">Spoken Document Summarization</a></p>
                <p><a class="w3-text" href="#Speech and Language in Health: from Remote Monitoring to Medical Conversations - 2 (Special Sessions)">Speech and Language in Health: from Remote Monitoring to Medical Conversations - 2 (Special Sessions)</a></p>
                <p><a class="w3-text" href="#Show and Tell 2">Show and Tell 2</a></p>
                <p><a class="w3-text" href="#Prosody">Prosody</a></p>
                <p><a class="w3-text" href="#Foundational Models for Deepfake and Spoofed Speech Detection">Foundational Models for Deepfake and Spoofed Speech Detection</a></p>
                <p><a class="w3-text" href="#Speaker Recognition 1">Speaker Recognition 1</a></p>
                <p><a class="w3-text" href="#Source Separation 1">Source Separation 1</a></p>
                <p><a class="w3-text" href="#Audio-Visual and Generative Speech Enhancement">Audio-Visual and Generative Speech Enhancement</a></p>
                <p><a class="w3-text" href="#Speech Privacy and Bandwidth Expansion">Speech Privacy and Bandwidth Expansion</a></p>
                <p><a class="w3-text" href="#Speech Synthesis: Prosody">Speech Synthesis: Prosody</a></p>
                <p><a class="w3-text" href="#Accented Speech, Prosodic Features, Dialect, Emotion, Sound Classification">Accented Speech, Prosodic Features, Dialect, Emotion, Sound Classification</a></p>
                <p><a class="w3-text" href="#Neural Network Adaptation">Neural Network Adaptation</a></p>
                <p><a class="w3-text" href="#ASR and LLMs">ASR and LLMs</a></p>
                <p><a class="w3-text" href="#Pathological Speech Analysis 3">Pathological Speech Analysis 3</a></p>
                <p><a class="w3-text" href="#Speech Disorders 3">Speech Disorders 3</a></p>
                <p><a class="w3-text" href="#Speech Recognition with Large Pretrained Speech Models for Under-represented Languages (Special Session)">Speech Recognition with Large Pretrained Speech Models for Under-represented Languages (Special Session)</a></p>
                <p><a class="w3-text" href="#Speech Processing Using Discrete Speech Units (Special Session)">Speech Processing Using Discrete Speech Units (Special Session)</a></p>
                <p><a class="w3-text" href="#Keynote 3">Keynote 3</a></p>
                <p><a class="w3-text" href="#Databases and Progress in Methodology">Databases and Progress in Methodology</a></p>
                <p><a class="w3-text" href="#Articulation, Convergence and Perception">Articulation, Convergence and Perception</a></p>
                <p><a class="w3-text" href="#Speech Emotion Recognition">Speech Emotion Recognition</a></p>
                <p><a class="w3-text" href="#Self-Supervised Models in Speaker Recognition">Self-Supervised Models in Speaker Recognition</a></p>
                <p><a class="w3-text" href="#Speech Quality Assessment">Speech Quality Assessment</a></p>
                <p><a class="w3-text" href="#Privacy and Security in Speech Communication 1">Privacy and Security in Speech Communication 1</a></p>
                <p><a class="w3-text" href="#Speech Synthesis: Voice Conversion 2">Speech Synthesis: Voice Conversion 2</a></p>
                <p><a class="w3-text" href="#Speech Synthesis: Text Processing">Speech Synthesis: Text Processing</a></p>
                <p><a class="w3-text" href="#Training Methods, Self-Supervised Learning, Adaptation">Training Methods, Self-Supervised Learning, Adaptation</a></p>
                <p><a class="w3-text" href="#Novel Architectures for ASR">Novel Architectures for ASR</a></p>
                <p><a class="w3-text" href="#Multimodality and Foundation Models">Multimodality and Foundation Models</a></p>
                <p><a class="w3-text" href="#Spoken Dialogue Systems and Conversational Analysis 1">Spoken Dialogue Systems and Conversational Analysis 1</a></p>
                <p><a class="w3-text" href="#Speech Technology">Speech Technology</a></p>
                <p><a class="w3-text" href="#Pathological Speech Analysis 2">Pathological Speech Analysis 2</a></p>
                <p><a class="w3-text" href="#Speech Science, Speech Technology, and Gender (Special Session)">Speech Science, Speech Technology, and Gender (Special Session)</a></p>
                <p><a class="w3-text" href="#Speech Production and Perception">Speech Production and Perception</a></p>
                <p><a class="w3-text" href="#Phonetics and Phonology: Segmentals and Suprasegmentals">Phonetics and Phonology: Segmentals and Suprasegmentals</a></p>
                <p><a class="w3-text" href="#Topics in Paralinguistics">Topics in Paralinguistics</a></p>
                <p><a class="w3-text" href="#Emotion Recognition: Fairness, Variability, Uncertainty">Emotion Recognition: Fairness, Variability, Uncertainty</a></p>
                <p><a class="w3-text" href="#Speaker Verification">Speaker Verification</a></p>
                <p><a class="w3-text" href="#Spatial Audio and Acoustics">Spatial Audio and Acoustics</a></p>
                <p><a class="w3-text" href="#Generative Models for Speech and Audio">Generative Models for Speech and Audio</a></p>
                <p><a class="w3-text" href="#Speech and Audio Modelling">Speech and Audio Modelling</a></p>
                <p><a class="w3-text" href="#Multi-Channel Speech Enhancement">Multi-Channel Speech Enhancement</a></p>
                <p><a class="w3-text" href="#Speech Synthesis: Paradigms and Methods 1">Speech Synthesis: Paradigms and Methods 1</a></p>
                <p><a class="w3-text" href="#Speech Synthesis: Paradigms and Methods 2">Speech Synthesis: Paradigms and Methods 2</a></p>
                <p><a class="w3-text" href="#Neural Network Architectures for ASR 1">Neural Network Architectures for ASR 1</a></p>
                <p><a class="w3-text" href="#Error Correction and Rescoring">Error Correction and Rescoring</a></p>
                <p><a class="w3-text" href="#Spoken Language Understanding">Spoken Language Understanding</a></p>
                <p><a class="w3-text" href="#Spoken Dialogue Systems and Conversational Analysis 2">Spoken Dialogue Systems and Conversational Analysis 2</a></p>
                <p><a class="w3-text" href="#Computational Models of Human Language Acquisition, Perception, and Production (Special Session)">Computational Models of Human Language Acquisition, Perception, and Production (Special Session)</a></p>
                <p><a class="w3-text" href="#Show and Tell 3">Show and Tell 3</a></p>
                <p><a class="w3-text" href="#Phonetics, Phonology and Prosody">Phonetics, Phonology and Prosody</a></p>
                <p><a class="w3-text" href="#Segmentals">Segmentals</a></p>
                <p><a class="w3-text" href="#New Avenues in Emotion Recognition">New Avenues in Emotion Recognition</a></p>
                <p><a class="w3-text" href="#Speaker Diarization 2">Speaker Diarization 2</a></p>
                <p><a class="w3-text" href="#Speaker Recognition 2">Speaker Recognition 2</a></p>
                <p><a class="w3-text" href="#Speech and Audio Analysis">Speech and Audio Analysis</a></p>
                <p><a class="w3-text" href="#Speech Quality and Intelligibility: Prediction and Enhancement">Speech Quality and Intelligibility: Prediction and Enhancement</a></p>
                <p><a class="w3-text" href="#Speech Synthesis: Vocoders">Speech Synthesis: Vocoders</a></p>
                <p><a class="w3-text" href="#ASR Model Training Methods">ASR Model Training Methods</a></p>
                <p><a class="w3-text" href="#Cross-Lingual and Multilingual Processing">Cross-Lingual and Multilingual Processing</a></p>
                <p><a class="w3-text" href="#Speech Assessment">Speech Assessment</a></p>
                <p><a class="w3-text" href="#Question Answering from Speech and Spoken Dialogue Systems">Question Answering from Speech and Spoken Dialogue Systems</a></p>
                <p><a class="w3-text" href="#Spoken Dialogue Systems and Conversational Analysis 3">Spoken Dialogue Systems and Conversational Analysis 3</a></p>
                <p><a class="w3-text" href="#Dysarthric Speech Assessment">Dysarthric Speech Assessment</a></p>
                <p><a class="w3-text" href="#Spoken Language Models for Universal Speech Processing (Special Session)">Spoken Language Models for Universal Speech Processing (Special Session)</a></p>
                <p><a class="w3-text" href="#Keynote 4">Keynote 4</a></p>
                <p><a class="w3-text" href="#L1/L2 Acquisition and Cross-Linguistic Factors">L1/L2 Acquisition and Cross-Linguistic Factors</a></p>
                <p><a class="w3-text" href="#Speaker Stance, Emotion and Language-External Factors">Speaker Stance, Emotion and Language-External Factors</a></p>
                <p><a class="w3-text" href="#Experimental Phonetics and Laboratory Phonology">Experimental Phonetics and Laboratory Phonology</a></p>
                <p><a class="w3-text" href="#Speaker recognition evaluation and resources">Speaker recognition evaluation and resources</a></p>
                <p><a class="w3-text" href="#Speech Type Classification">Speech Type Classification</a></p>
                <p><a class="w3-text" href="#Target Speaker Extraction">Target Speaker Extraction</a></p>
                <p><a class="w3-text" href="#Speech Synthesis: Voice Conversion 3">Speech Synthesis: Voice Conversion 3</a></p>
                <p><a class="w3-text" href="#Speech Synthesis: Paradigms and Methods 3">Speech Synthesis: Paradigms and Methods 3</a></p>
                <p><a class="w3-text" href="#Privacy and Security in Speech Communication 2">Privacy and Security in Speech Communication 2</a></p>
                <p><a class="w3-text" href="#Streaming ASR">Streaming ASR</a></p>
                <p><a class="w3-text" href="#Computational Resource Constrained ASR">Computational Resource Constrained ASR</a></p>
                <p><a class="w3-text" href="#Evaluation of Speech Technology Systems">Evaluation of Speech Technology Systems</a></p>
                <p><a class="w3-text" href="#Neural Network Training for Speech Recognition">Neural Network Training for Speech Recognition</a></p>
                <p><a class="w3-text" href="#Leveraging Large Language Models and Contextual Features for Phonetic Analysis (Special Session)">Leveraging Large Language Models and Contextual Features for Phonetic Analysis (Special Session)</a></p>
                <p><a class="w3-text" href="#Responsible Speech Foundation Models (Special Session)">Responsible Speech Foundation Models (Special Session)</a></p>
                <p><a class="w3-text" href="#Multimodal Paralinguistics">Multimodal Paralinguistics</a></p>
                <p><a class="w3-text" href="#Automatic Emotion Recognition">Automatic Emotion Recognition</a></p>
                <p><a class="w3-text" href="#Self and Weakly-Labelled Speaker Verification">Self and Weakly-Labelled Speaker Verification</a></p>
                <p><a class="w3-text" href="#Acoustic Event Detection, Segmentation and Classification">Acoustic Event Detection, Segmentation and Classification</a></p>
                <p><a class="w3-text" href="#Speech and Audio Modelling">Speech and Audio Modelling</a></p>
                <p><a class="w3-text" href="#Fake Audio Detection">Fake Audio Detection</a></p>
                <p><a class="w3-text" href="#Deep Learning-Based Speech Enhancement: Approaches, Scalability, and Evaluation">Deep Learning-Based Speech Enhancement: Approaches, Scalability, and Evaluation</a></p>
                <p><a class="w3-text" href="#Speech Synthesis: Other Topics 1">Speech Synthesis: Other Topics 1</a></p>
                <p><a class="w3-text" href="#Speech Synthesis: Other Topics 2">Speech Synthesis: Other Topics 2</a></p>
                <p><a class="w3-text" href="#Speech synthesis: Cross-lingual and multilingual aspects">Speech synthesis: Cross-lingual and multilingual aspects</a></p>
                <p><a class="w3-text" href="#Noise, Far-Field, Multi-Talker, Enhancement, Audio Classification">Noise, Far-Field, Multi-Talker, Enhancement, Audio Classification</a></p>
                <p><a class="w3-text" href="#Self-Supervised Learning for ASR">Self-Supervised Learning for ASR</a></p>
                <p><a class="w3-text" href="#Spoken Term Detection and Speech Retrieval">Spoken Term Detection and Speech Retrieval</a></p>
                <p><a class="w3-text" href="#Speech Disorders 1">Speech Disorders 1</a></p>
                <p><a class="w3-text" href="#Connecting Speech-science and Speech-technology for Childrenâs Speech (Special Session)">Connecting Speech-science and Speech-technology for Childrenâs Speech (Special Session)</a></p>
                <p><a class="w3-text" href="#Show and Tell 4">Show and Tell 4</a></p>
            </div>
        </div>


        <script>
            function myFunction() {
                var x = document.getElementById("smallnav");
                if (x.className.indexOf("w3-show") == -1) {
                    x.className += " w3-show";
                } else {
                    x.className = x.className.replace(" w3-show", "");
                }
            }

            // Get the modal
            var modal = document.getElementById('sessionchooser');

            // When the user clicks anywhere outside of the modal, close it
            window.onclick = function(event) {
                if (event.target == modal) {
                    modal.style.display = "none";
                }
            }


            $(document).ready(function() {

                $('#paper_table').DataTable( {
                    data: [['Ruizhe Wang', 'SA-MF: A Novel Self-Attention Mechanism for Multifeature Fusion in Speech Enhancement Networks', 'wang24_interspeech', 'multichannel environment distortion multi-feature formidable self-attentive noisy sdr inaccurate influencing'], ['Zhiqi Ai, Zhiyong Chen, Shugong Xu', 'MM-KWS: Multi-modal Prompts for Multilingual User-defined Keyword Spotting', 'ai24_interspeech', 'text embeddings libriphrase speech mining confusable enrollment applicability distinguishing solely'], ['Ye-Xin Lu, Yang Ai, Zheng-Yan Sheng, Zhen-Hua Ling', 'MultiStage Speech Bandwidth Extension with Flexible Sampling Rate Control', 'lu24_interspeech', 'ms-bwe bwe block generation stage sixty one-stage featuring source multi-stage'], ['Olympia Simantiraki, Martin Cooke', "Listeners' F0 preferences in quiet and stationary noise", 'simantiraki24_interspeech', 'alter mean intelligibility impact original inexperienced maximise comprehensibility variation masker'], ['Jennifer Williams, Eike Schneiders, Henry Card, Tina Seabrooke, Beatrice Pakenham-Walsh, Tayyaba Azim, Lucy Valls-Reed, Ganesh Vigneswaran, John Robert Bautista, Rohan Chandra, Arya Farahi', 'Predicting Acute Pain Levels Implicitly from Vocal Features', 'williams24_interspeech', 'clinical triage high-stakes three-class communication explainable cold stroke support emergency'], ['Xingxing Yang', 'G2PA: G2P with Aligned Audio for Mandarin Chinese', 'yang24_interspeech', 'pronunciation github solely ambiguity phoneme text disregarding preprocess polyphone repository'], ['Sizhou Chen, Yibo Bai, Jiadi Yao, Xiao-Lei Zhang, Xuelong Li', 'Textual-Driven Adversarial Purification for Speaker Verification', 'chen24_interspeech', 'tdap diffusion audio defense attack textual neglecting diffusion-based model causing'], ['Thien-Phuc Doan, Long Nguyen-Vu, Kihun Hong, Souhwan Jung', 'Balance, Multiple Augmentation, and Re-synthesis: A Triad Training Strategy for Enhanced Audio Deepfake Detection', 'doan24_interspeech', 'assembling surpassed set sample mini-batch in-the-wild re-synthesized benchmarking balancing achievable'], ['Mohan Li, Simon Keizer, Rama Doddipatla', 'Prompting Whisper for QA-driven Zero-shot End-to-end Spoken Language Understanding', 'li24_interspeech', 'slu slurp question-answering system optimising comprehend model cross-corpus excessive comparably'], ['Daisuke Niizumi, Daiki Takeuchi, Yasunori Ohishi, Noboru Harada, Masahiro Yasuda, Shunsuke Tsubaki, Keisuke Imoto', 'M2D-CLAP: Masked Modeling Duo Meets CLAP for Learning General-purpose Audio-Language Representation', 'niizumi24_interspeech', 'learns audio transfer language-audio performs gtzan aligns versatile classification zero-shot'], ['Nicolas M. MÃ¼ller, Piotr Kawa, Shen Hu, Matthias Neu, Jennifer Williams, Philip Sperl, Konstantin BÃ¶ttinger', 'A New Approach to Voice Authenticity', 'muller24_interspeech', 'edits fake editing binary maliciously ethically pinpointing nancy longstanding delineate'], ['Korbinian Kuhn, Verena Kersken, Gottfried Zimmermann', 'Beyond Levenshtein: Leveraging Multiple Algorithms for Robust Word Error Rate Computations And Granular Error Classifications', 'kuhn24_interspeech', 'punctuation wer non-semantic token-based exemplary common pre-processed visualisation substituting equivalence'], ['Jiatong Shi, Yueqian Lin, Xinyi Bai, Keyi Zhang, Yuning Wu, Yuxun Tang, Yifeng Yu, Qin Jin, Shinji Watanabe', 'Singing Voice Data Scaling-up: An Introduction to ACE-Opencpop and ACE-KiSing', 'shi24_interspeech', 'svs espnet datasets synthesis expansive multi-singer curation complemented supplementary thorough'], ['Umberto Cappellazzo, Daniele Falavigna, Alessio Brutti', 'Efficient Fine-tuning of Audio Spectrogram Transformers via Soft Mixture of Adapters', 'cappellazzo24_interspeech', 'moe expert burgeoning underexplored computational parameter-efficient affordable adapter dense ablation'], ['Titouan Parcollet, Rogier van Dalen, Shucong Zhang, Sourav Bhattacharya', 'SummaryMixing: A Linear-Complexity Alternative to Self-Attention for Speech Recognition and Understanding', 'parcollet24_interspeech', 'inference memory cheaper summarises slowing asr exceed quadratic consumption mixing'], ['Soham Deshmukh, Rita Singh, Bhiksha Raj', 'Domain Adaptation for Contrastive Audio-Language Models', 'deshmukh24_interspeech', 'alm zero-shot alms prompt generalization access require performance test-time enforcing'], ['Jan PeÅ¡Ã¡n, VojtÄch JuÅÃ­k, Martin KarafiÃ¡t, Jan ÄernockÃ½', 'BESST Dataset: A Multimodal Resource for Speech-based Stress Detection and Analysis', 'pesan24_interspeech', 'comprises physiological speech collection electrocardiogram data electrodermal clean temperature immersion'], ['Martijn Bentum, Louis ten Bosch, Tom Lentz', 'The Processing of Stress in End-to-End Automatic Speech Recognition Models', 'bentum24_interspeech', 'classifier correlate layer denominator acoustic mere vowel asr reflection representation'], ['Zhouyuan Huo, Dongseong Hwang, Gan Song, Khe Chai Sim, Weiran Wang', 'AdaRA: Adaptive Rank Allocation of Residual Adapters for Speech Foundation Model', 'huo24_interspeech', 'parameter additive adaptation bottleneck dimension optimal layer allocating possessing efficient'], ['Xinlei Niu, Jing Zhang, Charles Patrick Martin', 'HybridVC: Efficient Voice Style Conversion with Text and Audio Prompts', 'niu24_interspeech', 'contrastive latent embeddings cvae optimises user-defined personalised underscore speaker validates'], ['Oleg Rybakov, Dmitriy Serdyuk, Chengjian Zheng', 'USM RNN-T model weights binarization', 'rybakov24_interspeech', 'size grows serving cost float reduction dominated attractive transducer quantization'], ['Ji-Sang Hwang, Hyeongrae Noh, Yoonseok Hong, Insoo Oh', 'X-Singer: Code-Mixed Singing Voice Synthesis via Cross-Lingual Learning', 'hwang24_interspeech', 'svs lyric annotation phoneme synthesize encoder ability mixture code-switching intra'], ['Yingying Gao, Shilei Zhang, Chao Deng, Junlan Feng', 'GenDistiller: Distilling Pre-trained Language Models based on an Autoregressive Generative Model', 'gao24_interspeech', 'superb wavlm teacher autoregressively resource layer-by-layer hidden hinder hubert distillation'], ['Rui Cao, Tianrui Wang, Meng Ge, Andong Li, Longbiao Wang, Jianwu Dang, Yungang Jia', 'VoiCor: A Residual Iterative Voice Correction Framework for Monaural Speech Enhancement', 'cao24_interspeech', 'dns-challenge solution non-linearly concretely issue structure continue chain refine pesq'], ['Heeseung Kim, Sang-gil Lee, Jiheum Yeom, Che Hyun Lee, Sungwon Kim, Sungroh Yoon', 'VoiceTailor: Lightweight Plug-In Adapter for Diffusion-Based Personalized Text-to-Speech', 'kim24_interspeech', 'adaptation parameter-efficient pivotal tt speaker pre-trained equipping module lora low-rank'], ['Jizhong Liu, Gang Li, Junbo Zhang, Heinrich Dinkel, Yongqing Wang, Zhiyong Yan, Yujun Wang, Bin Wang', 'Enhancing Automated Audio Captioning via Large Language Models with Optimized Audio Encoding', 'liu24_interspeech', 'aac llm token pre-trained encoder decoder effectivity ced llama querying'], ['Siqi Sun, Korin Richmond', 'Learning Pronunciation from Other Accents via Pronunciation Knowledge Transfer', 'sun24_interspeech', 'seq word target bootstrapping frontend annotating transferred accent coverage type'], ['Masaya Ohagi, Tomoya Mizumoto, Katsumasa Yoshikawa', 'Investigation of look-ahead techniques to improve response time in spoken dialogue system', 'ohagi24_interspeech', 'user speed utterance chatbot bot finish returned delayed task-oriented say'], ['Si Chen, Bruce Xiao Wang, Yitian Hong, Fang Zhou, Angel Chan, Po-yi Tang, Bin Li, Chunyi Wen, James Cheung, Yan Liu, Zhuoming Chen', 'Acoustic changes in speech prosody produced by children with autism after robot-assisted speech training', 'chen24b_interspeech', 'autistic marking focus typically-developing variability monotone post-training mixed-effects designed signalling'], ['Wenbin Wang, Yang Song, Sanjay Jha', 'GLOBE: A High-quality English Corpus with Global Accents for Zero-shot Speaker Adaptive Text-to-Speech', 'wang24b_interspeech', 'worldwide metadata populating tt libritts curated rigorous vctk generalizability trained'], ['Jaden Pieper, Stephen Voran', 'AlignNet: Learning dataset score alignment functions to enable better training of speech quality estimators', 'pieper24_interspeech', 'mdf datasets aligner estimator us intermediate successful larger pretrains no-reference'], ['Ji Won Yoon, Beom Jun Woo, Nam Soo Kim', 'HuBERT-EE: Early Exiting HuBERT for Efficient Speech Recognition', 'yoon24_interspeech', 'exit inference branch intermediate stop model hidden-unit returned slowing confident'], ['Hideyuki Oiso, Yuto Matsunaga, Kazuya Kakizaki, Taiki Miyagawa', 'Prompt Tuning for Audio Deepfake Detection: Computationally Efficient Test-time Domain Adaptation with Limited Target Dataset', 'oiso24_interspeech', 'add computational gap challenge extra iii countering cost source-target plug-in'], ['Bunlong Lay, Timo Gerkmann', 'An Analysis of the Variance of Diffusion-based Speech Enhancement', 'lay24_interspeech', 'diffusion attenuation noise equation differential environmental stochastic adding gaussian concretely'], ['Lukas Christ, Shahin Amiriparian, Friederike Hawighorst, Ann-Kathrin Schill, Angelo Boutalikakis, Lorenz Graf-Vlachy, Andreas KÃ¶nig, BjÃ¶rn Schuller', 'This Paper Had the Smartest Reviewers - Flattery Detection Utilising an Audio-Textual Transformer-Based Approach', 'christ24_interspeech', 'whisper textual multimodal modality praise compliment bonding build roberta ast'], ['Zengrui Jin, Yifan Yang, Mohan Shi, Wei Kang, Xiaoyu Yang, Zengwei Yao, Fangjun Kuang, Liyong Guo, Lingwei Meng, Long Lin, Yong Xu, Shi-Xiong Zhang, Daniel Povey', 'LibriheavyMix: A 20,000-Hour Dataset for Single-Channel Reverberant Multi-Talker Speech Separation, ASR and Speaker Diarization', 'jin24_interspeech', 'far-field daunting multitalker landscape foundational crafted convenience encompassing generality challenge'], ['Andreas Triantafyllopoulos, Anton Batliner, Wolfgang Mayr, Markus Fendler, Florian Pokorny, Maurice Gerczuk, Shahin Amiriparian, Thomas Berghaus, BjÃ¶rn Schuller', 'Sustained Vowels for Pre- vs Post-Treatment COPD Classification', 'triantafyllopoulos24_interspeech', 'lung disease patient obstructed hospitalisation pulmonary read acute lens obstructive'], ['Andreas Triantafyllopoulos, Anton Batliner, Simon Rampp, Manuel Milling, BjÃ¶rn Schuller', 'INTERSPEECH 2009 Emotion Challenge Revisited: Benchmarking 15 Years of Progress in Speech Emotion Recognition', 'triantafyllopoulos24b_interspeech', 'ser official outperform corollary -the winner set newer hyperparameter model'], ['Andreas Triantafyllopoulos, BjÃ¶rn Schuller', 'Enrolment-based personalisation for improving individual-level fairness in speech emotion recognition', 'triantafyllopoulos24c_interspeech', 'aggregated evaluation ser individualistic failing uncovered enrolment speaker across characterise'], ['Zhenyu Wang, Shuyu Kong, Li Wan, Biqiao Zhang, Yiteng Huang, Mumin Jin, Ming Sun, Xin Lei, Zhaojun Yang', 'Query-by-Example Keyword Spotting Using Spectral-Temporal Graph Attentive Pooling and Multi-Task Learning', 'wang24c_interspeech', 'liconet qbye kw conformer framework fa tailoring speaker-invariant frr customized'], ['Daniela A. Wiepert, Rene L. Utianski, Joseph R. Duffy, John L. Stricker, Leland R. Barnard, David T. Jones, Hugo Botha', 'Speech foundation models in healthcare: Effect of layer selection on pathological speech feature prediction', 'wiepert24_interspeech', 'diagnosis treatment clinical best out-of-distribution lower average increase worst neurological'], ['Yuang Li, Jiawei Yu, Min Zhang, Mengxin Ren, Yanqing Zhao, Xiaofeng Zhao, Shimin Tao, Jinsong Su, Hao Yang', 'Using Large Language Model for End-to-End Chinese ASR and NER', 'li24b_interspeech', 'decoder-only llm encoder-decoder token long-form speech infers cross-attention connect taxonomy'], ['Yuang Li, Min Zhang, Chang Su, Yinglu Li, Xiaosong Qiao, Mengxin Ren, Miaomiao Ma, Daimeng Wei, Shimin Tao, Hao Yang', 'A Multitask Training Approach to Enhance Whisper with Open-Vocabulary Keyword Spotting', 'li24c_interspeech', 'ov-kws entity asr named aishell plug-and-play user-defined terminology model hot'], ['Li Xiao, Lucheng Fang, Yuhong Yang, Weiping Tu', 'LungAdapter: Efficient Adapting Audio Spectrogram Transformer for Lung Sound Classification', 'xiao24_interspeech', 'fine-tuning large-scale pre-trained model full parameter adapter predominant frozen entail'], ['Yi Gao, Xiang Su', 'Low Complexity Echo Delay Estimator Based on Binarized Feature Matching', 'gao24b_interspeech', 'method aec webrtc dearth nn-based traditional encompassing canceller serf enhances'], ['Yang Ai, Ye-Xin Lu, Xiao-Hang Jiang, Zheng-Yan Sheng, Rui-Chen Zheng, Zhen-Hua Ling', 'A Low-Bitrate Neural Audio Codec Framework with Bandwidth Reduction and Recovery for High-Sampling-Rate Waveforms', 'ai24b_interspeech', 'bitrate waveform quantizer sampling encoder decoder outputted bitrates decodes recovers'], ['Toshio Irino, Shintaro Doan, Minami Ishikawa', 'Signal processing algorithm effective for sound quality of hearing loss simulators ', 'irino24_interspeech', 'whis perceptible simulator distortion filterbank version listener synthesis le cambridge'], ['Hualei Wang, Jianguo Mao, Zhifang Guo, Jiarui Wan, Hong Liu, Xiangdong Wang', 'Leveraging Language Model Capabilities for Sound Event Detection', 'wang24d_interspeech', 'multi-modality audio generation timestamps sed feature showcase abundant classification flexibly'], ['Mohammad Hassan Vali, Tom BÃ¤ckstrÃ¶m', 'Privacy PORCUPINE: Anonymization of Speaker Attributes Using Occurrence Normalization for Space-Filling Vector Quantization', 'vali24_interspeech', 'information bottleneck private thus disclosure quantifiable privacy-preserving uneven protecting quantizing'], ['Jingyao Wu, Ting Dang, Vidhyasaharan Sethu, Eliathamby Ambikairajah', 'Dual-Constrained Dynamical Neural ODEs for Ambiguity-aware Continuous Emotion Prediction', 'wu24_interspeech', 'distribution ambiguity recola parameterised dynamic range evolve restrict smoothly comparatively'], ['Suhas BN, Amanda Rebar, Saeed Abdullah', 'Speaking of Health: Leveraging Large Language Models to assess Exercise Motivation and Behavior of Rehabilitation Patients', 'bn24_interspeech', 'session establish outcome wellbeing compliance decision-making thematic sentiment ground-truth augmenting'], ['Yu-Wen Chen, Zhou Yu, Julia Hirschberg', 'MultiPA: A Multi-task Speech Pronunciation Assessment Model for Open Response Scenarios', 'chen24c_interspeech', 'sentence-level open-response accuracy multitask predominantly offering real-life out-of-domain reached fluency'], ['Candy Olivia Mawalim, Shogo Okada, Masashi Unoki', 'Are Recent Deep Learning-Based Speech Enhancement Methods Ready to Confront Real-World Noisy Environments?', 'mawalim24_interspeech', 'deepfilternet fullsubnet denoiser scenario hallucination datasets nuanced asr-based struggle emphasizes'], ['Jihyun Mun, Sunhee Kim, Minhwa Chung', 'Developing an End-to-End Framework for Predicting the Social Communication Severity Scores of Children with Autism Spectrum Disorder', 'mun24_interspeech', 'asd fine-tuned diagnostic human-rated lifelong tool necessitate foundational profound objective'], ['Mewlude Nijat, Chen Chen, Dong Wang, Askar Hamdulla', 'UY/CH-CHILD -- A Public Chinese L2 Speech Database of Uyghur Children', 'nijat24_interspeech', 'kindergarten pronunciation school primary intriguing mature downloaded avenue showcase org'], ['Steven Vander Eeckt, Hugo Van hamme', 'Unsupervised Online Continual Learning for Automatic Speech Recognition', 'vandereeckt24_interspeech', 'ocl uocl forgetting continually leveraging asr domain supervised adaptation realm'], ['Robin Scheibler, Yusuke Fujita, Yuma Shirahata, Tatsuya Komatsu', 'Universal Score-based Speech Enhancement with High Content Preservation', 'scheibler24_interspeech', 'universe diffusion adversarial decouples three-fold loss low-rank favorably fidelity promote'], ['Minyoung Lee, Eunil Park, Sungeun Hong', 'FVTTS : Face Based Voice Synthesis for Text-to-Speech', 'lee24_interspeech', 'personalized expressive identity image tt sample individual voice-based personalization authentication'], ['Liang Tao, Maoshen Jia, Yonggang Hu, Changchun Bao', 'Spatial Acoustic Enhancement Using Unbiased Relative Harmonic Coefficients', 'tao24_interspeech', 'noisy source entire spherical multiplying compactly denoted environment domain clue'], ['Xin Jing, Luyang Zhang, Jiangjian Xie, Alexander Gebhard, Alice Baird, BjÃ¶rn Schuller', 'DB3V: A Dialect Dominated Dataset of Bird Vocalisation for Cross-corpus Bird Species Recognition', 'jing24_interspeech', 'publicly call zenodo region impedes contiguous mitigation across benchmarking acknowledged'], ['Da Mu, Zhicheng Zhang, Haobo Yue', 'MFF-EINV2: Multi-scale Feature Fusion across Spectral-Spatial-Temporal Domains for Sound Event Localization and Detection', 'mu24_interspeech', 'mff seld spatial module temporal spectral subnetworks three-stage localizing challenge'], ['Hao Yang, Min Zhang, Minghan Wang, Jiaxin Guo', 'RASU: Retrieval Augmented Speech Understanding through Generative Modeling', 'yang24b_interspeech', 'slu prompt retrieved rag language intent transcript spoken capability retrieval-based'], ['Julius Richter, Yi-Chiao Wu, Steven Krenn, Simon Welker, Bunlong Lay, Shinji Watanabe, Alexander Richard, Timo Gerkmann', 'EARS: An Anechoic Fullband Speech Dataset Benchmarked for Speech Enhancement and Dereverberation', 'richter24_interspeech', 'online freeform totalling style uploaded download instrumental non-verbal server blind'], ['Vladimir Despotovic, Abir ElbÃ©ji, Petr V. Nazarov, Guy Fagherazzi', 'Multimodal Fusion for Vocal Biomarkers Using Vector Cross-Attention', 'despotovic24_interspeech', 'modality voice standardized sustained phonation person reading biomarker single vowel'], ['Liming Wang, Yuan Gong, Nauman Dawalatabad, Marco Vilela, Katerina Placek, Brian Tracey, Yishu Gong, Alan Premasiri, Fernando Vieira, James Glass', 'Automatic Prediction of Amyotrophic Lateral Sclerosis Progression using Longitudinal Speech Transformer', 'wang24e_interspeech', 'al disease recording best auc interpretable network-based careful fine-grained pretrained'], ['Yujia Wang, Hexin Liu, Leibny Paola Garcia', 'Bridging Child-Centered Speech Language Identification and Language Diarization via Phonetics', 'wang24f_interspeech', 'lid fine-tuning back-end scoring pre-trained merlion slicing enriching inspiration needing'], ['Erfan Loweimi, Mengjie Qian, Kate Knill, Mark Gales', 'On the Usefulness of Speaker Embeddings for Speaker Retrieval in the Wild: A Comparative Study of x-vector and ECAPA-TDNN Models', 'loweimi24_interspeech', 'synopsis speechbrain develop nemo archival bbc posing toolkits encompasses challenge'], ['Zhengxiao Li, Nakamasa Inoue', 'Locally Aligned Rectified Flow Model for Speech Enhancement Towards Single-Step Diffusion', 'li24d_interspeech', 'larf transport equation differential wsj mapping voicebank-demand clean si-sdr noisy'], ['Jeehye Lee, Hyeji Seo', 'Online Knowledge Distillation of Decoder-Only Large Language Models for Efficient Speech Recognition', 'lee24b_interspeech', 'llm cer inference decoder reduction relative cost aed dataset task'], ['Yixuan Zhang, Hao Zhang, Meng Yu, Dong Yu', 'Neural Network Augmented Kalman Filter for Robust Acoustic Howling Suppression', 'zhang24_interspeech', 'ahs refining standalone adaptability performance method covariance validate thereby obtaining'], ['Dong Yang, Tomoki Koriyama, Yuki Saito', 'Frame-Wise Breath Detection with Self-Training: An Exploration of Enhancing Breath Naturalness in Text-to-Speech', 'yang24c_interspeech', 'annotation model mark up-sampling tt pseudo-labeling position synthesizes human-like conformer'], ['Hitoshi Suda, Aya Watanabe, Shinnosuke Takamichi', 'Who Finds This Voice Attractive? A Large-Scale Experiment Using In-the-Wild Data', 'suda24_interspeech', 'likability gender regarding age favorite corpus speech announcement listener speaker'], ['Mayank Kumar Singh, Naoya Takahashi, Weihsiang Liao, Yuki Mitsufuji', 'SilentCipher: Deep Audio Watermarking', 'singh24_interspeech', 'message imperceptible robustness introduce learning-based encode capacity enhancing enabling watermark'], ['Hyun Myung Kim, Kangwook Jang, Hoirin Kim', 'One-class learning with adaptive centroid shift for audio deepfake detection', 'kim24b_interspeech', 'bonafide ac representation unseen embeddings cluster well-separated t-sne disentangles system'], ['Constantijn Kaland, Jeremy Steffman, Jennifer Cole', 'K-means and hierarchical clustering of f0 contours', 'kaland24_interspeech', 'cluster intonation outcome difference popular research decision analysis time-series imitated'], ['Constantijn Kaland, Maria Lialiou', 'Quantity-sensitivity affects recall performance of word stress', 'kaland24b_interspeech', 'var pattern listener greek language segmental memorizing german variable hypothesizes'], ['Loukas Ilias, Dimitris Askounis', 'A Cross-Attention Layer coupled with Multimodal Fusion Methods for Recognizing Depression from Spontaneous Speech', 'ilias24_interspeech', 'perform lifeless activity people biomarker existing diagnosing feel productivity depressed'], ['Francesco Paissan, Elisabetta Farella', 'tinyCLAP: Distilling Constrastive Language-Audio Pretrained Models', 'paissan24_interspeech', 'clap contrastive event complexity text-to-audio detection employment sound distillation zero-shot'], ['Yiwen Wang, Xihong Wu', 'TSE-PI: Target Sound Extraction under Reverberant Environments with Pitch Information', 'wang24g_interspeech', 'tse gammatone filterbank fsd feature-wise provided asa model learnable clue'], ['Chin Yuen Kwok, Jia Qi Yip, Eng Siong Chng', 'Continual Learning Optimizations for Auto-regressive Decoder of Multilingual ASR systems', 'kwok24_interspeech', 'masr token pre-trained re-scaling unused freezing hypothesise surgery language sub-optimal'], ['Nicolas Gengembre, Olivier Le Blouch, CÃ©dric Gendrot', 'Disentangling prosody and timbre embeddings via voice conversion', 'gengembre24_interspeech', 'converted anonymization architecture speaker perfectly expressivity source prosodic disentangle preservation'], ['Masato Murata, Koichi Miyazaki, Tomoki Koriyama', 'An Attribute Interpolation Method in Speech Synthesis by Model Merging', 'murata24_interspeech', 'base merged task intensity emotion generation module control specific creates'], ['Quan Wang, Yiling Huang, Guanlong Zhao, Evan Clark, Wei Xia, Hank Liao', 'DiarizationLM: Speaker Diarization Post-Processing with Large Language Models', 'wang24h_interspeech', 'llm rel finetuned output framework wder post-process optionally dataset off-the-shelf'], ['Pawel Bujnowski, Bartlomiej Kuzma, Bartlomiej Paziewski, Jacek Rutkowski, Joanna Marhula, Zuzanna Bordzicka, Piotr Andruszkiewicz', 'SAMSEMO: New dataset for multilingual and multimodal emotion recognition', 'bujnowski24_interspeech', 'scene video cmu-mosei datasets class imbalanced audio metadata popularity heterogeneous'], ['Hyeonuk Nam, Seong-Hu Kim, Deokki Min, Junhyeok Lee, Yong-Hwa Park', 'Diversifying and Expanding Frequency-Adaptive Convolution Kernels for Sound Event Detection', 'nam24_interspeech', 'conv basis dilation dilated size frequency dfd diversify class-wise psds'], ['Jihwan Lee, Aditya Kommineni, Tiantian Feng, Kleanthis Avramidis, Xuan Shi, Sudarsana Reddy Kadiri, Shrikanth Narayanan', 'Toward Fully-End-to-End Listened Speech Decoding from EEG Signals', 'lee24c_interspeech', 'connector module learns waveform single-step unveil characteristic framework bridge com'], ['Tuochao Chen, Qirui Wang, Bohan Wu, Malek Itani, Emre Sefik Eskimez, Takuya Yoshioka, Shyamnath Gollakota', 'Target conversation extraction: Source separation using turn-taking dynamics', 'chen24d_interspeech', 'interfering -speaker speaker amidst participant uniquely accomplish engaged noise feasibility'], ['Youngmoon Jung, Seungjin Lee, Joon-Young Yang, Jaeyoung Roh, Chang Woo Han, Hoon-Young Cho', 'Relational Proxy Loss for Audio-Text based Keyword Spotting', 'jung24_interspeech', 'embeddings text kw enrollment within proxy-based point-to-point acoustic convenience focus'], ['Jaejun Lee, Yoori Oh, Injune Hwang, Kyogu Lee', 'Hear Your Face: Face-based voice conversion with F0 estimation', 'lee24d_interspeech', 'facial delf fundamental characteristic target framework frequency emerging align solely'], ['Eunik Park, Daehyun Ahn, Hyungjun Kim', 'RepTor: Re-parameterizable Temporal Convolution for Keyword Spotting via Differentiable Kernel Search', 'park24_interspeech', 'kw device mobile model re-parameterized galaxy top- plain smart feed-forward'], ['Seonwoo Lee, Sunhee Kim, Minhwa Chung', 'Automatic Assessment of Speech Production Skills for Children with Cochlear Implants Using Wav2Vec2.0 Acoustic Embeddings', 'lee24e_interspeech', 'ci adult model korean-speaking multi-head pearson therapy trait assessing self-supervised'], ['Hokuto Munakata, Ryo Terashima, Yusuke Fujita', 'Song Data Cleansing for End-to-End Neural Singer Diarization Using Neural Analysis and Synthesis Framework', 'munakata24_interspeech', 'singing choral eend non-overlapped solo convert popular duet mitigates model'], ['Heinrich Dinkel, Zhiyong Yan, Yongqing Wang, Junbo Zhang, Yujun Wang, Bin Wang', 'Streaming Audio Transformers for Online Audio Tagging', 'dinkel24_interspeech', 'sat sota usage delay memory vit benchmarked audioset widely-used long-range'], ['Qinglin Meng, Min Liu, Kaixun Huang, Kun Wei, Lei Xie, Zongfeng Quan, Weihong Deng, Quan Lu, Ning Jiang, Guoqing Zhao', 'SEQ-former: A context-enhanced and efficient automatic speech recognition framework', 'meng24_interspeech', 'contextual efficiency ctc asr decoder spike reduce prediction information private'], ['Yusuke Fujita, Tatsuya Komatsu', 'Audio Fingerprinting with Holographic Reduced Representations', 'fujita24_interspeech', 'fingerprint hrr resolution time decimation method original combined circular summation'], ['Heinrich Dinkel, Zhiyong Yan, Yongqing Wang, Junbo Zhang, Yujun Wang, Bin Wang', 'Scaling up masked audio encoder learning for general audio classification', 'dinkel24b_interspeech', 'dasheng music environmental ssl voxlingua competes nearest-neighbor crema-d ssl-based speech'], ['Nicolas M. MÃ¼ller, Nicholas Evans, Hemlata Tak, Philip Sperl, Konstantin BÃ¶ttinger', 'Harder or Different? Understanding Generalization of Audio Deepfake Detection', 'muller24b_interspeech', 'deepfakes hardness component gap model newer question generated fundamentally decomposing'], ['Shihao Chen, Yu Gu, Jie Zhang, Na Li, Rilin Chen, Liping Chen, Lirong Dai', 'LDM-SVC: Latent Diffusion Model Based Zero-Shot Any-to-Any Singing Voice Conversion with Singer Guidance', 'chen24e_interspeech', 'svc timbre ldm pretrain original vits leakage inevitable editing noted'], ['Haochen Wu, Wu Guo, Zhentao Zhang, Wenting Zhao, Shengyu Peng, Jie Zhang', 'Spoofing Speech Detection by Modeling Local Spectro-Temporal and Long-term Dependency', 'wu24b_interspeech', 'ssd branch artifact temporal bilstm-based exploit global dual-branch attention reside'], ['Haochen Wu, Wu Guo, Shengyu Peng, Zhuhai Li, Jie Zhang', 'Adapter Learning from Pre-trained Model for Robust Spoof Speech Detection', 'wu24c_interspeech', 'backbone wav vec local-global freezing appended task-dependent catastrophic over-fitting wavlm'], ['Yuankun Xie, Ruibo Fu, Zhengqi Wen, Zhiyong Wang, Xiaopeng Wang, Haonnan Cheng, Long Ye, Jianhua Tao', 'Generalized Source Tracing: Detecting Novel Audio Deepfake Algorithm with Real Emphasis and Fake Dispersion Strategy', 'xie24_interspeech', 'ood identifying nsd post-hoc showcasing logits urgent sample proliferation detection'], ['Hui-Peng Du, Ye-Xin Lu, Yang Ai, Zhen-Hua Ling', 'BiVocoder: A Bidirectional Neural Vocoder Integrating Feature Extraction and Waveform Generation', 'du24_interspeech', 'stft amplitude phase tt restores spectrum comprehensively symmetric analysis-synthesis reverse'], ['Tomoki Honda, Shinsuke Sakai, Tatsuya Kawahara', 'Efficient and Robust Long-Form Speech Recognition with Hybrid H3-Conformer', 'honda24_interspeech', 'mhsa hungry layer self-attention computation state-space csj multi-head deterioration unreliable'], ['Shuaishuai Ye, Shunfei Chen, Xinhui Hu, Xinkang Xu', 'SC-MoE: Switch Conformer Mixture of Experts for Unified Streaming and Non-streaming Code-Switching ASR', 'ye24_interspeech', 'moe router layer encoder decoder blank language equipped lid ctc'], ['Shengyu Peng, Wu Guo, Haochen Wu, Zuoliang Li, Jie Zhang', 'Fine-tune Pre-Trained Models with Multi-Level Feature Fusion for Speaker Verification', 'peng24_interspeech', 'ptm dbe afm dual-branch merge back-end front-end ptms layer fbank'], ['Tongtao Ling, Yutao Lai, Lei Chen, Shilei Huang, Yi Liu', 'A Small and Fast BERT for Chinese Medical Punctuation Restoration', 'ling24_interspeech', 'pre-training apr fine-tuning mark clinical pre-trained model roberta reformulate distilled'], ['Qian Yang, Jialong Zuo, Zhe Su, Ziyue Jiang, Mingze Li, Zhou Zhao, Feiyang Chen, Zhefeng Wang, Baoxing Huai', 'MSceneSpeech: A Multi-Scene Speech Dataset For Expressive Speech Synthesis', 'yang24d_interspeech', 'open style scenario user-specific prosody prompting multiple source entail audio'], ['Malo Maisonneuve, Corinne Fredouille, Muriel Lalain, Alain Ghio, Virginie Woisard', 'Towards objective and interpretable speech disorder assessment: a comparative analysis of CNN and transformer-based models', 'maisonneuve24_interspeech', 'hnc pathological wav vec patient impact datasets neck unbiased pave'], ['Ryo Setoguchi, Yoshiko Arimoto', 'Acoustical analysis of the initial phones in speech-laugh', 'setoguchi24_interspeech', 'anova speech vowel th-order lower-order variable coefficient explanatory elucidate two-way'], ['Hao Shi, Tatsuya Kawahara', 'Dual-path Adaptation of Pretrained Feature Extraction Module for Robust Automatic Speech Recognition', 'shi24b_interspeech', 'adapter finetuning path encoder noisy effective transformer achieving data freezing'], ['Thanh Lan Truong, Andrea Weber', 'Ethnolinguistic Identification of Vietnamese-German Heritage Speech', 'truong24_interspeech', 'asian german vietnamese listener speaker background identify chance accurately monotonized'], ['Oliver Niebuhr, Nafiseh Taghva', 'How rhythm metrics are linked to produced and perceived speaker charisma', 'niebuhr24_interspeech', 'presentation investor rhythmic element charismatic medium-sized duration-based committed recorded pvi'], ['Shahin Amiriparian, Filip PackaÅ, Maurice Gerczuk, BjÃ¶rn W. Schuller', 'ExHuBERT: Enhancing HuBERT Through Block Extension and Fine-Tuning on 37 Emotion Datasets', 'amiriparian24_interspeech', 'ser duplicate huggingface freeze layer skip gather adaptability twofold backbone'], ['Jie Lin, Xiuping Yang, Li Xiao, Xinhong Li, Weiyan Yi, Yuhong Yang, Weiping Tu, Xiong Chen', 'SimuSOE: A Simulated Snoring Dataset for Obstructive Sleep Apnea-Hypopnea Syndrome Evaluation during Wakefulness', 'lin24_interspeech', 'osahs snore obstruction airway upper signal datasets intentionally emitted chronic'], ['Shoval Messica, Yossi Adi', 'NAST: Noise Aware Speech Tokenization for Speech Language Models', 'messica24_interspeech', 'setup task disentanglement lastly representation com github serf iii signal'], ['Chiara Riegger, Tina BÃ¶gel, George Walkden', 'The prosody of the verbal prefix ge-: historical and experimental evidence', 'riegger24_interspeech', 'old negation preceding trochaic foot closure rhythmic auxiliary principle word'], ['Kexu Liu, Yuanxin Wang, Shengchen Li, Xi Shao', 'Speech Formants Integration for Generalized Detection of Synthetic Speech Spoofing Attacks', 'liu24b_interspeech', 'multi-view xls-r unseen variance feature one-class compactly dynamic struggle gating'], ['Zhe Li, Man-wai Mak, Hung-yi Lee, Helen Meng', 'Parameter-efficient Fine-tuning of Speaker-Aware Dynamic Prompts for Speaker Verification', 'li24e_interspeech', 'pool prompt transformer pre-trained tuning tunable resulting overfit plasticity learnable'], ['Bolaji Yusuf, Murali Karthick Baskar, Andrew Rosenberg, Bhuvana Ramabhadran', 'Speculative Speech Recognition by Audio-Prefixed Low-Rank Adaptation of Language Models', 'yusuf24_interspeech', 'ssr asr speculates empower speculation transcribes ahead prefix audio feed'], ['Louis Abel, Vincent Colotte, Slim Ouni', 'Towards realtime co-speech gestures synthesis using STARGATE', 'abel24_interspeech', 'graph fast ecas field resource-intensive credibility audio-text spatio-temporal architecture embodied'], ['Chenyu Li, Jalal Al-Tamimi', 'Impact of the tonal factor on diphthong realizations in Standard Mandarin with Generalized Additive Mixed Models', 'li24f_interspeech', 'tone falling tend realization gamms universality monophthongs vowel negatively dynamical'], ['Yehoshua Dissen, Shiry Yonash, Israel Cohen, Joseph Keshet', 'Enhanced ASR Robustness to Packet Loss with a Front-End Adaptation Network', 'dissen24_interspeech', 'whisper model packet-loss criterion practicality underscoring foundational realm noisy environment'], ['Nicolas Audibert, Cecile Fougeron, Christine Meunier', 'Do Speaker-dependent Vowel Characteristics depend on Speech Style?', 'audibert24_interspeech', 'speaker intra-speaker nasal distinction style-dependent read category variability spontaneous property'], ['Riyansha Singh, Parinita Nema, Vinod K Kurmi', 'Towards Robust Few-shot Class Incremental Learning in Audio Classification using Contrastive Representation', 'singh24b_interspeech', 'session base esc danger post-training analytics seamless address catastrophic forgetting'], ['Amit Roth, Arnon Turetzky, Yossi Adi', 'A Language Modeling Approach to Diacritic-Free Hebrew TTS', 'roth24_interspeech', 'diacritic modern text-to-speech word-piece tokenizer dictate in-the-wild imposes weakly pronounce'], ['Veranika Boukun, Jakob Drefs, JÃ¶rg LÃ¼cke', 'Blind Zero-Shot Audio Restoration: A Variational Autoencoder Approach for Denoising and Inpainting', 'boukun24_interspeech', 'optimization signal posterior probabilistic setting challenging truncated grounded available theoretically'], ['Austin Jones, Margaret E. L. Renwick', 'Evaluating Italian Vowel Variation with the Recurrent Neural Network Phonet', 'jones24_interspeech', 'posterior phonological lexicon close label phone sociophonetic correlation class marginally'], ['Harsha Veena Tadavarthy, Austin Jones, Margaret E. L. Renwick', 'Phonological Feature Detection for US English using the Phonet Library', 'tadavarthy24_interspeech', 'probability class distinctive posterior relationship patterned timestamps bridging designated broader'], ['Andrew Rouditchenko, Yuan Gong, Samuel Thomas, Leonid Karlinsky, Hilde Kuehne, Rogerio Feris, James Glass', 'Whisper-Flamingo: Integrating Visual Features into Whisper for Audio-Visual Speech Recognition and Translation', 'rouditchenko24_interspeech', 'video avsr thousand model hour language versatile data gated harder'], ['Soham Deshmukh, Dareen Alharthi, Benjamin Elizalde, Hannes Gamper, Mahmoud Al Ismail, Rita Singh, Bhiksha Raj, Huaming Wang', 'PAM: Prompting Audio-Language Models for Audio Quality Assessment', 'deshmukh24b_interspeech', 'alm metric reference-free score listening human prompt computing ttm tta'], ['Yi-Jen Shih, David Harwath', 'Interface Design for Self-Supervised Speech Models', 'shih24_interspeech', 'ssl downstream upstream depth sum many weighted layerwise logarithmically combining'], ['Helin Wang, JesÃºs Villalba, Laureano Moro-Velazquez, Jiarui Hai, Thomas Thebaud, Najim Dehak', 'Noise-robust Speech Separation with Fast Generative Correction', 'wang24i_interspeech', 'diffusion reverse process corrector rectify streamline sepformer si-snr libri isolating'], ['Suhita Ghosh, Melanie Jouaiti, Arnab Das, Yamini Sinha, Tim Polzehl, Ingo Siegert, Sebastian Stober', 'Anonymising Elderly and Pathological Speech: Voice Conversion Using DDSP and Query-by-Example', 'ghosh24_interspeech', 'domain preservation anonymity anonymisation uncommon prosody clinically disentangling pertinent differentiable'], ['Kunal Dhawan, Nithin Rao Koluguri, Ante JukiÄ, Ryan Langman, Jagadeesh Balam, Boris Ginsburg', 'Codec-ASR: Training Performant Automatic Speech Recognition Systems with Discrete Speech Representations', 'dhawan24_interspeech', 'asr codec ml-superb encodec garnered foundational speech-text speech-related bit-rate drawing'], ['Vidya Srinivas, Malek Itani, Tuochao Chen, Emre Sefik Eskimez, Takuya Yoshioka, Shyamnath Gollakota', 'Knowledge boosting during low-latency inference', 'srinivas24_interspeech', 'model chunk streaming operate small running delay large larger time-delayed'], ['Kyuhong Shim, Jinkyu Lee, Hyunjae Kim', 'Leveraging Adapter for Parameter-Efficient ASR Encoder', 'shim24_interspeech', 'parameter reduces reuses module adjusts conformer-based architecture balancing insert compromising'], ['Paarth Neekhara, Shehzeen Hussain, Subhankar Ghosh, Jason Li, Boris Ginsburg', 'Improving Robustness of LLM-based Speech Synthesis by Learning Monotonic Alignment', 'neekhara24_interspeech', 'cross-attention token text tt attention model hallucination robust repeating learnable'], ['Hongmei Guo, Yijiang Chen, Xiao-Lei Zhang, Xuelong Li', 'Graph Attention Based Multi-Channel U-Net for Speech Dereverberation With Ad-Hoc Microphone Arrays', 'guo24_interspeech', 'channel module reverberation model fusion integrated studied selection layer train'], ['Jia Qi Yip, Shengkui Zhao, Dianwen Ng, Eng Siong Chng, Bin Ma', 'Towards Audio Codec-based Speech Separation', 'yip24_interspeech', 'compression task sepformer mac chart cloud impractical codecs adopting high'], ['Nigel G. Ward, Andres Segura, Alejandro Ceballos, Divette Marco', 'Towards a General-Purpose Model of Perceived Pragmatic Similarity', 'ward24_interspeech', 'human inter-annotator generality hubert utterance fairly thousand judge sometimes judgment'], ['Yuma Shirahata, Byeongseon Park, Ryuichi Yamamoto, Kentaro Tachibana', 'Audio-conditioned phonemic and prosodic annotation for building text-to-speech models from unlabeled speech data', 'shirahata24_interspeech', 'label-speech tt paired dataset model trained sample existing shortage text-only'], ['Jingjing Xu, Wei Zhou, Zijian Yang, Eugen Beck, Ralf SchlÃ¼ter', 'Dynamic Encoder Size Based on Data-Driven Layer-wise Pruning for Speech Recognition', 'xu24_interspeech', 'supernet subnets performant on-par full-size effort resource-intensive score-based enjoy model'], ['Zhuhai Li, Jie Zhang, Wu Guo, Haochen Wu', 'Boosting the Transferability of Adversarial Examples with Gradient-Aligned Ensemble Attack for Speaker Recognition', 'li24g_interspeech', 'substitute gradient update model victim black-box spoof randomly calculate voxceleb'], ['Run Chen, Haozhe Chen, Anushka Kulkarni, Eleanor Lin, Linda Pang, Divya Tadimeti, Jun Shin, Julia Hirschberg', 'Detecting Empathy in Speech', 'chen24f_interspeech', 'feeling acoustic-prosodic done empathetic likability trust benchmarking interpretable creating identifying'], ['Yerbolat Khassanov, Zhipeng Chen, Tianfeng Chen, Tze Yuang Chong, Wei Li, Jun Zhang, Lu Lu, Yuxuan Wang', 'Dual-Pipeline with Low-Rank Adaptation for New Language Integration in Multilingual ASR', 'khassanov24_interspeech', 'masr pipeline lora pre-trained existing flow decoder fleurs language-agnostic unavailable'], ['Kohei Matsuura, Takanori Ashihara, Takafumi Moriya, Masato Mimura, Takatomo Kano, Atsunori Ogawa, Marc Delcroix', 'Sentence-wise Speech Summarization: Task, Datasets, and End-to-End Modeling with LM Knowledge Distillation', 'matsuura24_interspeech', 'model cascade summary text sentence-by-sentence combine appealing asr transformer-based evaluates'], ['Zezhong Jin, Youzhi Tu, Man-Wai Mak', 'W-GVKT: Within-Global-View Knowledge Transfer for Speaker Verification', 'jin24b_interspeech', 'dino student view global teacher eer diversification non-contrastive diversified negligible'], ['Michael Lambropoulos, Frantz Clermont, Shunichi Ishihara', 'The sub-band cepstrum as a tool for locating local spectral regions of phonetic sensitivity: A first attempt with multi-speaker vowel data', 'lambropoulos24_interspeech', 'blccs sub-bands flexible cc spectrum band-limited implying full-band classification gaining'], ['Kun Zhou, Shengkui Zhao, Yukun Ma, Chong Zhang, Hao Wang, Dianwen Ng, Chongjia Ni, Trung Hieu Nguyen, Jia Qi Yip, Bin Ma', 'Phonetic Enhanced Language Modeling for Text-to-Speech Synthesis', 'zhou24_interspeech', 'autoregressive non-autoregressive tt in-context training accumulation model scalability codecs propagation'], ['Zezhong Jin, Youzhi Tu, Man-Wai Mak', 'Self-Supervised Learning with Multi-Head Multi-Mode Knowledge Distillation for Speaker Verification', 'jin24c_interspeech', 'memo self architecture teacher contrastive head mode student dino collaboratively'], ['Ju-ho Kim, Hee-Soo Heo, Bong-Jin Lee, Youngki Kwon, Minjae Lee, Ha-Jin Yu', 'Self-supervised speaker verification with relational mask prediction', 'kim24c_interspeech', 'ssl-based overlooking inter-frame comprehensively mitigating encourages aggregation enrich bridge emerged'], ['Eungbeom Kim, Hantae Kim, Kyogu Lee', 'Guiding Frame-Level CTC Alignments Using Self-knowledge Distillation', 'kim24d_interspeech', 'disagreement student alignment encoder introduces sub-model method spike model teacher-student'], ['Yao Shen, Yingying Gao, Yaqian Hao, Chenguang Hu, Fulin Zhang, Junlan Feng, Shilei Zhang', 'CEC: A Noisy Label Detection Method for Speaker Recognition', 'shen24_interspeech', 'counting inconsistent sample hard cic overfitted metric excels preventing categorize'], ['En-Lun Yu, Kuan-Hsun Ho, Jeih-weih Hung, Shih-Chieh Huang, Berlin Chen', 'Speaker Conditional Sinc-Extractor for Personal VAD', 'yu24_interspeech', 'pvad vanilla feature sinc d-vectors wearable acoustic cutoff accepting function'], ['Seyun Um, Doyeon Kim, Hong-Goo Kang', 'PARAN: Variational Autoencoder-based End-to-End Articulation-to-Speech System for Speech Intelligibility', 'um24_interspeech', 'ema latent signal distribution adjusts researched high-fidelity vae normalizing clarity'], ['Jingze Lu, Yuxiang Zhang, Zhuo Li, Zengqiang Shang, Wenchao Wang, Pengyuan Zhang', 'Improving Copy-Synthesis Anti-Spoofing Training Method with Rhythm and Speaker Perturbation', 'lu24b_interspeech', 'artifact algorithm tt introduced neglecting acoustic model facing locate vocoders'], ['Sheng Li, Chen Chen, Chin Yuen Kwok, Chenhui Chu, Eng Siong Chng, Hisashi Kawai', 'Investigating ASR Error Correction with Large Language Model and Multilingual 1-best Hypotheses', 'li24h_interspeech', 'llm n-best llm-based effectively correct low-resourced feeding noticed output let'], ['Yip Keng Kan, Ke Xu, Hao Li, Jie Shi', 'VoiceDefense: Protecting Automatic Speaker Verification Models Against Black-box Adversarial Attacks', 'kan24_interspeech', 'asv sample trustworthiness formidable counteract slice proving detection compromised distinctly'], ['HyunJung Choi, Muyeol Choi, Yohan Lim, Minkyu Lee, Seonhui Kim, Seung Yun, Donghyun Kim, SangHun Kim', 'Spoken-to-written text conversion with Large Language Model', 'choi24_interspeech', 'itn readability notation korean written making standardize pronunciation err form'], ['Jiwon Suh, Injae Na, Woohwan Jung', 'Improving Domain-Specific ASR with LLM-Generated Contextual Descriptions', 'suh24_interspeech', 'datasets terminology specific struggle domain metadata unavailable llm method whisper'], ['Rubing Shen, Yanzhen Ren, Zongkun Sun', 'FA-GAN: Artifacts-free and Phase-aware High-fidelity GAN-based Vocoder', 'shen24b_interspeech', 'artifact spectral quality non-ideal blurring twin alleviating aliasing upsampling deconvolution'], ['Sheng Feng, Heyang Liu, Yu Wang, Yanfeng Wang', 'Towards an End-to-End Framework for Invasive Brain Signal Decoding with Large Language Models', 'feng24_interspeech', 'llm groundbreaking bcis bci brain-computer underscoring immense evolve underscore showcase'], ['Yi-Wei Wang, Ke-Han Lu, Kuan-Yu Chen', 'HypR: A comprehensive study for ASR hypothesis revising with a reference corpus', 'wang24j_interspeech', 'recognition error progress research checkpoint reranking ted-lium speech dataset modeling'], ['Yuki Saito, Takuto Igarashi, Kentaro Seki, Shinnosuke Takamichi, Ryuichi Yamamoto, Kentaro Tachibana, Hiroshi Saruwatari', 'SRC4VC: Smartphone-Recorded Corpus for Voice Conversion Benchmark', 'saito24_interspeech', 'sample low-quality smartphones multi-speaker high-quality speech speaker-wise utterance-wise any-to-any recorded'], ['Jonathan Svirsky, Uri Shaham, Ofir Lindenbaum', 'Sparse Binarization for Fast Keyword Spotting', 'svirsky24_interspeech', 'device kw edge model efficiency keyword-spotting voice-activated necessitates convenience smartphones'], ['Aviv Shamsian, Aviv Navon, Neta Glazer, Gill Hetz, Joseph Keshet', 'Keyword-Guided Adaptation of Automatic Speech Recognition', 'shamsian24_interspeech', 'whisper prompt decoder steer transcription biasing prefix guiding significant specialized'], ['Guillem Bonafos, Clara Bourot, Pierre Pudlo, Jean-Marc Freyermuth, Laurence Reboul, Samuel TronÃ§on, Arnaud Rey', 'Dirichlet process mixture model based on topologically augmented signal representation for clustering infant vocalizations', 'bonafos24_interspeech', 'month diagram vocalization life persistence persistent non-parametric categorization mfccs profile'], ['Asad Ullah, Alessandro Ragano, Andrew Hines', 'Reduce, Reuse, Recycle: Is Perturbed Data Better than Other Language Augmentation for Low Resource Self-Supervised Speech Models', 'ullah24_interspeech', 'pre-training combined resource-constrained phoneme pre-train pitch target noise viable option'], ['Deok-Hyeon Cho, Hyung-Seok Oh, Seung-Bin Kim, Sang-Hoon Lee, Seong-Whan Lee', 'EmoSphere-TTS: Emotional Style and Intensity Modeling via Spherical Emotion Vector for Controllable Emotional Text-to-Speech', 'cho24_interspeech', 'ability expressive speech multi-aspect control nuanced pseudo-labels mimicking synthesizes compromising'], ['Chenyuan Zhang, Linkai Luo, Hong Peng, Wei Wen', 'Variable Segment Length and Domain-Adapted Feature Optimization for Speaker Diarization', 'zhang24b_interspeech', 'msr mixed embeddings still multiple alternation distinguishes surpasses reaching unreliable'], ['Marie KuneÅ¡ovÃ¡, Jan LeheÄka, Josef MichÃ¡lek, Jindrich Matousek, Jan Å vec', 'Zero-shot Out-of-domain is No Joke: Lessons Learned in the VoiceMOS 2023 MOS Prediction Challenge', 'kunesova24_interspeech', 'track ensemble win surpassed centered singing degrade team wav vec'], ['Eros Rosello, Angel M. Gomez, IvÃ¡n LÃ³pez-Espejo, Antonio M. Peinado, Juan M. MartÃ­n-DoÃ±as', 'Anti-spoofing Ensembling Model: Dynamic Weight Allocation in Ensemble Models for Improved Voice Biometrics Security', 'rosello24_interspeech', 'countermeasure showcasing still neglecting malicious adjusts susceptible spoofed neural prof'], ['Tianzi Wang, Xurong Xie, Zhaoqing Li, Shoukang Hu, Zengrui Jin, Jiajun Deng, Mingyu Cui, Shujie Hu, Mengzhe Geng, Guinan Li, Helen Meng, Xunying Liu', 'Towards Effective and Efficient Non-autoregressive Decoding Using Block-based Attention Mask', 'wang24k_interspeech', 'amd ctc nar decoder block statistically librispeech- concealed wer tripartite'], ['Yifei Xin, Xuxin Cheng, Zhihong Zhu, Xusheng Yang, Yuexian Zou', 'DiffATR: Diffusion-based Generative Modeling for Audio-Text Retrieval', 'xin24_interspeech', 'atr query candidate methodology joint discriminative clotho audiocaps loss discerning'], ['Hiroshi Sato, Takafumi Moriya, Masato Mimura, Shota Horiguchi, Tsubasa Ochiai, Takanori Ashihara, Atsushi Ando, Kentaro Shinayama, Marc Delcroix', 'SpeakerBeam-SS: Real-time Target Speaker Extraction with Lightweight Conv-TasNet and State Space Modeling', 'sato24_interspeech', 'tse ssm frontend dependency convolutional encoder tasnet complexity computational enlarge'], ['Jessica Monaghan, Arun Sebastian, Nicky Chong-White, Vicky Zhang, Vijayalakshmi Easwar, Padraig Kitterick', "Automatic Detection of Hearing Loss from Children's Speech using wav2vec 2.0 Features", 'monaghan24_interspeech', 'early scalable developmental xgboost acknowledging preschool proof-of-concept non-intrusive screening toward'], ['Iuliia Zaitova, Irina Stenger, Wei Xue, Tania Avgustinova, Bernd MÃ¶bius, Dietrich Klakow', 'Cross-Linguistic Intelligibility of Non-Compositional Expressions in Spoken Context', 'zaitova24_interspeech', 'russian surprisal ukrainian distance phonological multiple-choice slavic bulgarian polish score'], ['Arnon Turetzky, Or Tal, Yael Segal, Yehoshua Dissen, Ella Zeldes, Amit Roth, Eyal Cohen, Yosi Shrem, Bronya R. Chernyak, Olga Seleznova, Joseph Keshet, Yossi Adi', 'HebDB: a Weakly Supervised Dataset for Hebrew Speech Processing', 'turetzky24_interspeech', 'language pre-processed model recording asr provide multi-lingual spoken page baseline'], ['Wei Xue, Ivan Yuen, Bernd MÃ¶bius', 'Towards a better understanding of receptive multilingualism: listening conditions and priming effects', 'xue24_interspeech', 'similarity affected comprehend word null prime language-dependent without slower accuracy'], ['Zhiyong Yan, Heinrich Dinkel, Yongqing Wang, Jizhong Liu, Junbo Zhang, Yujun Wang, Bin Wang', 'Bridging Language Gaps in Audio-Text Retrieval', 'yan24_interspeech', 'text encoder ced clotho audiocaps excels content abundance disparity non-english'], ['Xin Wang, Tomi Kinnunen, Kong Aik Lee, Paul-Gauthier NoÃ©, Junichi Yamagishi', 'Revisiting and Improving Scoring Fusion for Spoofing-aware Speaker Verification Using Compositional Data Analysis', 'wang24l_interspeech', 'asv score-level calibration spoofing non-linear finding score zero-effort decision summing'], ['Miseul Kim, Soo-Whan Chung, Youna Ji, Hong-Goo Kang, Min-Seok Choi', 'Speak in the Scene: Diffusion-based Acoustic Scene Transfer toward Immersive Speech Generation', 'kim24e_interspeech', 'ast environment target clap signal task diffusion audio emphasize accompanied'], ['Haiyang Sun, Fulin Zhang, Yingying Gao, Shilei Zhang, Zheng Lian, Junlan Feng', 'MFSN: Multi-perspective Fusion Search Network For Pre-training Knowledge in Speech Emotion Recognition', 'sun24b_interspeech', 'comprehensiveness emotional appropriateness sec ser capturing tec content overlooking cue'], ['Hyun Kyung Hwang, Manami Hirayama', 'Acquisition of high vowel devoicing in Japanese: A production experiment with three and four year olds', 'hwang24b_interspeech', 'hvd developmental word-medial position advancement old rate pattern distinct age'], ['Rotem Rousso, Eyal Cohen, Joseph Keshet, Eleanor Chodroff', 'Tradition or Innovation: A Comparison of Modern ASR Methods for Forced Alignment', 'rousso24_interspeech', 'whisperx mm mfa gmm-hmm speech dominantly kaldi-based montreal massively buckeye'], ['Young Jin Ahn, Jungwoo Park, Sangha Park, Jonghyun Choi, Kee-Eung Kim', 'SyncVSR: Data-Efficient Visual Speech Recognition with End-to-End Crossmodal Audio Token Synchronization', 'ahn24_interspeech', 'vsr synchronizes fell versatility intersection visemes non-autoregressive sought stand aligning'], ['Fengrun Zhang, Wangjin Zhou, Yiming Liu, Wang Geng, Yahui Shan, Chen Zhang', 'Disentangling Age and Identity with a Mutual Information Minimization for Cross-Age Speaker Verification', 'zhang24c_interspeech', 'embeddings backbone gap vox-ca identity-related disentangled age-related aging disentangle method'], ['Naoki Makishima, Naotaka Kawata, Mana Ihori, Tomohiro Tanaka, Shota Orihashi, Atsushi Ando, Ryo Masumura', 'SOMSRED: Sequential Output Modeling for Joint Multi-talker Overlapped Speech Recognition and Speaker Diarization', 'makishima24_interspeech', 'identifier asr unknown jointly fully separate timestamps clustering-based recursively sub-optimal'], ['Xihang Qiu, Lixian Zhu, Zikai Song, Zeyu Chen, Haojie Zhang, Kun Qian, Ye Zhang, Bin Hu, Yoshiharu Yamamoto, BjÃ¶rn W. Schuller', 'Study Selectively: An Adaptive Knowledge Distillation based on a Voting Network for Heart Sound Classification', 'qiu24_interspeech', 'excellent teacher student impart complexity sizeable computational strategy tell nowadays'], ['Takafumi Moriya, Takanori Ashihara, Masato Mimura, Hiroshi Sato, Kohei Matsuura, Ryo Masumura, Taichi Asami', 'Boosting Hybrid Autoregressive Transducer-based ASR with Internal Acoustic Model Training and Dual Blank Thresholding', 'moriya24_interspeech', 'hat iam non-blank decoding transducer joint emit synchronously speed-up skip'], ['I-Ting Hsieh, Chung-Hsien Wu', 'Dysarthric Speech Recognition Using Curriculum Learning and Articulatory Feature Embedding', 'hsieh24_interspeech', 'characteristic recognizing disorder diverse incorporate patient speaker commonly efficiency additionally'], ['Matthijs Van keirsbilck, Alexander Keller', 'Conformer without Convolutions', 'vankeirsbilck24_interspeech', 'learnable temporal surprising speech-to-text averaging discover replace remove completely shift'], ['Yi-Cheng Lin, Tzu-Quan Lin, Hsi-Che Lin, Andy T. Liu, Hung-yi Lee', 'On the social bias of speech self-supervised models', 'lin24b_interspeech', 'ssl biased debiasing inadvertently marginalized reinforcing amplify disparate training shallower'], ['Ke-Han Lu, Zhehuai Chen, Szu-Wei Fu, He Huang, Boris Ginsburg, Yu-Chiang Frank Wang, Hung-yi Lee', 'DeSTA: Enhancing Speech Language Models through Descriptive Speech-Text Alignment', 'lu24c_interspeech', 'slms instruction-following capability reshape generalizing captioning zero-shot non-linguistic caption facilitating'], ['Ching-Yu Yang, Shreya G. Upadhyay, Ya-Tse Wu, Bo-Hao Su, Chi-Chun Lee', 'RW-VoiceShield: Raw Waveform-based Adversarial Attack on One-shot Voice Conversion', 'yang24e_interspeech', 'protected speaker matures utterance attacking imperceptible white-box recognizable undergoes disparity'], ['Xinwei Cao, Zijian Fan, TorbjÃ¸rn Svendsen, Giampiero Salvi', 'A Framework for Phoneme-Level Pronunciation Assessment Using CTC', 'cao24b_interspeech', 'gop alignment method prone traditional deletion insertion error child alignment-based'], ['Woan-Shiuan Chien, Chi-Chun Lee', 'An Investigation of Group versus Individual Fairness in Perceptually Fair Speech Emotion Recognition', 'chien24_interspeech', 'ser raters gender label standpoint diminished persist issue biased arising'], ['Martin Lenglet, Olivier Perrotin, Gerard Bailly', 'FastLips: an End-to-End Audiovisual Text-to-Speech System with Lip Features Prediction for Virtual Avatars', 'lenglet24_interspeech', 'fastspeech avatar facial explicit co-verbal encoder model movement generation visual'], ['Yin-Tse Lin, Shreya G. Upadhyay, Bo-Hao Su, Chi-Chun Lee', 'SWiBE: A Parameterized Stochastic Diffusion Process for Noise-Robust Bandwidth Expansion', 'lin24c_interspeech', 'score-based bwe parameterizations stepwise gan-based hyperparameters current including manifest encounter'], ['Joun Yeop Lee, Myeonghun Jeong, Minchan Kim, Ji-Hyun Lee, Hoon-Young Cho, Nam Soo Kim', 'High Fidelity Text-to-Speech Via Discrete Tokens Using Token Transducer and Group Masked Language Model', 'lee24f_interspeech', 'interpreting semantic speech speaking stage module enriching conformer-based high-fidelity text'], ['Shreya G. Upadhyay, Carlos Busso, Chi-Chun Lee', 'A Layer-Anchoring Strategy for Enhancing Cross-Lingual Speech Emotion Recognition', 'upadhyay24_interspeech', 'ser layer pretrained transformer hierarchical uncovers encapsulates msp-podcast podcast model'], ['Wei-Tung Hsu, Chin-Po Chen, Yun-Shao Lin, Chi-Chun Lee', 'A Cluster-based Personalized Federated Learning Strategy for End-to-End ASR of Dementia Patients', 'hsu24_interspeech', 'heterogeneity usage pause asr-related wer privacy-preserving adress distribution alzheimer challenge'], ['Hsing-Hang Chou, Woan-Shiuan Chien, Ya-Tse Wu, Chi-Chun Lee', 'An Inter-Speaker Fairness-Aware Speech Emotion Regression Framework', 'chou24_interspeech', 'ser fairness id fair knowing speaker cluster human-to-machine upfront speaker-level'], ['Jan LeheÄka, Josef V. Psutka, Lubos Smidl, Pavel Ircing, Josef Psutka', 'A Comparative Analysis of Bilingual and Trilingual Wav2Vec Models for Automatic Speech Recognition in Multilingual Oral History Archives', 'lehecka24_interspeech', 'mixed-language archive monolingual unique public heritage commonvoice releasing dataset push'], ['Dirk Eike Hoffner, Jana RoÃbach, Bernd T. Meyer', 'Joint prediction of subjective listening effort and speech intelligibility based on end-to-end learning', 'hoffner24_interspeech', 'non-intrusive character root-mean-square entropy-based model intrusive hearing-impaired normal-hearing quantified real-life'], ['Yaroslav Getman, Tamas Grosz, Mikko Kurimo', 'What happens in continued pre-training? Analysis of self-supervised speech models with continued pre-training for colloquial Finnish ASR', 'getman24_interspeech', 'multilingual specialize less-resourced high-resourced codeword language discovered quantized foundation purely'], ['Fredrik Cumlin, Xinyu Liang, Victor Ungureanu, Chandan K. A. Reddy, Christian SchÃ¼ldt, Saikat Chatterjee', 'DNSMOS Pro: A Reduced-Size DNN for Probabilistic MOS of Speech', 'cumlin24_interspeech', 'non-intrusive subjectively datasets rated quality method training design voip architecture'], ['Yaroslav Getman, Tamas Grosz, Katri Hiovain-Asikainen, Mikko Kurimo', 'Exploring adaptation techniques of large speech foundation models for low-resource ASR: a case study on Northern SÃ¡mi', 'getman24b_interspeech', 'fine-tuning pre-training already extended include low-resourced augments new preparing continued'], ['Hoan My Tran, David Guennec, Philippe Martin, Aghilas Sini, Damien Lolive, Arnaud Delhay, Pierre-FranÃ§ois Marteau', 'Spoofed Speech Detection with a Focus on Speaker Embedding', 'tran24_interspeech', 'deepfakes contrastive excel loss layer-wise deepfake finetuned spoof attentive wavlm'], ['Ya-Tse Wu, Jingyao Wu, Vidhyasaharan Sethu, Chi-Chun Lee', 'Can Modelling Inter-Rater Ambiguity Lead To Noise-Robust Continuous Emotion Predictions?', 'wu24d_interspeech', 'noise cer insufficiently ccc recola robustness concordance regularize broadly arousal'], ['Yuanyuan Zhang, Zhengjun Yue, Tanvina Patel, Odette Scharenborg', 'Improving child speech recognition with augmented child-like speech', 'zhang24d_interspeech', 'child-to-child cross-lingual augmentation model absolute asrs two-fold asr csr suboptimal'], ['Victor Miara, Theo Lepage, Reda Dehak', 'Towards Supervised Performance on Speaker Verification with Self-Supervised Learning by Leveraging Large-Scale ASR Models', 'miara24_interspeech', 'ssl pseudo-labels fine-tuning eer narrowing wavlm representation establishing iteratively refined'], ['Guanrou Yang, Ziyang Ma, Fan Yu, Zhifu Gao, Shiliang Zhang, Xie Chen', 'MaLa-ASR: Multimedia-Assisted LLM-Based ASR', 'yang24f_interspeech', 'llm auxiliary audio integrate keywords ingest information-rich surge fresh conveniently'], ['CÃ©cile Macaire, ChloÃ© Dion, Didier Schwab, Benjamin Lecouteux, Emmanuelle EsperanÃ§a-Rodier', 'Towards Speech-to-Pictograms Translation', 'macaire24_interspeech', 'cascade end-to-end tailor speech state-of-the-art in-depth nlp everyday specially released'], ['June-Woo Kim, Miika Toikkanen, Yera Choi, Seoung-Eun Moon, Ho-Young Jung', 'BTS: Bridging Text and Sound Modalities for Metadata-Aided Respiratory Sound Classification', 'kim24f_interspeech', 'rsc metadata text-audio patient recording multimodal icbhi sample surpassing validates'], ['Alexander Kathan, Martin BÃ¼rger, Andreas Triantafyllopoulos, Sabrina Milkus, Jonas Hohmann, Pauline Muderlak, JÃ¼rgen Schottdorf, Richard Musil, BjÃ¶rn Schuller, Shahin Amiriparian', 'Real-world PTSD Recognition: A Cross-corpus and Cross-linguistic Evaluation', 'kathan24_interspeech', 'mental analyse early disaster post-traumatic abuse wellbeing sexual cross-cultural combat'], ['Pu Wang, Junhui Li, Jialu Li, Liangdong Guo, Youshan Zhang', 'Diffusion Gaussian Mixture Audio Denoise', 'wang24m_interspeech', 'model reverse noise distribution signal clean comply subtracted noisy estimate'], ['Thomas Graave, Zhengyang Li, Timo Lohrenz, Tim Fingscheidt', 'Mixed Children/Adult/Childrenized Fine-Tuning for Childrenâs ASR: How to Reduce Age Mismatch and Speaking Style Mismatch', 'graave24_interspeech', 'speech read partially matched pre-trained child absolute datasets individual deteriorate'], ['Shucong Zhang, Titouan Parcollet, Rogier van Dalen, Sourav Bhattacharya', 'Linear-Complexity Self-Supervised Learning for Speech Processing', 'zhang24e_interspeech', 'mhsa pre-training ssl gpus week wav vec encoder model tesla'], ['Fan Huang, Kun Zeng, Wei Zhu', 'DiffVC+: Improving Diffusion-based Voice Conversion for Speaker Anonymization', 'huang24_interspeech', 'privacy converted speech encoder embedding server-side content suppresses decoupled leakage'], ['Zhengyang Li, Patrick Blumenberg, Jing Liu, Thomas Graave, Timo Lohrenz, Siegfried Kunzmann, Tim Fingscheidt', 'Interleaved Audio/Audiovisual Transfer Learning for AV-ASR in Low-Resourced Languages', 'li24i_interspeech', '-stage target stage language german excels cross-modality catastrophic forgetting english'], ['Arnav Kundu, Prateeth Nayak, Priyanka Padmanabhan, Devang Naik', 'RepCNN: Micro-sized, Mighty Models for Wakeword Detection', 'kundu24_interspeech', 'always-on runtime memory footprint compute inference uni-branch convolutional model re-parameterized'], ['ThÃ©odor Lemerle, Nicolas Obin, Axel Roebel', 'Small-E: Small Language Model with Linear Attention for Efficient Speech Synthesis', 'lemerle24_interspeech', 'transformer cloning zero-shot architecture showcased decoder-only powered impeding tt skipping'], ['Ji-Hun Kang, Jae-Hong Lee, Mun-Hak Lee, Joon-Hyuk Chang', 'Whisper Multilingual Downstream Task Tuning Using Task Vectors', 'kang24_interspeech', 'model vector direction weight orient summing simple space arithmetic effective'], ['Luis Felipe Parra-Gallego, Tilak Purohit, Bogdan Vlasenko, Juan Rafael Orozco-Arroyave, Mathew Magimai.-Doss', 'Cross-transfer Knowledge between Speech and Text Encoders to Evaluate Customer Satisfaction', 'parragallego24_interspeech', 'bert reputation distilling enriching cost-effective wavlm asr learning company whisper'], ['Honglie Chen, Rodrigo Mira, Stavros Petridis, Maja Pantic', 'RT-LA-VocE: Real-Time Low-SNR Audio-Visual Speech Enhancement', 'chen24g_interspeech', 'frame causal latency stream emformer devising non-causal state-of-the-art audio component'], ['Mara Barberis, Pieter De Clercq, Bastiaan Tamm, Hugo Van hamme, Maaike Vandermosten', 'Automatic recognition and detection of aphasic natural speech', 'barberis24_interspeech', 'aphasia asr svm feature detect stroke semi-automatically administered semi-automatic consuming'], ['Moreno La Quatra, Maria Francesca Turco, TorbjÃ¸rn Svendsen, Giampiero Salvi, Juan Rafael Orozco-Arroyave, Sabato Marco Siniscalchi', "Exploiting Foundation Models and Speech Enhancement for Parkinson's Disease Detection from Speech in Real-World Operative Conditions", 'laquatra24_interspeech', 'pc-gita base performance devising foundational off-the-shelf wavlm hubert fine-tune drop'], ['Cong Zhang, Tong Li, Gayle DeDe, Christos Salis', 'Prosody of speech production in latent post-stroke aphasia', 'zhang24f_interspeech', 'neurotypical mild forest prosodic random left-hemisphere utterance-initial reinforced stroke control'], ['Lorenzo Maselli, VÃ©ronique Delvaux', 'Aerodynamics of Sakata labial-velar oral stops', 'maselli24_interspeech', 'bilabial airflow plain pressure manova congo delineated variable southwestern universitÃ©'], ['Jongsuk Kim, Jiwon Shin, Junmo Kim', 'AVCap: Leveraging Audio-Visual Features as Text Tokens for Captioning', 'kim24g_interspeech', 'advancement extensibility human-level pivotal scalability exploration com github model applicable'], ['Hassan Taherian, Vahid Ahmadi Kalkhorani, Ashutosh Pandey, Daniel Wong, Buye Xu, DeLiang Wang', 'Towards Explainable Monaural Speaker Separation with Auditory-based Training', 'taherian24_interspeech', 'pit permutation onset criterion cue ambiguity pitch hybrid talker-independent same-gender'], ['Anith Selvakumar, Homa Fashandi', 'Getting More for Less: Using Weak Labels and AV-Mixup for Robust Audio-Visual Speaker Verification', 'selvakumar24_interspeech', 'dml voxceleb multimodal overfit space multitask reporting owing dominated learning'], ['Avihu Dekel, Raul Fernandez', 'Exploring the Benefits of Tokenization of Discrete Acoustic Units', 'dekel24_interspeech', 'dau variable-rate vocabulary overlooked audio-based showcase task merge playing grapheme-to-phoneme'], ['Junzuo Zhou, Jiangyan Yi, Tao Wang, Jianhua Tao, Ye Bai, Chu Yuan Zhang, Yong Ren, Zhengqi Wen', 'TraceableSpeech: Towards Proactively Traceable Text-to-Speech with Watermarking', 'zhou24b_interspeech', 'watermark imperceptibility speech attack flexibility quality watermarked vall-e tt resilience'], ['Georgios Chochlakis, Chandrashekhar Lavania, Prashant Mathur, Kyu J. Han', 'Tackling Missing Modalities in Audio-Visual Representation Learning Using Masked Autoencoders', 'chochlakis24_interspeech', 'imputed pristine robust curriculum make lombard retraining trained autoencoder necessarily'], ['Lun Wang, Om Thakkar, Zhong Meng, Nicole Rafidi, Rohit Prabhavalkar, Arun Narayanan', 'Efficiently Train ASR Models that Memorize Less and Perform Better with Per-core Clipping', 'wang24n_interspeech', 'pcc gradient memorization unintended mitigate apcc minibatch streamlined multifaceted training'], ['Zilong Huang, Man-Wai Mak, Kong Aik Lee', 'MM-NodeFormer: Node Transformer Multimodal Fusion for Emotion Recognition in Conversation', 'huang24b_interspeech', 'modality erc richness emotional auxiliary text consultation visual meld main'], ['Ji Sub Um, Hoirin Kim', 'Utilizing Adaptive Global Response Normalization and Cluster-Based Pseudo Labels for Zero-Shot Voice Conversion', 'um24b_interspeech', 'content information conduct speaker convnext layer dynamic transmit conveying transmitted'], ['Jialu Li, Mark Hasegawa-Johnson, Karrie Karahalios', 'Enhancing Child Vocalization Classification with  Phonetically-Tuned Embeddings for Assisting Autism Diagnosis', 'li24j_interspeech', 'clinician old auxiliary behavior build year reproducible helping labor audio'], ['Alexander Johnson, Peter Plantinga, Pheobe Sun, Swaroop Gadiyaram, Abenezer Girma, Ahmad Emami', 'Efficient SQA from Long Audio Contexts: A Policy-driven Approach', 'johnson24_interspeech', 'file compute safely skipping infeasible podcasts recording skip retrieving growth'], ['Li-Fang Lai, Nicole Holliday', 'Voice Quality Variation in AAE: An Additional Challenge for Addressing Bias in ASR Models?', 'lai24_interspeech', 'creaky mae creak american men woman young phonation creakier non-modal'], ['Shiran Aziz, Yossi Adi, Shmuel Peleg', 'Audio Enhancement from Multiple Crowdsourced Recordings: A Simple and Effective Baseline', 'aziz24_interspeech', 'event local noise location device signal cleaned uncorrelated cellular unrelated'], ['Wen Wu, Chao Zhang, Philip C. Woodland', 'Confidence Estimation for Automatic Detection of Depression and Alzheimerâs Disease Based on Clinical Interviews', 'wu24e_interspeech', 'daic-woz informs adress distribution second-order dirichlet clinician attracted speech-based risk'], ['Vikentii Pankov, Valeria Pronina, Alexander Kuzmin, Maksim Borisov, Nikita Usoltsev, Xingshan Zeng, Alexander Golubkov, Nikolai Ermolenko, Aleksandra Shirshova, Yulia Matveeva', 'DINO-VITS: Data-Efficient Zero-Shot TTS with Self-Supervised Speaker Verification Loss for Noise Robustness', 'pankov24_interspeech', 'dino noisy training encoder clean noise-robustness speech cloning objective discriminability'], ['Jie Chi, Electra Wallington, Peter Bell', 'Characterizing code-switching: Applying Linguistic Principles for Metric Assessment and Development', 'chi24_interspeech', 'leverage data-sets hindi-english capture mandarin-english code-switched richness intuition participating vital'], ['Sean Robertson, Gerald Penn, Ewan Dunbar', 'Quantifying the Role of Textual Predictability in Automatic Speech Recognition', 'robertson24_interspeech', 'model asr straightforwardly ability long-standing diagnosing use higher-order spite context'], ['Shiyi Han, Mingbin Xu, Zhihong Lei, Zhen Huang, Xingyu Na', 'Enhancing CTC-based speech recognition with diverse modeling units', 'han24_interspeech', 'model synergistic grapheme-based asr phoneme-based heterogeneous driving align evolution remarkable'], ['Zhiqi Huang, Diamantino Caseiro, Kandarp Joshi, Christopher Li, Pat Rondon, Zelin Wu, Petr Zadrazil, Lillian Zhou', 'Optimizing Large-Scale Context Retrieval for End-to-End ASR', 'huang24c_interspeech', 'entity scalable comparative recall scoring contextual accurate outstanding segment-level method'], ['Yiling Huang, Weiran Wang, Guanlong Zhao, Hank Liao, Wei Xia, Quan Wang', 'On the Success and Limitations of Auxiliary Network Based Word-Level End-to-End Neural Speaker Diarization', 'huang24d_interspeech', 'spoke asr turn-based capability modularized logits eend blank -speaker rnn-t'], ['Chung-Ming Chien, Andros Tjandra, Apoorv Vyas, Matt Le, Bowen Shi, Wei-Ning Hsu', 'Learning Fine-Grained Controllability on Speech Generation via Efficient Fine-Tuning', 'chien24b_interspeech', 'voicebox adapter pre-trained module lora reuse grow across compromising follow-up'], ['Ankit Gupta, George Saon, Brian Kingsbury', 'Exploring the limits of decoder-only models trained on public speech recognition corpora', 'gupta24_interspeech', 'whisper asr transformer competitive owsm open hour permissive large-v checkpoint'], ['Woo Hyun Kang, Srikanth Vishnubhotla, Rudolf Braun, Yogesh Virkar, Raghuveer Peri, Kyu J. Han', 'SWAN: SubWord Alignment Network for HMM-free word timing estimation in end-to-end automatic speech recognition', 'kang24b_interspeech', 'wte hmm asr multilingual method fleurs label inability accumulated phonetic'], ['Frank Seide, Yangyang Shi, Morrie Doulaty, Yashesh Gaur, Junteng Jia, Chunyang Wu', 'Speech ReaLLM â Real-time Speech Recognition with Multimodal Language Models by Teaching the Flow of Time', 'seide24_interspeech', 'llm decoder-only architecture rnn-t asr end-pointing empty real reasonably without'], ['Tuan Vu Ho, Kota Dohi, Yohei Kawaguchi', 'Stream-based Active Learning for Anomalous Sound Detection in Machine Condition Monitoring', 'ho24_interspeech', 'asd sample budget unexplored dcase updating framework receiver backend retraining'], ['Virat Shejwalkar, Om Thakkar, Arun Narayanan', 'Quantifying Unintended Memorization in BEST-RQ ASR Encoders', 'shejwalkar24_interspeech', 'auditing downstream real-world unintentionally memorize sample clipping impacting conformer-based mitigating'], ['Ke Chen, Jiaqi Su, Taylor Berg-Kirkpatrick, Shlomo Dubnov, Zeyu Jin', 'Improving Generalization of Speech Separation in Real-World Scenarios: Strategies in Simulation, Optimization, and Evaluation', 'chen24h_interspeech', 'pipeline training diverse content acoustic separator pit objective across environment'], ['Tien-Ju Yang, Andrew Rosenberg, Bhuvana Ramabhadran', 'Contemplative Mechanism for Speech Recognition: Speech Encoders can Think', 'yang24g_interspeech', 'token size encoder strategically interleaving doubling model inserting encourages innovation'], ['Pan-Pan Jiang, Jimmy Tobin, Katrin Tomanek, Robert MacDonald, Katie Seaver, Richard Cave, Marilyn Ladewig, Rus Heywood, Jordan Green', 'Learnings from curating a trustworthy, well-annotated, and useful dataset of disordered English speech', 'jiang24_interspeech', 'metadata project correction transcript annotation inter-rater report machine-learning gathering rationale'], ['Ante JukiÄ, Roman Korostik, Jagadeesh Balam, Boris Ginsburg', 'SchrÃ¶dinger Bridge for Generative Speech Enhancement', 'jukic24_interspeech', 'model dereverberation denoising clean loss diffusion-based complex-valued distribution tractable baseline'], ['Naijun Zheng, Xucheng Wan, Kai Liu, Ziqing Du, Zhou Huan', 'An efficient text augmentation approach for contextualized Mandarin speech recognition', 'zheng24_interspeech', 'contextualize speech-text text-only asr codebook embeddings pre-trained uncommon top-performing hindered'], ['Jiafeng Zhong, Bin Li, Jiangyan Yi', 'Enhancing Partially Spoofed Audio Localization with Boundary-aware Attention Mechanism', 'zhong24_interspeech', 'boundary bam authenticity frame partialspoof intra-frame inter-frame fake unexplored frame-wise'], ['Zejiang Hou, Goeric Huybrechts, Anshu Bhatia, Daniel Garcia-Romero, Kyu J. Han, Katrin Kirchhoff', 'Revisiting Convolution-free Transformer for Speech Recognition', 'hou24_interspeech', 'conformer convolution wer architecture training scale state-ofthe-art module catch inductive'], ['Houjian Guo, Chaoran Liu, Carlos Toshinori Ishi, Hiroshi Ishiguro', 'X-E-Speech: Joint Training Framework of Non-Autoregressive Cross-lingual Emotional Text-to-Speech and Voice Conversion', 'guo24b_interspeech', 'tt speech model style-related content-related freeze similarity content nar synthesis'], ['Haici Yang, Jiaqi Su, Minje Kim, Zeyu Jin', 'Genhancer: High-Fidelity Speech Enhancement via Generative Modeling on Discrete Codec Tokens', 'yang24h_interspeech', 'conditioning speaker-identity content retention enforce conventional audio domain supplement provide'], ['Yanxiong Li, Jiaxin Tan, Guoqing Chen, Jialong Li, Yongjie Si, Qianhua He', 'Low-Complexity Acoustic Scene Classification Using Parallel Attention-Convolution Network', 'li24k_interspeech', 'dcase challenge contextual global local exceeds distillation method clip com'], ['Yifei Xin, Zhihong Zhu, Xuxin Cheng, Xusheng Yang, Yuexian Zou', 'Audio-text Retrieval with Transformer-based Hierarchical Alignment and Disentangled Cross-modal Representation', 'xin24b_interspeech', 'atr dcr tha latent factor transformer audio finegrained semantic single-level'], ['Huai-Zhe Yang, Chia-Ping Chen, Shan-Yun He, Cheng-Ruei Li', 'Bilingual and Code-switching TTS Enhanced with Denoising Diffusion Model and GAN', 'yang24i_interspeech', 'adversarial consistency mo speaker employ classifier mandarin-english speech push featuring'], ['Shiu-Hsiang Liou, Po-Cheng Chan, Chia-Ping Chen, Tzu-Chieh Lin, Chung-Li Lu, Yu-Han Cheng, Hsiang-Feng Chuang, Wei-Yu Chen', 'Enhancing ECAPA-TDNN with Feature Processing Module and Attention Mechanism for Speaker Verification', 'liou24_interspeech', 'kernel temporal front-end weight ecapa capture flop expands assigns mindcf'], ['HengYu Li, Kangdi Mei, Zhaoci Liu, Yang Ai, Liping Chen, Jie Zhang, Zhenhua Ling', 'Refining Self-supervised Learnt Speech Representation using Brain Activations', 'li24l_interspeech', 'similarity model downstream pre-trained often-used superb fmri human aligning refine'], ['Tianteng Gu, Bei Liu, Hang Shao, Yanmin Qian', 'SparseWAV: Fast and Accurate One-Shot Unstructured Pruning for Large Speech Foundation Models', 'gu24_interspeech', 'parameter remove compression pre-trained unimportant eliminated sacrificing negligible performance consumption'], ['Changhwan Kim', 'ClariTTS: Feature-ratio Normalization and Duration Stabilization for Code-mixed Multi-speaker Speech Synthesis', 'kim24h_interspeech', 'tt accent language speaker synthesized disentangles flow-based speaker-related linguistic affine'], ['Junhui Li, Pu Wang, Jialu Li, Youshan Zhang', 'Complex Image-Generative Diffusion Transformer for Audio Denoising', 'li24m_interspeech', 'attention image field generation deep model expands leaving receptive scalability'], ['Aijun Li, Jun Gao, Zhiwei Wang', 'Effect of Complex Boundary Tones on Tone Identification: An Experimental Study with Mandarin-speaking Preschool Children', 'li24n_interspeech', 'suabt preschooler word age tonal forty-eight decoding stabilizes impede child-directed'], ['Nameer Hirschkind, Xiao Yu, Mahesh Kumar Nandwana, Joseph Liu, Eloi DuBois, Dao Le, Nicolas Thiebaut, Colin Sinclair, Kyle Spence, Charles Shang, Zoe Abrams, Morgan McGuire', 'Diffusion Synthesizer for Efficient Multilingual Speech to Speech Translation', 'hirschkind24_interspeech', 'diffusion-based tacotron-based low-latency zero-shot translating double speech-to-speech bleu count pesq'], ['Yu Nakagome, Michael Hentschel', 'InterBiasing: Boost Unseen Word Recognition through Biasing Intermediate Predictions', 'nakagome24_interspeech', 'label ctc subsequent unknown self-conditioned parameter-free keywords layer pair substituting'], ['Haixin Guan, Wei Dai, Guangyong Wang, Xiaobin Tan, Peng Li, Jiaen Liang', 'Reducing Speech Distortion and Artifacts for Speech Enhancement by Loss Function', 'guan24_interspeech', 'combined governing diminish persist stride dns lightweight learning-based continuity formation'], ['Tzu-Quan Lin, Hung-yi Lee, Hao Tang', 'DAISY: Data Adaptive Self-Supervised Early Exit for Speech Representation Models', 'lin24d_interspeech', 'fine-tuning inference adaptivity layer need round decides hubert eliminating adjusting'], ['Guanlin Chen, Yun Jin', "Cascaded Transfer Learning Strategy for Cross-Domain Alzheimer's  Disease Recognition through Spontaneous Speech", 'chen24i_interspeech', 'subspace second-level first-level corpus gpt- multi-source respectively experiment forest align'], ['Keiko Ochi, Koji Inoue, Divesh Lala, Tatsuya Kawahara', 'Entrainment Analysis and Prosody Prediction of Subsequent Interlocutorâs Backchannels in Dialogue', 'ochi24_interspeech', 'preceding utterance prosodic feature power regression interrelationship empathy svr attentive'], ['Shubham Gupta, Mirco Ravanelli, Pascal Germain, Cem Subakan', 'Phoneme Discretized Saliency Maps for Explainable Detection of AI-Generated Voice', 'gupta24b_interspeech', 'explanation discretization faithful understandable associating fastspeech standard tacotron algorithm experimentally'], ['Atsushi Ando, Takafumi Moriya, Shota Horiguchi, Ryo Masumura', 'Factor-Conditioned Speaking-Style Captioning', 'ando24_interspeech', 'caption generates gts factor ensure diverse deterministically original learning guarantee'], ['Zhe Liu, Suyoun Kim, Ozlem Kalinli', 'Evaluating Speech Recognition Performance Towards Large Language Model Based Voice Assistants', 'liu24c_interspeech', 'llm asr semantic metric curated popularity failure cascaded raised judgement'], ['Francesco Paissan, Luca Della Libera, Zhepei Wang, Paris Smaragdis, Mirco Ravanelli, Cem Subakan', 'Audio Editing with Non-Rigid Text Prompts', 'paissan24b_interspeech', 'edits diffusion pipeline latent inpainting faithfulness lora user qualitatively fidelity'], ['Shilin Wang, Haixin Guan, Yanhua Long', 'QMixCAT: Unsupervised Speech Enhancement Using Quality-guided Signal Mixing and Competitive Alternating Model Training', 'wang24o_interspeech', 'teacher-student supervised mixture cat epoch learning-based framework iteratively trained innovative'], ['Shuai Wang, Dehao Zhang, Kexin Shi, Yuchen Wang, Wenjie Wei, Jibin Wu, Malu Zhang', 'Global-Local Convolution with Spiking Neural Networks for Energy-efficient Keyword Spotting', 'wang24p_interspeech', 'kw module fewer efficiency energy extraction sparser lightweight hand-crafted performance'], ['Yuexuan Kong, Viet-Anh Tran, Romain Hennequin', 'STraDa: A Singer Traits Dataset', 'kong24_interspeech', 'metadata downloadable track thousand lead file bias ssc twenty-five benchmarked'], ['Junseok Ahn, Youkyum Kim, Yeunju Choi, Doyeop Kwak, Ji-Hoon Kim, Seongkyu Mun, Joon Son Chung', 'VoxSim: A perceptual voice similarity dataset', 'ahn24b_interspeech', 'speaker prediction vcc utilised benchmarking automate unexplored leaving score out-of-domain'], ['Jialong Mai, Xiaofen Xing, Weidong Chen, Xiangmin Xu', 'DropFormer: A Dynamic Noise-Dropping Transformer for Speech Emotion Recognition', 'mai24_interspeech', 'dropping emotional local information ser token non-emotional overlook meld overly'], ['Peng Wang, Yifan Yang, Zheng Liang, Tian Tan, Shiliang Zhang, Xie Chen', 'Incorporating Class-based Language Model for Named Entity Recognition in Factorized Neural Transducer', 'wang24q_interspeech', 'fnt ner biasing hurting decoupling triggering excessive lm attention-based risk'], ['Duc-Tuan Truong, Ruijie Tao, Tuan Nguyen, Hieu-Thi Luong, Kong Aik Lee, Eng Siong Chng', 'Temporal-Channel Modeling in Multi-head Self-Attention for Synthetic Speech Detection', 'truong24b_interspeech', 'mhsa temporal transformer dependency channel module neglect ablation input artifact'], ['Fei Zhao, Chenggang Zhang, Shulin He, Jinjiang Liu, Xueliang Zhang', 'Deep Echo Path Modeling for Acoustic Echo Cancellation', 'zhao24_interspeech', 'aec near-end scenario learning unseen single-talk complex full-duplex double-talk generalizing'], ['Jen-Hung Huang, Wei-Tsung Lee, Chung-Hsien Wu', 'USD-AC: Unsupervised Speech Disentanglement for Accent Conversion', 'huang24e_interspeech', 'content generalization disentangles exceptional linguistic grounded adaptability generalizability boosting learning'], ['Yuqin Lin, Longbiao Wang, Jianwu Dang, Nobuaki Minematsu', 'Exploring Pre-trained Speech Model for Articulatory Feature Extraction in Dysarthric Speech Using ASR', 'lin24e_interspeech', 'phonemic dysarthria pretrained attribute extract torgo detection uaspeech information dysphonia'], ['Yiying Hu, Hui Feng', 'Key Acoustic Cues for the Realization of Metrical Prominence in Tone Languages: A Cross-Dialect Study', 'hu24_interspeech', 'right-dominant pitch cumulative analysis dialect intensity identify metrically dynamic across'], ['Marc HÃ¤rkÃ¶nen, Samuel J. Broughton, Lahiru Samarakoon', 'EEND-M2F: Masked-attention mask transformers for speaker diarization', 'harkonen24_interspeech', 'end-to-end dihard-iii segmentation alimeeting winning truly stack eliminating irrelevant der'], ['Dongheon Lee, Jung-Woo Choi', 'DeFTAN-AA: Array Geometry Agnostic Multichannel Speech Enhancement', 'lee24g_interspeech', 'spatial cross-attention microphone block channel-wise foreground alleviates dense gated various'], ['Neil Shah, Shirish Karande, Vineet Gandhi', 'Towards Improving NAM-to-Speech Synthesis Intelligibility using Self-Supervised Speech Models', 'shah24_interspeech', 'nam self-supervision seq ground-truth methodology non-audible mcd murmur cstr gauge'], ['Pin-Yen Liu, Jen-Tzung Chien', 'Modality Translation Learning for Joint Speech-Text Model', 'liu24d_interspeech', 'speech shared text emotional cross-modality harness space unexplored struggle hardly'], ['Semin Kim, Myeonghun Jeong, Hyeonseung Lee, Minchan Kim, Byoung Jin Choi, Nam Soo Kim', 'MakeSinger: A Semi-Supervised Training Method for Data-Efficient Singing Voice Synthesis via Classifier-free Diffusion Guidance', 'kim24i_interspeech', 'svs data pitch tt semisupervised diffusion-based gathering guiding text dual'], ['Hanyu Meng, Qiquan Zhang, Xiangyu Zhang, Vidhyasaharan Sethu, Eliathamby Ambikairajah', 'Binaural Selective Attention Model for Target Speaker Extraction', 'meng24b_interspeech', 'time-domain configuration fasnet filter-and-sum si-sdr inter-channel separator two-speaker anechoic cocktail'], ['Liuxian Ma, Lin Shen, Ruobing Li, Haojie Zhang, Kun Qian, Bin Hu, BjÃ¶rn W. Schuller, Yoshiharu Yamamoto', 'E-ODN: An Emotion Open Deep Network for Generalised and Adaptive Speech Emotion Recognition', 'ma24_interspeech', 'emotional type infer ser model widest finer-grained uneven range unbalanced'], ['Hongyang Chen, Yuhong Yang, Zhongyuan Wang, Weiping Tu, Haojun Ai, Cedar Lin', 'Exploring Sentence Type Effects on the Lombard Effect and Intelligibility Enhancement: A Comparative Study of Natural and Grid Sentences', 'chen24j_interspeech', 'lct pronounced superior normal-to-lombard corpus valuable enhancing maintaining perspective focusing'], ['Masaya Kawamura, Ryuichi Yamamoto, Yuma Shirahata, Takuya Hasumi, Kentaro Tachibana', 'LibriTTS-P: A Corpus with Speaking Style and Speaker Identity Prompts for Text-to-Speech and Style Captioning', 'kawamura24_interspeech', 'libritts-r annotation prompt prompt-based tt speaker-level model dataset controllable conventional'], ['Yujie Chen, Jiangyan Yi, Jun Xue, Chenglong Wang, Xiaohui Zhang, Shunbo Dong, Siding Zeng, Jianhua Tao, Zhao Lv, Cunhang Fan', 'RawBMamba: End-to-End Bidirectional State Space Model for Audio Deepfake Detection', 'chen24k_interspeech', 'long-range fake mamba bonafide capture short information short-range sinc combining'], ['Xujiang Xing, Mingxing Xu, Thomas Fang Zheng', 'A Joint Noise Disentanglement and Adversarial Training Framework for Robust Speaker Verification', 'xing24_interspeech', 'noise-independent encoder embedding condition discourage supervise module speaker-invariant noisy space'], ['Chaeyoung Jung, Suyeon Lee, Ji-Hoon Kim, Joon Son Chung', 'FlowAVSE: Efficient Audio-Visual Speech Enhancement with Conditional Flow Matching', 'jung24b_interspeech', 'diffusion-based inference speed quality github reduces u-net output learnable degrading'], ['Yosuke Kashiwagi, Hayato Futami, Emiru Tsunoo, Siddhant Arora, Shinji Watanabe', 'Rapid Language Adaptation for Multilingual E2E Speech Recognition Using Encoder Prompting', 'kashiwagi24_interspeech', 'ctc language-specific prompt self-conditioned conditionally model zero-shot incoming attention-based multi-task'], ['Zhaoqing Li, Haoning Xu, Tianzi Wang, Shoukang Hu, Zengrui Jin, Shujie Hu, Jiajun Deng, Mingyu Cui, Mengzhe Geng, Xunying Liu', 'One-pass Multiple Conformer and Foundation Speech Systems Compression and Quantization Using An All-in-one Neural Model', 'li24o_interspeech', 'librispeech- wer switchboard- nested incurring single speed-up asr width store'], ['Emiru Tsunoo, Hayato Futami, Yosuke Kashiwagi, Siddhant Arora, Shinji Watanabe', 'Decoder-only Architecture for Streaming End-to-end Speech Recognition', 'tsunoo24_interspeech', 'blockwise prompt asr lm decoder subnetwork ample speech-processing test-other truncated'], ['Sichen Jin, Youngmoon Jung, Seungjin Lee, Jaeyoung Roh, Changwoo Han, Hoonyoung Cho', 'CTC-aligned Audio-Text Embedding for Streaming Open-vocabulary Keyword Spotting', 'jin24d_interspeech', 'kw text libriphrase frame non-streaming mere aligns aggregated attain on-the-fly'], ['Kiyoshi Kurihara, Masanori Sano', 'Enhancing Japanese Text-to-Speech Accuracy with a Novel Combination Transformer-BERT-based G2P: Integrating Pronunciation Dictionaries and Accent Sandhi', 'kurihara24_interspeech', 'transformer numeral counter bert transformer-based noun external proper dictionary employ'], ['Jiahao Li, Miao Liu, Shu Yang, Jing Wang, Xiang Xie', 'Motion Based Audio-Visual Segmentation', 'li24p_interspeech', 'av object task video mva attention module crossmodal pixel optical'], ['Le Xu, Jiangyan Yi, Tao Wang, Yong Ren, Rongxiu Zhong, Zhengqi Wen, Jianhua Tao', 'Residual Speaker Representation for One-Shot Voice Conversion', 'xu24b_interspeech', 'timbre robustness multi-layer approximation unseen encountering limited control challenge page'], ['Hayato Futami, Siddhant Arora, Yosuke Kashiwagi, Emiru Tsunoo, Shinji Watanabe', 'Finding Task-specific Subnetworks in Multi-task Spoken Language Understanding Model', 'futami24_interspeech', 'slu task forgetting previously trained adapting experiencing subnetwork mitigated catastrophic'], ['Pengfei Cai, Yan Song, Kang Li, Haoyu Song, Ian McLoughlin', 'MAT-SED: A Masked Audio Transformer with Masked-Reconstruction Based Pre-training for Sound Event Detection', 'cai24_interspeech', 'psds sed dcase network context pre-trained encoder global-local rnn-based positional'], ['Yuliya Korotkova, Ilya Kalinovskiy, Tatiana Vakhrusheva', 'Word-level Text Markup for Prosody Control in Speech Synthesis', 'korotkova24_interspeech', 'hand-labeling intonation tt one-to-many prosodic interpretable scalability expertise quantized problem'], ['Ryandhimas E. Zezario, Fei Chen, Chiou-Shann Fuh, Hsin-Min Wang, Yu Tsao', 'Non-Intrusive Speech Intelligibility Prediction for Hearing Aids using Whisper and Metadata', 'zezario24_interspeech', 'mbi-net clarity embeddings haspi hearing-aid metric top-performing validating intrusive pivotal'], ['Anfeng Xu, Kevin Huang, Tiantian Feng, Lue Shen, Helen Tager-Flusberg, Shrikanth Narayanan', 'Exploring Speech Foundation Models for Speaker Diarization in Child-Adult Dyadic Interactions', 'xu24c_interspeech', 'understanding child exemplary opened pathway demographic adopting vast opportunity addressing'], ['Mario Zusag, Laurin Wagner, Bernhad Thallinger', 'CrisperWhisper: Accurate Timestamps on Verbatim Speech Transcriptions', 'zusag24_interspeech', 'hallucination finetune tokenizer transcription timed cross-attention adjusting whisper filler adjustment'], ['AndrÃ©s PiÃ±eiro-MartÃ­n, Carmen GarcÃ­a-Mateo, Laura Docio-Fernandez, MarÃ­a del Carmen LÃ³pez-PÃ©rez, Georg Rehm', 'Weighted Cross-entropy for Low-Resource Languages in Multilingual Speech Recognition', 'pineiromartin24_interspeech', 'high-resource wer whisper asr reduction continual model unbalanced fine-tune remarkable'], ['Yujie Yan, Xiran Xu, Haolin Zhu, Pei Tian, Zhongshu Ge, Xihong Wu, Jing Chen', 'Auditory Attention Decoding in Four-Talker Environment with EEG', 'yan24b_interspeech', 'aad asad trf cortical spatial indicated unattended two-talker scenario lateralization'], ['Cunhang Fan, Shunbo Dong, Jun Xue, Yujie Chen, Jiangyan Yi, Zhao Lv', 'Frequency-mix Knowledge Distillation for Fake Speech Detection', 'fan24_interspeech', 'fsd telephony asvspoof generalization scenario competitively combat undergoes model information'], ['Yafeng Chen, Siqi Zheng, Hui Wang, Luyao Cheng, Qian Chen, Shiliang Zhang, Junjie Li', 'ERes2NetV2: Boosting Short-Duration Speaker Verification Performance with Computational Efficiency', 'chen24l_interspeech', 'trial net voxceleb fusion tasked sub-optimal feature multi-scale backbone ultimately'], ['Anika A. Spiesberger, Andreas Triantafyllopoulos, Alexander Kathan, Anastasia Semertzidou, Caterina Gawrilow, Tilman Reinelt, Wolfgang A. Rauch, BjÃ¶rn Schuller', 'âSo . . . my child . . . â â How Child ADHD Influences the Way Parents Talk', 'spiesberger24_interspeech', 'mental symptomatology exerts parental parent-child surpassed well-being preschool cumbersome impractical'], ['Lifeng Zhou, Yuke Li, Rui Deng, Yuting Yang, Haoqi Zhu', 'Cross-Modal Denoising: A Novel Training Paradigm for Enhancing Speech-Image Retrieval', 'zhou24c_interspeech', 'modality framework inference feature alignment flickr interaction dataset effective task'], ['Malin Svensson Lundmark', 'Magnitude and timing of acceleration peaks in stressed and unstressed syllables', 'svenssonlundmark24_interspeech', 'velocity lower articulator lip peak measured segment expands posture accounted'], ['Ruizhe Huang, Mahsa Yarmohammadi, Sanjeev Khudanpur, Daniel Povey', 'Improving Neural Biasing for Contextual Speech Recognition by Early Context Injection and Text Perturbation', 'huang24f_interspeech', 'rare perturb inject technique context-aware enforce model asr merely encoders'], ['Yue Li, Xinsheng Wang, Li Zhang, Lei Xie', 'SCDNet: Self-supervised Learning Feature based Speaker Change Detection', 'li24q_interspeech', 'scd ssl wavlm wav vec model potent discern showcase task'], ['Zijie Lin, Tianyu He, Siqi Cai, Haizhou Li', 'ASA: An Auditory Spatial Attention Dataset with Multiple Speaking Locations', 'lin24f_interspeech', 'asad datasets localizing sound featuring electroencephalography cocktail attended source eeg'], ['Nan Chen, Yonghe Wang, Feilong Bao', 'Parameter-Efficient Adapter Based on Pre-trained Models for Speech Translation', 'chen24m_interspeech', 'peft parameter trainable fine-tuning poorest non-negligible performance na lora mtl'], ['Tin Mei Lun, Ekaterina Voskoboinik, Ragheb Al-Ghezi, Tamas Grosz, Mikko Kurimo', 'Oversampling, Augmentation and Curriculum Learning for Speaking Assessment with Limited Training Data', 'lun24_interspeech', 'finland imbalance greatest finnish evaluates remarkable swedish boost proficiency low-resource'], ['Fei Zhao, Jinjiang Liu, Xueliang Zhang', 'SDAEC: Signal Decoupling for Advancing Acoustic Echo Cancellation', 'zhao24b_interspeech', 'energy reference scaling subsequent microphone network impedes multiplied cancel factor'], ['YongKang Yin, Xu Li, Ying Shan, YueXian Zou', 'AFL-Net: Integrating Audio, Facial, and Lip Modalities with a Two-step Cross-attention for Robust Speaker Diarization in the Wild', 'yin24_interspeech', 'modality enhance obscured strategy fuse multi-modal sufficiently randomly scene enhances'], ['Genshun Wan, Mengzhi Wang, Tingzhi Mao, Hang Chen, Zhongfu Ye', 'Lightweight Transducer Based on Frame-Level Criterion', 'wan24_interspeech', 'blank output probability achieving element encoder decoder truncate memory non-blank'], ['Hiroki Kanagawa, Takafumi Moriya, Yusuke Ijima', 'Pre-training Neural Transducer-based Streaming Voice Conversion for Faster Convergence and Alignment-free Training', 'kanagawa24_interspeech', 'vc-t seq guiding alignment tensor probable path pipeline matrix improbable'], ['Jing Wu, Ting Chen, Minchuan Chen, Wei Hu, Shaojun Wang, Jing Xiao', 'Improving Multilingual Text-to-Speech with Mixture-of-Language-Experts and Accent Disentanglement', 'wu24f_interspeech', 'code-switching tt conquer intra-utterance authenticity seamless aligns comprehensibility thorough fuse'], ['Boyong Wu, Chao Yan, Haoran Pu', 'Transferable speech-to-text large language model alignment module', 'wu24g_interspeech', 'speech-text subspace capability swap sqa like concatenate svd altogether multitask'], ['Jens Edlund, Christina TÃ¥nnander, SÃ©bastien Le Maguer, Petra Wagner', 'Assessing the impact of contextual framing on subjective TTS quality', 'edlund24_interspeech', 'evaluation mo situation generalize without varying decontextualized information-rich fiction corroborates'], ['Kexin Wang, Carlos Ishi, Ryoko Hayashi', 'A multimodal analysis of different types of laughter expression in conversational dialogues', 'wang24r_interspeech', 'mirthful boosting gaze body facial softening tenser form predominant nonverbal'], ['Shunsuke Kando, Yusuke Miyao, Jason Naradowsky, Shinnosuke Takamichi', 'Textless Dependency Parsing by Labeled Sequence Prediction', 'kando24_interspeech', 'capturing method tree excels effectiveness acoustic speech cascading feature asr'], ['Zugang Zhao, Jinghong Zhang, Yonghui Liu, Jianbing Liu, Kai Niu, Zhiqiang He', 'Streamlining Speech Enhancement DNNs: an Automated Pruning Method Based on Dependency Graph with Advanced Regularized Loss Strategies', 'zhao24c_interspeech', 'compression unveils high-performing burgeoning layer quest impede enriches size computational'], ['Jingru Lin, Meng Ge, Junyi Ao, Liqun Deng, Haizhou Li', 'SA-WavLM: Speaker-Aware Self-Supervised Pre-training for Mixture Speech', 'lin24g_interspeech', 'pre-trained pipeline speaker shuffling model single-speaker merged limiting individually ssl'], ['Ziyang Ma, Mingjie Chen, Hezhao Zhang, Zhisheng Zheng, Wenxi Chen, Xiquan Li, Jiaxin Ye, Xie Chen, Thomas Hain', 'EmoBox: Multilingual Multi-corpus Speech Emotion Recognition Toolkit and Benchmark', 'ma24b_interspeech', 'ser intra-corpus cross-corpus datasets setting balanced fully making suffered language'], ['Haoyu Li, Baochen Yang, Yu Xi, Linfeng Yu, Tian Tan, Hao Li, Kai Yu', 'Text-aware Speech Separation for Multi-talker Keyword Spotting', 'li24r_interspeech', 'kw clue mixed permutation greatly keyword-specific determinization noisy cocktail front-ends'], ['Jaesong Lee, Soyoon Kim, Hanbyul Kim, Joon Son Chung', 'Lightweight Audio Segmentation for Long-form Speech Translation', 'lee24h_interspeech', 'model quality consume overall segment partitioned pre-training system exists self-supervised'], ['Martin Lebourdais, ThÃ©o Mariotte, Antonio AlmudÃ©var, Marie Tahon, Alfonso Ortega', 'Explainable by-design Audio Segmentation through Non-Negative Matrix Factorization and Probing', 'lebourdais24_interspeech', 'interpretable good representation explanation latent forensics modularity informativeness property compactness'], ['Nan Zhou, Youhai Jiang, Jialin Tan, Chongmin Qi', 'PLDNet: PLD-Guided Lightweight Deep Network Boosted by Efï¬cient Attention for Handheld Dual-Microphone Speech Enhancement', 'zhou24d_interspeech', 'u-net mobile low-complexity guidance phone algorithm pre-process top-performing era gated'], ['Martina Valente, Fabio Brugnara, Giovanni Morrone, Enrico Zovato, Leonardo Badino', 'Exploring Spoken Language Identification Strategies for Automatic Transcription of Multilingual Broadcast and Institutional Speech', 'valente24_interspeech', 'diarization sli monolingual reduction relative wer lower change negatively observing'], ['Kenichi Fujita, Takanori Ashihara, Marc Delcroix, Yusuke Ijima', 'Lightweight Zero-shot Text-to-Speech with Mixture of Adapters', 'fujita24b_interspeech', 'tt method speaker module reproducing adapter non-autoregressive characteristic fidelity daily'], ['Junzhe Liu, Jianwei Yu, Xie Chen', 'Improved Factorized Neural Transducer Model For Text-only Domain Adaptation', 'liu24e_interspeech', 'ifnt fnt wer datasets cer out-of-domain relative compared vocabulary doubt'], ['Jakub Hoscilowicz, Adam Wiacek, Jan Chojnacki, Adam Cieslak, Leszek Michon, Artur Janicki', 'Non-Linear Inference Time Intervention: Improving LLM Truthfulness', 'hoscilowicz24_interspeech', 'iti truthful multiple-choice probing pointing let manifest forest relative truth'], ['Benjamin Elie, Juraj Simko, Alice Turk', 'A data-driven model of acoustic speech intelligibility for optimization-based models of speech production', 'elie24_interspeech', 'hyper-articulation articulatory least bilstm-based effort hypo lindblom phoneme balancing conflicting'], ['Jinghong Zhang, Zugang Zhao, Yonghui Liu, Jianbing Liu, Zhiqiang He, Kai Niu', 'TD-PLC: A Semantic-Aware Speech Encoding for Improved Packet Loss Concealment', 'zhang24g_interspeech', 'plc facilitating integrates transmission audio semantic scenario integrity prolonged concurrently'], ['Antonio AlmudÃ©var, ThÃ©o Mariotte, Alfonso Ortega, Marie Tahon, Luis Vicente, Antonio Miguel, Eduardo Lleida', 'Predefined Prototypes for Intra-Class Separation and Disentanglement', 'almudevar24_interspeech', 'embeddings explainable advantage class inter-class disentangling different separability prototypical simplify'], ['Tina Raissi, Christoph LÃ¼scher, Simon Berger, Ralf SchlÃ¼ter, Hermann Ney', 'Investigating the Effect of Label Topology and Training Criterion on ASR Performance and Alignment Quality', 'raissi24_interspeech', 'comparison hmm dis factored monotonic first-order strictly division classic modular'], ['Kira Tulchynska, Sylvanus Job, Alena Witzlack-Makarevich, Margaret Zellers', 'Prosodic marking of syntactic boundaries in Khoekhoe', 'tulchynska24_interspeech', 'clause-final auxiliary clause position lengthening candidate intonation sov naq following'], ['Premanand Nayak, Kamini Sabu, M. Ali Basha Shaik', 'Multi-mic Echo Cancellation Coalesced with Beamforming for Real World Adverse Acoustic Conditions', 'nayak24_interspeech', 'aec mmaec deep beamformer ser erle psd introduce far-end steering'], ['Martina Di Bratto, Maria Di Maro, Antonio Origlia', 'On the Use of Plausible Arguments in Explainable Conversational AI', 'dibratto24_interspeech', 'recommendation usability concerning delf cross-disciplinary argumentative dialogue believable system interaction'], ['Yaoyao Yue, Michael Proctor, Luping Zhou, Rijul Gupta, Tharinda Piyadasa, Amelia Gully, Kirrie Ballard, Craig Jin', 'Towards Speech Classification from Acoustic and Vocal Tract data in Real-time MRI', 'yue24_interspeech', 'multimodal rtmri unimodal transformer audio phonemic stream model articulatory combine'], ['Thanapat Trachu, Chawan Piansaddhayanon, Ekapol Chuangsuwanich', 'Thunder : Unified Regression-Diffusion Speech Enhancement with a Single Reverse Step using Brownian Bridge', 'trachu24_interspeech', 'diffusion model mode regression score-based necessitate regression-based initializing diffusion-based instability'], ['Rohit Paturi, Xiang Li, Sundararajan Srinivasan', 'AG-LSEC: Audio Grounded Lexical Speaker Error Correction', 'paturi24_interspeech', 'lsec wder audio-based diarization pipeline asr system beat callhome relative'], ['Sheng-Chieh Chiu, Chia-Hua Wu, Jih-Kang Hsieh, Yu Tsao, Hsin-Min Wang', 'Learnable Layer Selection and Model Fusion for Speech Self-Supervised Learning Models', 'chiu24_interspeech', 'gumbel ssl dimension-wise fusing superb interleaved promise enhances sum concatenation'], ['Yicong Jiang, Tianzi Wang, Xurong Xie, Juan Liu, Wei Sun, Nan Yan, Hui Chen, Lan Wang, Xunying Liu, Feng Tian', 'Perceiver-Prompt: Flexible Speaker Adaptation in Whisper for Chinese Disordered Speech Recognition', 'jiang24b_interspeech', 'dysarthric afflicted non-dysarthric lora profound stemming perceiver fixed-length variable-length dissimilarity'], ['Premanand Nayak, M. Ali Basha Shaik', 'Elucidating Clock-drift Using Real-world Audios In Wireless Mode For Time-offset Insensitive End-to-End Asynchronous Acoustic Echo Cancellation', 'nayak24b_interspeech', 'non-linear device delineate clock cancellers revisit conventional playback causing neural'], ['Hao Tan, Xiaochen Liu, Huan Zhang, Junjian Zhang, Yaguan Qian, Zhaoquan Gu', 'DualPure: An Efficient Adversarial Purification Method for Speech Command Recognition', 'tan24_interspeech', 'purify malicious defense perturbation attack frequency unconditional disrupt white-box black-box'], ['Robert Flynn, Anton Ragni', 'Self-Train Before You Transcribe', 'flynn24_interspeech', 'self-training adaptation domain teacher student gain test-time training noisy utilises'], ['Bulat Khaertdinov, Pedro Jeruis, Annanda Sousa, Enrique Hortal', 'Exploring Self-Supervised Multi-view Contrastive Learning for Speech Emotion Recognition with Limited Annotations', 'khaertdinov24_interspeech', 'ser ssl unprecedented reaching performance costly unweighted advancement paralinguistic pre-training'], ['Chengxu Yang, Lin Zheng, Sanli Tian, Gaofeng Cheng, Sujie Xiao, Ta Li', 'Contextual Biasing with Confidence-based Homophone Detector for Mandarin End-to-End Speech Recognition', 'yang24j_interspeech', 'fusion shallow phrase method infrequently deep asr aishell- incorrectly relative'], ['Robert Flynn, Anton Ragni', 'How Much Context Does My Attention-Based ASR System Need?', 'flynn24b_interspeech', 'second long-format length tedlium uncommon acoustic podcasts positional zero-shot width'], ['Sophie Fagniart, Brigitte Charlier, VÃ©ronique Delvaux, Bernard Harmegnies, Anne Huberlant, Myriam Piccaluga, Kathy Huet', 'Production of fricative consonants in French-speaking children with cochlear implants and typical hearing: acoustic and phonological analyses.', 'fagniart24_interspeech', 'group stopping lower percentage higher amplitude correct mid-frequency chronological value'], ['Ming Gao, Hang Chen, Jun Du, Xin Xu, Hongxiao Guo, Hui Bu, Jianxing Yang, Ming Li, Chin-Hui Lee', 'Enhancing Voice Wake-Up for Dysarthria: Mandarin Dysarthria Speech Corpus Release and Customized System Design', 'gao24c_interspeech', 'mdsc wws dysarthric home individual intelligibility effortless exceptional encompasses challenge'], ['Jeremy Chang, Kuan-Yu Chen, Chung-Hsien Wu', 'Applying Reinforcement Learning and Multi-Generators for Stage Transition in an Emotional Support Dialogue System', 'chang24_interspeech', 'rouge-l empathetic distress bleu skill user experiencing response grown coping'], ['Bingsong Bai, Fengping Wang, Yingming Gao, Ya Li', 'SPA-SVC: Self-supervised Pitch Augmentation for Singing Voice Conversion', 'bai24_interspeech', 'svc cross-domain scenario model innovatively ssim posing diffusion-based disparity hoarseness'], ['Song Li, Yongbin You, Xuezhi Wang, Zhengkun Tian, Ke Ding, Guanglu Wan', 'MSR-86K: An Evolving, Multilingual Corpus with 86,300 Hours of Transcribed Audio for Speech Recognition Research', 'li24s_interspeech', 'asr whisper publicly impeded gateway chatgpt huggingface garnered immense evidenced'], ['Zheshu Song, Jianheng Zhuo, Yifan Yang, Ziyang Ma, Shixiong Zhang, Xie Chen', 'LoRA-Whisper: Parameter-Efficient and Extensible Multilingual ASR', 'song24_interspeech', 'language lora interference persist witnessed mitigating emergence degrading performance incorporation'], ['Na Hu, Hugo Schnack, Amalia Arvaniti', 'Automatic pitch accent classification through image classification', 'hu24b_interspeech', 'classifying showcasing effectiveness feature pixel posed feature-based type labelling yielded'], ['Wei-lin Xie, Yu-Xuan Xi, Yan Song, Jian-tao Zhang, Hao-yu Song, Ian McLoughlin', 'DB-PMAE: Dual-Branch Prototypical Masked AutoEncoder with locality for domain robust speaker verification', 'xie24b_interspeech', 'sid pretrained cnceleb similarity siamese finetuned finetuning frontend framework remarkably'], ['Dan Oneata, Herman Kamper', 'Translating speech with just images', 'oneata24_interspeech', 'translation caption low-resource audio image yoruba captioning regime albeit grounded'], ['Per E Kummervold, Javier de la Rosa, Freddy Wetjen, Rolv-Arild Braaten, Per Erik Solberg', 'Whispering in Norwegian: Navigating Orthographic and Dialectic Challenges', 'kummervold24_interspeech', 'openai whisper dataset large-v fleurs summarise weakly translating converting tailored'], ['David Ortiz-Perez, Jose Garcia-Rodriguez, David TomÃ¡s', 'Cognitive Insights Across Languages: Enhancing Multimodal Interview Analysis', 'ortizperez24_interspeech', 'decline taukadial initiating anomalous in-depth audio mild transcribe differentiate comprises'], ['ThÃ©o Mariotte, Anthony Larcher, Silvio MontrÃ©sor, Jean-Hugh Thomas', 'ASoBO: Attentive Beamformer Selection for Distant Speaker Diarization in Meetings', 'mariotte24_interspeech', 'osd vad spatial filter steer speech-processing explainability multi-microphone segment convincing'], ['Rong Gong, Hongfei Xue, Lezhi Wang, Xin Xu, Qisheng Li, Lei Xie, Hui Bu, Shaomei Wu, Jiaming Zhou, Yong Qin, Binbin Zhang, Jun Du, Jia Bin, Ming Li', 'AS-70: A Mandarin stuttered speech dataset for automatic speech recognition and stuttering event detection', 'gong24_interspeech', 'asr inclusivity diminishes human-level verbatim sed encompassing task speech-related stand'], ['Sumit Ranjan, Rupayan Chakraborty, Sunil Kumar Kopparapu', 'Reinforcement Learning based Data Augmentation for Noise Robust Speech Emotion Recognition', 'ranjan24_interspeech', 'ser technique building empathetic scenario picking machine validating cross-corpus reward'], ['Bilal Rahou, HervÃ© Bredin', 'Multi-latency look-ahead for streaming speaker segmentation', 'rahou24_interspeech', 'latency frame-wise detection inference prism bare contribution computational causal overlapped'], ['Hiroki Kanagawa, Yusuke Ijima', 'Knowledge Distillation from Self-Supervised Representation Learning Model with Discrete Speech Units for Any-to-Any Streaming Voice Conversion', 'kanagawa24b_interspeech', 'ssl content teacher offline prosody operation student encoder inferencing vcs'], ['Yuchen Hu, Chen Chen, Ruizhe Li, Qiushi Zhu, Eng Siong Chng', 'Noise-aware Speech Enhancement using Diffusion Probabilistic Model', 'hu24c_interspeech', 'nase noise reverse guide unseen plug-and-play surge mainstream attracted specificity'], ['Jinming Chen, Jingyi Fang, Yuanzhong Zheng, Yaoxuan Wang, Haojun Fei', 'Qifusion-Net: Layer-adapted Stream/Non-stream Model for End-to-End Multi-Accent Speech Recognition', 'chen24n_interspeech', 'laf fusion accent auto facilitating multi chunk streaming cer fine-grained'], ['Tianci Wu, Shulin He, Jiahui Pan, Haifeng Huang, Zhijian Mo, Xueliang Zhang', 'Unified Audio Visual Cues for Target Speaker Extraction', 'wu24h_interspeech', 'lip fuse distinct network divide-and-conquer movement capitalizing attention tse cue'], ['Hui Wang, Shiwan Zhao, Jiaming Zhou, Xiguang Zheng, Haoqin Sun, Xuechen Wang, Yong Qin', 'Uncertainty-Aware Mean Opinion Score Prediction', 'wang24s_interspeech', 'mo uncertainty diverse system practical epistemic heteroscedastic hindering real monte'], ['Marcely Zanon Boito, Vivek Iyer, Nikolaos Lagos, Laurent Besacier, Ioan Calapodescu', 'mHuBERT-147: A Compact Multilingual HuBERT Model', 'zanonboito24_interspeech', 'params hour larger ml-superb up-sampling leaderboards mm competitiveness massively unprecedented'], ['Seung-bin Kim, Chan-yeong Lim, Jungwoo Heo, Ju-ho Kim, Hyun-seo Shin, Kyo-Won Koo, Ha-Jin Yu', 'MR-RawNet: Speaker verification system with multiple temporal resolutions for variable duration utterances using raw waveforms', 'kim24j_interspeech', 'multi-resolution waveform-based robustness persistent adjusts obstacle optimally utilization ensuring insufficient'], ['Dejan Porjazovski, Anssi Moisio, Mikko Kurimo', 'Out-of-distribution generalisation in spoken language understanding', 'porjazovski24_interspeech', 'ood slu split slurp modified data emphasising technique unexpectedly dataset'], ['Juan M. MartÃ­n-DoÃ±as, Aitor Ãlvarez, Eros Rosello, Angel M. Gomez, Antonio M. Peinado', 'Exploring Self-supervised Embeddings and Synthetic Data Augmentation for Robust Audio Deepfake Detection', 'martindonas24_interspeech', 'classifier downstream upstream revisit complemented anti-spoofing feed augmenting foundation specialized'], ['Kou Tanaka, Hirokazu Kameoka, Takuhiro Kaneko, Yuto Kondo', 'PRVAE-VC2: Non-Parallel Voice Conversion by Distillation of Speech Representations', 'tanaka24_interspeech', 'streamable hubert converted gap hidden-unit persists webpage posing many-to-many compromised'], ['MarkÃ©ta ÅezÃ¡ÄkovÃ¡, Daniel Tihelka, JindÅich MatouÅ¡ek', 'Homograph Disambiguation with Text-to-Text Transfer Transformer', 'rezackova24_interspeech', 'single-model wikipedia grapheme-to-phoneme fine-tuned model published proved outperformed powerful online'], ['SÃ©verine Guillaume, Maxime Fily, Alexis Michaud, Guillaume Wisniewski', 'Gender and Language Identification in Multilingual Models of Speech: Exploring the Genericity and Robustness of Speech Representations', 'guillaume24_interspeech', 'xls-r unispeech snippet distill informational audio away irrelevant refined conveyed'], ['Beomseok Lee, Ioan Calapodescu, Marco Gaido, Matteo Negri, Laurent Besacier', 'Speech-MASSIVE: A Multilingual Speech Dataset for SLU and Beyond', 'lee24i_interspeech', 'massive language datasets inherits slot-filling massively few-shot versatile benchmarking task'], ['Longbiao Cheng, Ashutosh Pandey, Buye Xu, Tobi Delbruck, Shih-Chii Liu', 'Dynamic Gated Recurrent Neural Network for Compute-efficient Speech Enhancement', 'cheng24_interspeech', 'rnn gru gate select step model resource-constrained rnn-based dns neuron'], ['FÃ©lix Saget, Meysam Shamsi, Marie Tahon', 'Lifelong Learning MOS Prediction for Synthetic Speech Quality Evaluation', 'saget24_interspeech', 'predictor mode bvcc chronological long-standing breakthrough cross-corpus synthesis reproducible blizzard'], ['Mark Huckvale, Gaston Hilkhuysen', 'Evaluating a 3-factor listener model for prediction of speech intelligibility to hearing-impaired listeners', 'huckvale24_interspeech', 'pure-tone impaired hearing factor sensitivity threshold listener-dependent audiogram held-out evaluate'], ['SÃ©verin Baroudi, Thomas Pellegrini, HervÃ© Bredin', 'Specializing Self-Supervised Speech Representations for Speaker Segmentation', 'baroudi24_interspeech', 'diarization pretraining wavlm single-speaker pretrained multi-speaker conversational specialize pretext pre-segmented'], ['Xun Gong, Anqi Lv, Zhiming Wang, Yanmin Qian', 'Contextual Biasing Speech Recognition in Speech-enhanced Large Language Model', 'gong24b_interspeech', 'speechllm bias wer persists hallucination declined test-clean word reduction relative'], ['Yangze Li, Xiong Wang, Songjun Cao, Yike Zhang, Long Ma, Lei Xie', 'A Transcription Prompt-based Efficient Audio Large Language Model for Robust Speech Recognition', 'li24t_interspeech', 'repetition decoding llm k-hour nar tokenizer illusion fundamentally non-autoregressive cer'], ['Cheng Gong, Erica Cooper, Xin Wang, Chunyu Qiang, Mengzhe Geng, Dan Wells, Longbiao Wang, Jianwu Dang, Marc Tessier, Aidan Pine, Korin Richmond, Junichi Yamagishi', 'An Initial Investigation of Language Adaptation for TTS Systems under Low-resource Scenarios', 'gong24c_interspeech', 'fine-tuning multilingual similarity ssl-based massively adaptability data target surprisingly audio-only'], ['Lingwei Meng, Jiawen Kang, Yuejiao Wang, Zengrui Jin, Xixin Wu, Xunying Liu, Helen Meng', 'Empowering Whisper as a Joint Multi-Talker and Target-Talker Speech Recognition System', 'meng24c_interspeech', 'talker task embedding librispeechmix librimix empower plug freeze pioneering separator'], ['Takuto Igarashi, Yuki Saito, Kentaro Seki, Shinnosuke Takamichi, Ryuichi Yamamoto, Kentaro Tachibana, Hiroshi Saruwatari', 'Noise-Robust Voice Conversion by Conditional Denoising Training Using Latent Variables of Recording Quality and Environment', 'igarashi24_interspeech', 'speech converted source noisy-to-clean utterance-wise conventional frame-wise noise scene model'], ['Zuoliang Li, Wu Guo, Bin Gu, Shengyu Peng, Jie Zhang', 'Contrastive Learning and Inter-Speaker Distribution Alignment Based Unsupervised Domain Adaptation for Robust Speaker Verification', 'li24u_interspeech', 'uda source target source-domain target-domain method cn-celeb momentum compactness mitigating'], ['Kubilay Can Demir, BelÃ©n Lojo RodrÃ­guez, Tobias Weise, Andreas Maier, Seung Hee Yang', 'Towards Intelligent Speech Assistants in Operating Rooms: A Multimodal Model for Surgical Workflow Analysis', 'demir24_interspeech', 'phase operation mono-modal merges seamlessly multi-stage prerequisite frame-wise -score gated'], ['Dong-Hyun Kim, Joon-Hyuk Chang', 'Mitigating Overfitting in Structured Pruning of ASR Models with Gradient-Guided Parameter Regularization', 'kim24k_interspeech', 'availability shift model exacerbated confront limited generality regularize catastrophic emerges'], ['Oliver SchrÃ¼fer, Manuel Milling, Felix Burkhardt, Florian Eyben, BjÃ¶rn Schuller', 'Are you sure? Analysing Uncertainty Quantification Approaches for Real-world Speech Emotion Recognition', 'schrufer24_interspeech', 'ser faulty ood prediction ambiguity reliable out-of-distribution documented many indication'], ['Katharina Anderer, Andreas Reich, Matthias WÃ¶lfel', 'MaViLS, a Benchmark Dataset for Video-to-Slide Alignment, Assessing Baseline Accuracy with a Multimodal Alignment Algorithm Leveraging Speech, OCR, and Visual Features', 'anderer24_interspeech', 'slide lecture highlight matching image video sift underscoring challenge optical'], ['Jinlong Xue, Yayue Deng, Yingming Gao, Ya Li', 'Retrieval Augmented Generation in Prompt-based Text-to-Speech Synthesis with Context-Aware Contrastive Language-Audio Pretraining', 'xue24b_interspeech', 'rag prompt llm tt speech style-related in-context akin clone model'], ['GÃ¡bor Gosztolya, LÃ¡szlÃ³ TÃ³th', "Combining Acoustic Feature Sets for Detecting Mild Cognitive Impairment in the Interspeech'24 TAUKADIAL Challenge", 'gosztolya24_interspeech', 'mci task cross-validation machine workflow functionals custom learning mmse rmse'], ['Zhiyuan Tang, Dong Wang, Shen Huang, Shidong Shang', 'Pinyin Regularization in Error Correction for Chinese Speech Recognition with Large Language Models', 'tang24_interspeech', 'llm dataset error-correcting paradise hypothesis asr website specialized straightforward enhances'], ['Maryam Naderi, Enno Hermann, Alexandre Nanchen, Sevada Hovsepyan, Mathew Magimai.-Doss', 'Towards interfacing large language models with ASR systems using confidence measures and prompting', 'naderi24_interspeech', 'llm transcript confidence-based post-hoc grow rescoring correction n-best beyond avoid'], ['Delphine Charuau, Andrea Briglia, Erika Godde, GÃ©rard Bailly', 'Training speech-breathing coordination in computer-assisted reading', 'charuau24_interspeech', 'highlighting respiratory untrained assistance aloud repeated text principle trained karaoke'], ['Koichi Miyazaki, Yoshiki Masuyama, Masato Murata', 'Exploring the Capability of Mamba in Speech Applications', 'miyazaki24_interspeech', 'transformer-based ssms model e-branchformer evaluation long-form facto well-designed asr summarization'], ['GÃ¡bor Gosztolya, Mercedes VetrÃ¡b, Veronika Svindt, Judit BÃ³na, IldikÃ³ Hoffmann', 'Wav2vec 2.0 Embeddings Are No Swiss Army Knife -- A Case Study for Multiple Sclerosis', 'gosztolya24b_interspeech', 'functionals surprisingly feature self-supervised classification mediocre model unannotated ecapa-tdnn audio'], ['Stefan Kalabakov, Monica Gonzalez-Machorro, Florian Eyben, BjÃ¶rn W. Schuller, Bert Arnrich', 'A Comparative Analysis of Federated Learning for Speech-Based Cognitive Decline Detection', 'kalabakov24_interspeech', 'healthy centralised solution hampered collectively discern alzheimer timely state healthcare'], ['Tim Polzehl, Tim Herzig, Friedrich Wicke, Kathleen Wermke, Razieh Khamsehashari, Michiko Dahlem, Sebastian MÃ¶ller', 'Towards Classifying Mother Tongue from Infant Cries - Findings Substantiating Prenatal Learning Theory', 'polzehl24_interspeech', 'panns neonate model network adhere substantiate confounding cry thereof held-out'], ['JÃ©rÃ©my Giroud, Jessica Lei, Kirsty Phillips, Matthew H. Davis', 'Behavioral evidence for higher speech rate convergence following natural than artificial time altered speech', 'giroud24_interspeech', 'interaction artificially crucial ai-powered phenomenon multiplying proliferation amplified inform everyday'], ['Andrei Andrusenko, Aleksandr Laptev, Vladimir Bataev, Vitaly Lavrukhin, Boris Ginsburg', 'Fast Context-Biasing for CTC and Transducer ASR models with CTC-based Word Spotter', 'andrusenko24_interspeech', 'recognition candidate log-probabilities pressing nemo method nvidia contextualized reuse model'], ['Huihang Zhong, Yanlu Xie, ZiJin Yao', 'Leveraging Large Language Models to Refine Automatic Feedback Generation at Articulatory Level in Computer Aided Pronunciation Training', 'zhong24b_interspeech', 'gpt- llm helpfulness invite potential effectiveness generated comprehensibility computer-aided mispronunciation'], ['Qiuming Zhao, Guangzhi Sun, Chao Zhang, Mingxing Xu, Thomas Fang Zheng', 'SAML: Speaker Adaptive Mixture of LoRA Experts for End-to-End ASR', 'zhao24d_interspeech', 'moe quantised model mixture-of-experts test-time adaptation personalised ted-lium low-rank resource-constrained'], ['Siyang Wang, Ãva SzÃ©kely, Joakim Gustafson', 'Contextual Interactive Evaluation of TTS Models in Dialogue Systems', 'wang24t_interspeech', 'mo shortcoming setup context mean-opinion-score custom-built paramount system questioned evaluate'], ['GÃ¡bor Gosztolya, Veronika Svindt, Judit BÃ³na, IldikÃ³ Hoffmann', 'Automatic Longitudinal Investigation of Multiple Sclerosis Subjects', 'gosztolya24c_interspeech', 'year healthy third category nervous control chronic change workflow classification'], ['Imen Ben-Amor, Jean-Francois Bonastre, Salima Mdhaffar', 'Extraction of interpretable and shared speaker-specific speech attributes through binary auto-encoder', 'benamor24_interspeech', 'explainability proposal attribute embeddings eer lack binarization attribute-based restructuring posing'], ['Anisia Popescu, Lori Lamel, Ioana Vasilescu, Laurence Devillers', 'Automatic Speech Recognition with parallel L1 and L2 acoustic phone models to evaluate /l/ allophony in L2 English speech production', 'popescu24_interspeech', 'french lateral staple darkness dark clearer asr documented classic consuming'], ['Zizhen Lin, Xiaoting Chen, Junyu Wang', 'MUSE: Flexible Voiceprint Receptive Fields and Multi-Path Fusion Enhanced Taylor Transformer for U-Net-based Speech Enhancement', 'lin24h_interspeech', 'met u-net lightweight spatial csa deformable voicebank channel attention mere'], ['Yin-Long Liu, Rui Feng, Jia-Hong Yuan, Zhen-Hua Ling', "Clever Hans Effect Found in Automatic Detection of Alzheimer's Disease through Speech", 'liu24f_interspeech', 'pitt recording bias datasets preprocessed uncover audio necessity emphasize accessible'], ['Biswajit Karan, Joshua Jansen van VÃ¼ren, Febe de Wet, Thomas Niesler', 'A Transformer-Based Voice Activity Detector', 'karan24_interspeech', 'vad architecture multilingual benchmark end-to-end manually-segmented widens enterprise dataset off-the-shelf'], ['Tasnima Sadekova, Mikhail Kudinov, Vadim Popov, Assel Yermekova, Artem Khrapov', 'PitchFlow: adding pitch control to a Flow-matching based TTS model', 'sadekova24_interspeech', 'guidance generation recent diffusion high timbre quality denoising stability fine-grained'], ['Tonmoy Rajkhowa, Amartya Roy Chowdhury, Sankalp Nagaonkar, Achyut Mani Tripathi, Mahadeva Prasanna', 'TM-PATHVQA: 90000+ Textless Multilingual Questions for Medical Visual Question Answering', 'rajkhowa24_interspeech', 'vqa pathological speech-based dataset performing image scenario diagnostics system interaction'], ['Erfan A. Shams, Iona Gessinger, Patrick Cormac English, Julie Carson-Berndsen', 'Are Articulatory Feature Overlaps Shrouded in Speech Embeddings?', 'shams24_interspeech', 'probe assimilation transformer activation articulation explanatory probing spreading ipa phonetic'], ['Sevada Hovsepyan, Mathew Magimai.-Doss', "Neurocomputational model of speech recognition for pathological speech detection: a case study on Parkinson's disease speech detection", 'hovsepyan24_interspeech', 'healthy accumulates computational two-level syllable uncover auc modest merit plausible'], ['Anurag Chowdhury, Abhinav Misra, Mark C. Fuhs, Monika Woszczyna', 'Investigating Confidence Estimation Measures for Speaker Diarization', 'chowdhury24_interspeech', 'score system downstream identity error derived propagate speaker-adapted adversely segment'], ['Mengjie Qian, Siyuan Tang, Rao Ma, Kate M. Knill, Mark J.F. Gales', "Learn and Don't Forget: Adding a New Language to ASR Foundation Models", 'qian24_interspeech', 'ewc tuning soft fine-tuning code parameter capability performance consolidation set'], ['Benjamin van Niekerk, Julian ZaÃ¯di, Marc-AndrÃ© Carbonneau, Herman Kamper', 'Spoken-Term Discovery using Discrete Speech Units', 'vanniekerk24_interspeech', 'pattern find sub-sequences longstanding discretization zerospeech zero-resource revisit challenge discovering'], ['Mukhtar Mohamed, Oli Danyi Liu, Hao Tang, Sharon Goldwater', 'Orthogonality and isotropy of speaker and phonetic information in self-supervised speech representations', 'mohamed24_interspeech', 'probing correlate centroid property downstream degree phone nuanced space spanned'], ['Jinlong Xue, Yayue Deng, Yicheng Han, Yingming Gao, Ya Li', 'Improving Audio Codec-based Zero-Shot Text-to-Speech Synthesis with Multi-Modal Context and Large Language Model', 'xue24c_interspeech', 'tt llm prompt leverage token adapt scenario audiobook -second personalized'], ['Alexis Plaquet, HervÃ© Bredin', 'On the calibration of powerset speaker diarization models', 'plaquet24_interspeech', 'low-confidence region confidence formulation random explore multiclass validating model unannotated'], ['Kishan Gupta, Nicola Pia, Srikanth Korse, Andreas Brendel, Guillaume Fuchs, Markus Multrus', 'On Improving Error Resilience of Neural End-to-End Speech Coders', 'gupta24c_interspeech', 'packet fec plc bitrates loss low resilient robustness like concealment'], ['Ryo Masumura, Naoki Makishima, Tomohiro Tanaka, Mana Ihori, Naotaka Kawata, Shota Orihashi, Kazutoshi Shinoda, Taiga Yamane, Saki Mizuno, Keita Suzuki, Satoshi Suzuki, Nobukatsu Hojo, Takafumi Moriya, Atsushi Ando', 'Unified Multi-Talker ASR with and without Target-speaker Enrollment', 'masumura24_interspeech', 'mt-asr modeling process form independent bridging enrolled mutually trained autoregressive'], ['Guinan Li, Jiajun Deng, Youjun Chen, Mengzhe Geng, Shujie Hu, Zhe Li, Zengrui Jin, Tianzi Wang, Xurong Xie, Helen Meng, Xunying Liu', 'Joint Speaker Features Learning for Audio-visual Multichannel Speech Separation and Recognition', 'li24v_interspeech', 'wavlm -ted feature purpose-built lr best-performing ecapa-tdnn tightly dev zero-shot'], ['Zexu Pan, Gordon Wichern, FranÃ§ois G. Germain, Kohei Saijo, Jonathan Le Roux', 'PARIS: Pseudo-AutoRegressIve Siamese Training for Online Speech Separation', 'pan24_interspeech', 'streaming autoregressive offline step training-inference empowering network si-snr forcing regime'], ['Jizhen Li, Xinmeng Xu, Weiping Tu, Yuhong Yang, Rong Zhu', 'Improving Speech Enhancement by Integrating Inter-Channel and Band Features with Dual-branch Conformer', 'li24w_interspeech', 'channel t-f aware correlation time-frequency information dns-challenge relation recent different'], ['Vasileios Moschopoulos, Thanasis Kotsiopoulos, Pablo Peso Parada, Konstantinos Nikiforidis, Alexandros Stergiadis, Gerasimos Papakostas, Md Asif Jalal, Jisi Zhang, Anastasios Drosou, Karthikeyan Saravanan', 'Exploring compressibility of transformer based text-to-music (TTM) models', 'moschopoulos24_interspeech', 'params compression generative fad infeasible desktop state-of-the distillation server applicability'], ['Thomas Muller, Stephane Ragot, Laetitia Gros, Pierrick Philippe, Pascal Scalart', 'Speech quality evaluation of neural audio codecs', 'muller24c_interspeech', 'codec lyra encodec dmos opus lpcnet bitrates targeting technological complement'], ['Yi-Cheng Lin, Haibin Wu, Huang-Cheng Chou, Chi-Chun Lee, Hung-yi Lee', 'Emo-bias: A Large Scale Evaluation of Social Bias on Speech Emotion Recognition', 'lin24i_interspeech', 'ser gender upstream model ssl toward exhibit cutting-edge ssl-based aiding'], ['Judith Dineley, Ewan Carr, Lauren L. White, Catriona Lucas, Zahia Rahman, Tian Pan, Faith Matcham, Johnny Downs, Richard J. Dobson, Thomas F. Quatieri, Nicholas Cummins', 'Variability of speech timing features across repeated recordings: a comparison of open-source extraction techniques', 'dineley24_interspeech', 'extracted clinical via replication hinder variation within-speaker susceptible week symptom'], ['Mahdi Amiri, Ina Kodrasi', 'Adversarial Robustness Analysis in Automatic Pathological Speech Detection Approaches', 'amiri24_interspeech', 'dl-based perturbation imperceptibility imperceptible ineffective healthcare vulnerability unexplored attend projected'], ['Chun-Yi Kuan, Wei-Ping Huang, Hung-yi Lee', 'Understanding Sounds, Missing the Questions: The Challenge of Object Hallucination in Large Audio-Language Models', 'kuan24_interspeech', 'lalms discriminative audio enhance overlooking captioning struggle inadequate weakness clip'], ['Yiyuan Yang, Niki Trigoni, Andrew Markham', 'Pre-training Feature Guided Diffusion Model for Speech Enhancement', 'yang24k_interspeech', 'efficiency streamline vae clarity optimizes deterministic reverse guidance pretraining utilization'], ['Chung-Wen Wu, Berlin Chen', 'Optimizing Automatic Speech Assessment: W-RankSim Regularization and Hybrid Feature Fusion Strategies', 'wu24i_interspeech', 'asa ordinal vector weighted handcrafted ssl closer showcasing challenge imbalanced'], ['Livia Qian, Gabriel Skantze', 'Joint Learning of Context and Feedback Embeddings in Spoken Dialogue', 'qian24b_interspeech', 'response appropriateness ranking conversational short neglecting backchannels function primarily carry'], ['NicolÃ² Loddo, Francisca Pessanha, Almila Akdag', 'What if HAL breathed? Enhancing Empathy in Human-AI Interactions with Breathing Speech Synthesis', 'loddo24_interspeech', 'agent novelty diverges towards synthesized empathetic methodologically dilemma deepen engagement'], ['Sameer Khurana, Chiori Hori, Antoine Laurent, Gordon Wichern, Jonathan Le Roux', 'ZeroST: Zero-Shot Speech Translation', 'khurana24_interspeech', 'foundation model multilingual mm bypassing synergistic massively speech-text pave connect'], ['Stefano Goria, Roseline Polle, Salvatore Fara, Nicholas Cummins', 'Revealing Confounding Biases: A Novel Benchmarking Approach for Aggregate-Level Performance Metrics in Health Assessments', 'goria24_interspeech', 'model assessment overestimation overestimated exaggerate machine report alzheimer cross-sectional small-scale'], ['Lucas Block Medin, Thomas Pellegrini, Lucile Gelin', "Self-Supervised Models for Phoneme Recognition: Applications in Children's Speech for Reading Learning", 'blockmedin24_interspeech', 'wavlm child base transformer non-english hubert various continue ctc wav'], ['Jules Cauzinille, BenoÃ®t Favre, Ricard Marxer, Dena Clink, Abdul Hamid Ahmad, Arnaud Rey', "Investigating self-supervised speech models' ability to classify animal vocalizations: The case of gibbon's vocal signatures", 'cauzinille24_interspeech', 'ssl probing pre-trained grey bioacoustic primate bird non-human classifier explainability'], ['Maurice Gerczuk, Shahin Amiriparian, Justina Lutz, Wolfgang Strube, Irina Papazova, Alkomiet Hasan, BjÃ¶rn W. Schuller', 'Exploring Gender-Specific Speech Patterns in Automatic Suicide Risk Assessment', 'gerczuk24_interspeech', 'patient modelling female gender-based psychiatric medicine specialised subject emergency hindered'], ['Thomas Rolland, Alberto Abad', 'Introduction To Partial Fine-tuning: A Comprehensive Evaluation Of End-to-end Childrenâs Automatic Speech Recognition Adaptation', 'rolland24_interspeech', 'asr dealing data departing granular overfit limited model challenge advancing'], ['Thomas Rolland, Alberto Abad', 'Shared-Adapters: A Novel Transformer-based Parameter Efficient Transfer Learning Approach For Childrenâs Automatic Speech Recognition', 'rolland24b_interspeech', 'peft parameter-efficient asr fine-tuning pre-trained strike minimising model exceptional challenge'], ['Kentaro Seki, Shinnosuke Takamichi, Norihiro Takamune, Yuki Saito, Kanami Imamura, Hiroshi Saruwatari', 'Spatial Voice Conversion: Voice Conversion Preserving Spatial Information and Non-target Signals', 'seki24_interspeech', 'inherent waveform organize balancing bs stereo ignoring mixing encourage exploration'], ['Nina R. Benway, Jonathan L. Preston, Carol Espy-Wilson', 'Examining Vocal Tract Coordination in Childhood Apraxia of Speech with Acoustic-to-Articulatory Speech Inversion Feature Sets', 'benway24_interspeech', 'disorder auroc genetically neurodevelopmental correlation-based spatiotemporal nested sound -fold replicated'], ['Anna Stein, Kevin Tang', 'Modeling probabilistic reduction across domains with Naive Discriminative Learning', 'stein24_interspeech', 'word context syllable predictability competition cue outcome segment duration local'], ['Alkis Koudounas, Gabriele Ciravegna, Marco Fantini, Erika Crosetti, Giovanni Succo, Tania Cerquitelli, Elena Baralis', 'Voice Disorder Analysis: a Transformer-based Approach', 'koudounas24_interspeech', 'shortage pathology diagnosis data type solution under-explored recording private non-invasive'], ['KiHyun Nam, Hee-Soo Heo, Jee-weon Jung, Joonson Chung', 'Disentangled Representation Learning for Environment-agnostic Speaker Recognition', 'nam24b_interspeech', 'embedding auto-encoder framework extractor code popularly versatility utilises compatibility disentanglement'], ['Tomoki Koriyama', 'VAE-based Phoneme Alignment Using Gradient Annealing and SSL Acoustic Features', 'koriyama24_interspeech', 'vae model -based acoustic-feature mfa ctc-based boundary state-level linguistic widely-used'], ['Iva Ewert, Marvin Borsdorf, Haizhou Li, Tanja Schultz', 'Does the Lombard Effect Matter in Speech Separation? Introducing the Lombard-GRID-2mix Dataset', 'ewert24_interspeech', 'work normal reflexive soundscapes studied style speaking change two-speaker cocktail'], ['Cliodhna Hughes, Guy Brown, Ning Ma, Nicola Dibben', 'Acoustic Effects of Facial Feminisation Surgery on Speech and Singing: A Case Study', 'hughes24_interspeech', 'altered vocal tract people single-case procedure undergoing understudied undergo characteristic'], ['GaÃ«lle LaperriÃ¨re, Sahar Ghannay, Bassam Jabaian, Yannick EstÃ¨ve', 'A dual task learning approach to fine-tune a multilingual semantic speech encoder for Spoken Language Understanding', 'laperriere24_interspeech', 'samu-xlsr slu enrichment specializing loss specialization language-agnostic vastly enrich portability'], ['Jacob Kealey, John R. Hershey, FranÃ§ois Grondin', 'Unsupervised Improved MVDR Beamforming for Sound Enhancement', 'kealey24_interspeech', 'multi-channel separation data supervised isolated channel in-the-wild single distortionless case'], ['Yoshiaki Bando, Tomohiko Nakamura, Shinji Watanabe', 'Neural Blind Source Separation and Diarization for Distant Speech Recognition', 'bando24_interspeech', 'g dsr multichannel supervision mixture method jointly separate weakly-supervised signal-level'], ['Jian Cheng', 'Context-Aware Speech Recognition Using Prompts for Language Learners', 'cheng24b_interspeech', 'gemini whisper spoken asr text context-awareness elicitors wer apps response'], ['Khalid Daoudi, Solange MilhÃ© de Saint Victor, Alexandra Foubert-Samier, Margherita Fabbri, Anne Pavy-Le Traon, Olivier Rascol, Virginie Woisard, Wassilios G. Meissner', "Electroglottography for the assessment of dysphonia in Parkinson's disease and multiple system atrophy", 'daoudi24_interspeech', 'egg early msa-p parkinsonian msa diagnosis disorder stage analysis noninvasive'], ['Arunav Arya, Murtiza Ali, Karan Nathwani', 'Exploiting Wavelet Scattering Transform for an Unsupervised Speaker Diarization in Deep Neural Network Framework', 'arya24_interspeech', 'wst embeddings model speechbrain manner voxconverse segment-wise pyannote customize api'], ['Alexander Barnhill, Elmar Noeth, Andreas Maier, Christian Bergler', 'ANIMAL-CLEAN â A Deep Denoising Toolkit for Animal-Independent Signal Enhancement', 'barnhill24_interspeech', 'bioacoustic animal downstream largely bioacoustics myriad impede non-human existing recording'], ['Adriana Fernandez-Lopez, Honglie Chen, Pingchuan Ma, Lu Yin, Qiao Xiao, Stavros Petridis, Shiwei Liu, Maja Pantic', 'MSRS: Training Multimodal Speech Recognition Models from Scratch with Sparse Mask Optimization', 'fernandezlopez24_interspeech', 'dense vsr avsr regularization gradient stabilizes abbreviated vanishing non-zero foundational'], ['James Tanner, Morgan Sonderegger, Jane Stuart-Smith, Tyler Kendall, Jeff Mielke, Robin Dodsworth, Erik Thomas', 'Exploring the anatomy of articulation rate in spontaneous English speech: relationships between utterance length effects and social factors', 'tanner24_interspeech', 'conditioned across gender age effect modulate leaving broader shown accounted'], ['Lila Kim, CÃ©dric Gendrot', 'Using wav2vec 2.0 for phonetic classification tasks: methodological aspects', 'kim24l_interspeech', 'sequence phoneme longer correlating react speaker vector nasality airflow recovering'], ['Zhaoyu Wang, Haohe Liu, Harry Coppock, BjÃ¶rn Schuller, Mark D. Plumbley', 'Neural Compression Augmentation for Contrastive Audio Representation Learning', 'wang24u_interspeech', 'nca self-supervised music underperform twin lossy audioset pivotal surpass generalisation'], ['Kwanghee Choi, Ankita Pasad, Tomohiko Nakamura, Satoru Fukayama, Karen Livescu, Shinji Watanabe', 'Self-Supervised Speech Representations are More Phonetic than Semantic', 'choi24b_interspeech', 'similarity pair datasets synonym curate corroborates snip property word linguistic'], ['Wiebke Hutiri, Tanvina Patel, Aaron Yi Ding, Odette Scharenborg', 'As Biased as You Measure: Methodological Pitfalls of Bias Evaluations in Speaker Verification Research', 'hutiri24_interspeech', 'base metric choice ratio-based hindering recommend contradictory group across favour'], ['Charles McGhee, Kate Knill, Mark Gales', 'Highly Intelligible Speaker-Independent Articulatory Synthesis', 'mcghee24_interspeech', 'synthesiser inversion deep real simulation-based wer synthetic training acoustic-to-articulatory struggle'], ['Xizi Wei, Stephen McGregor', 'Prompt Tuning for Speech Recognition on Unknown Spoken Name Entities', 'wei24_interspeech', 'entity phrase scenario reflecting named model unheard stratification pertains bot'], ['RÃ©mi Uro, Marie Tahon, David Doukhan, Antoine Laurent, Albert Rilliard', 'Detecting the terminality of speech-turn boundary for spoken interactions in French TV and Radio content', 'uro24_interspeech', 'turn-taking terminal analyzing turn fusion place interrupting non-terminal floor initialization'], ['Liwei Liu, Huihui Wei, Dongya Liu, Zhonghua Fu', 'HarmoNet: Partial DeepFake Detection Network based on Multi-scale HarmoF0 Feature Fusion', 'liu24g_interspeech', 'add region audio track loss post-processor fake locating framework innovative'], ['Nhan Phan, Anna von Zansen, Maria Kautonen, Ekaterina Voskoboinik, Tamas Grosz, Raili Hilden, Mikko Kurimo', 'Automated content assessment and feedback for Finnish L2 learners in a picture description speaking task', 'phan24_interspeech', 'grading asa language explanation low-resource automatic generation solution visual nlg'], ['Mathilde Hutin, Junfei Hu, Liesbeth Degand', 'Uh, um and mh: Are filled pauses prone to conversational converge?', 'hutin24_interspeech', 'speaker-oriented interlocutor frequent yet conversation asymmetrical interaction form participate debate'], ['Iona Gessinger, Bistra Andreeva, Benjamin R. Cowan', 'The Use of Modifiers and f0 in Remote Referential Communication with Human and Computer Partners', 'gessinger24_interspeech', 'competitor ground partner status condition description privileged common information responded'], ['Marvin Borsdorf, Zexu Pan, Haizhou Li, Tanja Schultz', 'wTIMIT2mix: A Cocktail Party Mixtures Database to Study Target Speaker Extraction for Normal and Whispered Speech', 'borsdorf24_interspeech', 'tse mode reference signal work two-speaker closed-set given equipped smart'], ['Louis Bahrman, Mathieu Fontaine, Jonathan Le Roux, GaÃ«l Richard', 'Speech dereverberation constrained on room impulse response characteristics', 'bahrman24_interspeech', 'dereverberated rir regularizing dry signal loss acoustic black-box provision physically'], ['Xiang Li, Vivek Govindan, Rohit Paturi, Sundararajan Srinivasan', 'Speakers Unembedded: Embedding-free Approach to Long-form Neural Diarization', 'li24x_interspeech', 'eend embeddings speaker framework local embedding-based -pass additional mitigates generalizing'], ['Neelesh Samptur, Tanuka Bhattacharjee, Anirudh Chakravarty K, Seena Vengalil, Yamini Belur, Atchayaram Nalini, Prasanta Kumar Ghosh', 'Exploring Syllable Discriminability during Diadochokinetic Task with Increasing Dysarthria Severity for Patients with Amyotrophic Lateral Sclerosis', 'samptur24_interspeech', 'ddk al manual classification decline among automatic healthy cue persist'], ['Benjamin Elie, David Doukhan, RÃ©mi Uro, Lucas Ondel-Yang, Albert Rilliard, Simon Devauchelle', 'Articulatory Configurations across Genders and Periods in French Radio and TV archives', 'elie24b_interspeech', 'maeda frame gender female parameter protrusion diachronic assertion lowered spanning'], ['Lingyun Gao, Cristian Tejedor-Garcia, Helmer Strik, Catia Cucchiarini', 'Reading Miscue Detection in Primary School through Automatic Speech Recognition', 'gao24d_interspeech', 'whisper sota child exercise wav diagnosis vec asr highest dutch'], ['Michaela Watkins, Paul Boersma, Silke Hamann', 'Revisiting Pitch Jumps: F0 Ratio in Seoul Korean', 'watkins24_interspeech', 'octave periodicity vibration algorithm capture vocal-fold fortis downward upward chart'], ['Xuanjun Chen, Haibin Wu, Roger Jang, Hung-yi Lee', 'Singing Voice Graph Modeling for SingFake Detection', 'chen24o_interspeech', 'singer unseen sota model music groundbreaking mert struggled copyright deepfakes'], ['Chin-Yun Yu, GyÃ¶rgy Fazekas', 'Differentiable Time-Varying Linear Prediction in the Context of End-to-End Analysis-by-Synthesis', 'yu24b_interspeech', 'generalise frame-wise vocoder efficient reconstructs time-invariant acceleration barrier source-filter recursive'], ['Xuanjun Chen, Jiawei Du, Haibin Wu, Jyh-Shing Roger Jang, Hung-yi Lee', 'Neural Codec-based Adversarial Sample Detection for Speaker Verification', 'chen24p_interspeech', 'asv codecs sota codec method single-model delivering surpassing re-synthesized defense'], ['Trung Dang, David Aponte, Dung Tran, Kazuhito Koishida', 'LiveSpeech: Low-Latency Zero-shot Text-to-Speech via Autoregressive Modeling of Audio Discrete Codes', 'dang24_interspeech', 'streaming codebook token codebooks codec grouping model-based enabling hard generative'], ['Adaeze Adigwe, Sarenne Wallbridge, Simon King', 'What do people hear? Listenersâ Perception of Conversational Speech', 'adigwe24_interspeech', 'tt explanation preference style underscoring pinpoint prompting synthesise organisation inappropriate'], ['Yifan Peng, Jinchuan Tian, William Chen, Siddhant Arora, Brian Yan, Yui Sudo, Muhammad Shakeel, Kwanghee Choi, Jiatong Shi, Xuankai Chang, Jee-weon Jung, Shinji Watanabe', 'OWSM v3.1: Better and Faster Open Whisper-Style Speech Models based on E-Branchformer', 'peng24b_interspeech', 'openai predecessor emergent toolkits reproducing license biasing zero-shot data inferior'], ['Kazutoshi Shinoda, Nobukatsu Hojo, Saki Mizuno, Keita Suzuki, Satoshi Kobashikawa, Ryo Masumura', 'Learning from Multiple Annotator Biased Labels in Multimodal Conversation', 'shinoda24_interspeech', 'bias minority class majority debiasing label overlook mitigates distribution value'], ['Shabnam Ghaffarzadegan, Luca Bondi, Wei-Chang Lin, Abinaya Kumar, Ho-Hsiang Wu, Hans-Georg Horst, Samarjit Das', 'Sound of Traffic: A Dataset for Acoustic Traffic Identification and Counting', 'ghaffarzadegan24_interspeech', 'vehicle zenodo org record http right-to-left radar passenger coil inductive'], ['Tobias Weise, Philipp Klumpp, Kubilay Can Demir, Paula Andrea PÃ©rez-Toro, Maria Schuster, Elmar Noeth, Bjoern Heismann, Andreas Maier, Seung Hee Yang', 'Speaker- and Text-Independent Estimation of Articulatory Movements and Phoneme Alignments from Speech', 'weise24_interspeech', 'aai inversion phoneme-related pta alignment frame aligner acoustic-to-articulatory task text-dependent'], ['Zakaria Aldeneh, Takuya Higuchi, Jee-weon Jung, Skyler Seto, Tatiana Likhomanenko, Stephen Shum, Ahmed Hussen Abdelaziz, Shinji Watanabe, Barry-John Theobald', 'Can you Remove the Downstream Model for Speaker Recognition with Self-Supervised Speech Features?', 'aldeneh24_interspeech', 'verification simplify ingest filter-banks superb revisit sacrificing filter-bank performance inherently'], ['Donna Erickson, Albert Rilliard, Malin Svensson Lundmark, Adelaide Silva, Leticia Rebollo Couto, Oliver Niebuhr, JoÃ£o Antonio de Moraes', 'Collecting Mandible Movement in Brazilian Portuguese', 'erickson24_interspeech', 'closing quick speaker helmet post-stress prosodic structure sentence synchronization lowering'], ['Saurav Pahuja, Gabriel Ivucic, Pascal Himmelmann, Siqi Cai, Tanja Schultz, Haizhou Li', 'Leveraging Graphic and Convolutional Neural Networks for Auditory Attention Detection with EEG', 'pahuja24_interspeech', 'spatiotemporal selective ensemble spatial st-gcn single-trial prediction locus electroencephalography -second'], ['Seong-Gyun Leem, Daniel Fulford, Jukka-Pekka Onnela, David Gard, Carlos Busso', 'Keep, Delete, or Substitute: Frame Selection Strategy for Noise-Robust Speech Emotion Recognition', 'leem24_interspeech', 'ser noise framework background noisy dropped discarding emotionally suppressing avoiding'], ['Alkis Koudounas, Flavio Giobergia, Eliana Pastor, Elena Baralis', 'A Contrastive Learning Approach to Mitigate Bias in Speech Models', 'koudounas24b_interspeech', 'subgroup internal affected three-level overlooking user-defined adoption fair imbalance representation'], ['Debasmita Bhattacharya, Eleanor Lin, Run Chen, Julia Hirschberg', 'Switching Tongues, Sharing Hearts: Identifying the Relationship between Empathy and Code-switching in Speech', 'bhattacharya24_interspeech', 'csw multilingual motivation empathetic prior prevalence sociolinguistic qualitatively acoustic-prosodic asking'], ['Lucas Goncalves, Donita Robinson, Elizabeth Richerson, Carlos Busso', 'Bridging Emotions Across Languages: Low Rank Adaptation for Multilingual Speech Emotion Recognition', 'goncalves24_interspeech', 'ser lora expression surge envision taiwanese linguistic refining overcoming constantly'], ['Abinay Reddy Naini, Lucas Goncalves, Mary A. Kohler, Donita Robinson, Elizabeth Richerson, Carlos Busso', 'WHiSER: White House Tapes Speech Emotion Recognition Corpus', 'naini24_interspeech', 'ser speech-emotion complex authenticity defense healthcare advancing office offering perfect'], ['Joseph Liu, Mahesh Kumar Nandwana, Janne PylkkÃ¶nen, Hannes Heikinheimo, Morgan McGuire', 'Enhancing Multilingual Voice Toxicity Detection with Speech-Text Alignment', 'liu24h_interspeech', 'semantic classification classifier across general-purpose text framework ablation cross-modal conducting'], ['Sri Harsha Dumpala, Dushyant Sharma, Chandramouli Shama Sastry, Stanislav Kruchinin, James Fosburgh, Patrick A. Naylor', 'XANE: eXplainable Acoustic Neural Embeddings', 'dumpala24_interspeech', 'background detection parameter signal non-intrusive wavlm noise type overlapped method'], ['Spyretta Leivaditi, Tatsunari Matsushima, Matt Coler, Shekhar Nayak, Vass Verkhodanova', 'Fine-Tuning Strategies for Dutch Dysarthric Speech Recognition: Evaluating the Impact of Healthy, Disease-Specific, and Speaker-Specific Data', 'leivaditi24_interspeech', 'ssl third ineffective asr inadequate learning second widespread scarcity sufficiently'], ['Tanel PÃ¤rnamaa, Ando Saabas', 'Personalized Speech Enhancement Without a Separate Speaker Embedding Model', 'parnamaa24_interspeech', 'pse suppression winner teleconferencing icassp audio echo surpasses cancellation representation'], ['Deepanshu Gupta, Javier Latorre', 'Positional Description for Numerical Normalization ', 'gupta24d_interspeech', 'pd arithmetic digit model fatal tokenization mitigates tractable fst challenge'], ['Wangyou Zhang, Robin Scheibler, Kohei Saijo, Samuele Cornell, Chenda Li, Zhaoheng Ni, Jan Pirklbauer, Marvin Sach, Shinji Watanabe, Tim Fingscheidt, Yanmin Qian', 'URGENT Challenge: Universality, Robustness, and Generalizability For Speech Enhancement', 'zhang24h_interspeech', 'sub-tasks metric curated existing unify witnessed dereverberation data fill learning-based'], ['Kohei Saijo, Gordon Wichern, FranÃ§ois G. Germain, Zexu Pan, Jonathan Le Roux', 'Enhanced Reverberation as Supervision for Unsupervised Speech Separation', 'saijo24_interspeech', 'ra mapped channel mixture era separated stable source-channel pseudo-targets loss'], ['ChengHung Hu, Yusuke Yasuda, Tomoki Toda', 'Embedding Learning for Preference-based Speech Quality Assessment', 'hu24d_interspeech', 'mo embeddings loss utterance closer similar preference score t-sne out-domain'], ['Pravin Mote, Berrak Sisman, Carlos Busso', 'Unsupervised Domain Adaptation for Speech Emotion Recognition using K-Nearest Neighbors Voice Conversion', 'mote24_interspeech', 'unlabeled labeled data ser transformed knn sample re-training model ineffective'], ['Catarina Botelho, John MendonÃ§a, Anna Pompili, Tanja Schultz, Alberto Abad, Isabel Trancoso', "Macro-descriptors for Alzheimer's disease detection using large language models", 'botelho24_interspeech', 'llm transcription low-dimension designated surpassing prompting experiment interpretable coherence annotator'], ['Ali N. Salman, Zongyang Du, Shreeram Suresh Chandra, Ä°smail Rasim Ãlgen, Carlos Busso, Berrak Sisman', 'Towards Naturalistic Voice Conversion: NaturalVoices Dataset with an Automatic Processing Pipeline', 'salman24_interspeech', 'natural speech expressive providing spontaneity msp-podcast sourced podcast podcasts scripted'], ['Muhammad Shakeel, Yui Sudo, Yifan Peng, Shinji Watanabe', 'Contextualized End-to-end Automatic Speech Recognition with Intermediate Biasing Loss', 'shakeel24_interspeech', 'contextual employing non-contextual contextualization layer unbiased objective ignore biased baseline'], ['Ailin Liu, Pepijn Vunderink, Jose Vargas Quiros, Chirag Raman, Hayley Hung', 'How Private is Low-Frequency Speech Audio in the Wild? An Analysis of Verbal Intelligibility by Humans and Machines', 'liu24i_interspeech', 'privacy social behavior delicate privacy-preserving wearable comprehensively ensures simulating balance'], ['Ladislav MoÅ¡ner, Romain Serizel, LukÃ¡Å¡ Burget, OldÅich Plchot, Emmanuel Vincent, Junyi Peng, Jan ÄernockÃ½', 'Multi-Channel Extension of Pre-trained Models for Speaker Verification', 'mosner24_interspeech', 'ssl designing enhancement interleaf downside noteworthy propagated cross-channel focus leveraged'], ['William Ravenscroft, George Close, Stefan Goetze, Thomas Hain, Mohammad Soleymanpour, Anurag Chowdhury, Mark C. Fuhs', 'Transcription-Free Fine-Tuning of Speech Separation Models for Noisy and Reverberant Multi-Speaker Automatic Speech Recognition', 'ravenscroft24_interspeech', 'asr pit signal-level reference loss training separator artefact often audio'], ['Tsun-An Hsieh, Heeyoul Choi, Minje Kim', 'Multimodal Representation Loss Between Timed Text and Audio for Regularized Speech Separation', 'hsieh24b_interspeech', 'ttr summarizer semantics gap underexplored regularizer promotes wavlm text-based bert'], ['Wangyou Zhang, Kohei Saijo, Jee-weon Jung, Chenda Li, Shinji Watanabe, Yanmin Qian', 'Beyond Performance Plateaus: A Comprehensive Study on Scalability in Speech Enhancement', 'zhang24i_interspeech', 'architecture insight larger-scale small-sized size under-explored multi-domain plateau budget provide'], ['Jianyuan Sun, Wenwu Wang, Mark D. Plumbley', 'PFCA-Net: Pyramid Feature Fusion and Cross Content Attention Network for Automated Audio Captioning', 'sun24c_interspeech', 'aac scale fuse existing across intricate struggle facilitating top-down high-dimensional'], ['Woo-Jin Chung, Hong-Goo Kang', 'Speaker-Independent Acoustic-to-Articulatory Inversion through Multi-Channel Attention Discriminator', 'chung24_interspeech', 'aai model intricate overcoming kinematic pearson articulography ema attention-based electromagnetic'], ['Maria Teleki, Xiangjue Dong, Soohwan Kim, James Caverlee', 'Comparing ASR Systems in the Context of Speech Disfluencies', 'teleki24_interspeech', 'whisperx podcasts disfluent google non-scripted node podcast episode larger closer'], ['Ricardo GarcÃ­a, Rodrigo Mahu, NicolÃ¡s GrÃ¡geda, Alejandro Luzanto, Nicolas Bohmer, Carlos Busso, NÃ©stor Becerra Yoma', 'Speech emotion recognition with deep learning beamforming  on a distant human-robot interaction scenario', 'garcia24_interspeech', 'hri ser testing ccc average technology non-acted emulates indoor msp-podcast'], ['Sarthak Yadav, Zheng-Hua Tan', 'Audio Mamba: Selective State Spaces for Self-Supervised Audio Representations', 'yadav24_interspeech', 'general-purpose transformer spectrogram ssast spurred self-supervision size space model patch'], ['Brady Houston, Omid Sadjadi, Zejiang Hou, Srikanth Vishnubhotla, Kyu J. Han', 'Improving Multilingual ASR Robustness to Errors in Language Input', 'houston24_interspeech', 'sensitivity information inference model label common strategy susceptible continues ensuring'], ['Minh Nguyen, Franck Dernoncourt, Seunghyun Yoon, Hanieh Deilamsalehy, Hao Tan, Ryan Rossi, Quan Hung Tran, Trung Bui, Thien Huu Nguyen', 'Identifying Speakers in Dialogue Transcripts: A Text-based Approach Using Pretrained Language Models', 'nguyen24_interspeech', 'medium large-scale name speaker-identification encompassing speaker accessibility lacking novel archive'], ['Matthew Perez, Aneesha Sampath, Minxue Niu, Emily Mower Provost', 'Beyond Binary: Multiclass Paraphasia Detection with Generative Pretrained Transformers and End-to-End Models', 'perez24_interspeech', 'paraphasias gpt aphasia sequence automatic invention misuse single multiple unexplored'], ['Nicholas Klein, Tianxiang Chen, Hemlata Tak, Ricardo Casal, Elie Khoury', 'Source Tracing of Audio Deepfake Systems', 'klein24_interspeech', 'generation deepfakes anti-spoofing spoofing attribute discerning fake multi-language undergo genuine'], ['Christoph Boeddeker, Tobias Cord-Landwehr, Reinhold Haeb-Umbach', 'Once more Diarization: Improving meeting transcription systems through segment-level speaker reassignment', 'boeddeker24_interspeech', 'confusion enhancement revisiting correct error attribution assigning highlighting ease applicability'], ['Gabriel PÃ®rlogeanu, Octavian Pascu, Alexandru-Lucian Georgescu, Horia Cucu', 'Hybrid-Diarization System with Overlap Post-Processing for the DISPLACE 2024 Challenge', 'pirlogeanu24_interspeech', 'diarization der detection eval exhaustive participating collaborative overlapped semi-supervised ensemble'], ['Chris Bras, Tanvina Patel, Odette Scharenborg', 'Using articulated speech EEG signals for imagined speech decoding', 'bras24_interspeech', 'bcis amongst interface transformative end brain-computer point connecting vowel electroencephalography'], ['Emmy Phung, Harsh Deshpande, Ahmad Emami, Kanishk Singh', 'AR-NLU: A Framework for Enhancing Natural Language Understanding Model Robustness against ASR Errors', 'phung24_interspeech', 'nlu asr-robust gold transcript upstream pre-existing adversely challenge input intent'], ['Alireza Bayestehtashk, Amit Kumar, Mike Wurtz', 'Design of Feedback Active Noise Cancellation Filter Using Nested Recurrent Neural Networks', 'bayestehtashk24_interspeech', 'anc stability classical anti-noise problem iir stochastically intractable machine avenue'], ['Paige TuttÃ¶sÃ­, H. Henny Yeung, Yue Wang, Fenqi Wang, Guillaume Denis, Jean-Julien Aucouturier, Angelica Lim', 'Mmm whatcha say? Uncovering distal and proximal context effects in first and second-language word perception using psychophysical reverse correlation', 'tuttosi24_interspeech', 'surrounding profile pitch french timescales strikingly rate acoustic speaker vowel'], ['Alan Baade, Puyuan Peng, David Harwath', 'Neural Codec Language Models for Disentangled and Textless Voice Conversion', 'baade24_interspeech', 'speaker vall-e similarity any-to-any synthesis disentanglement normalizing disentangle guidance autoregressive'], ['Daniel Friedrichs, Monica Lancheros, Sam Kirkham, Lei He, Andrew Clark, Clemens Lutz, Volker Dellwo, Steven Moran', 'Temporal Co-Registration of Simultaneous Electromagnetic Articulography and Electroencephalography for Precise Articulatory and Neural Data Alignment', 'friedrichs24_interspeech', 'eeg ema planning precision onset synchronizes signal integrity kinematics event-related'], ['Octavian Pascu, Adriana Stan, Dan Oneata, Elisabeta Oneata, Horia Cucu', 'Towards generalisable and calibrated audio deepfake detection with self-supervised representations', 'pascu24_interspeech', 'generalisation reliable building desideratum rawnet model frozen logistic coupled pretrained'], ['Suwon Shon, Kwangyoun Kim, Yi-Te Hsu, Prashant Sridhar, Shinji Watanabe, Karen Livescu', 'DiscreteSLU: A Large Language Model with Self-Supervised Discrete Speech Units for Spoken Language Understanding', 'shon24_interspeech', 'llm encoder instruction-following adapter answering diverse task integration capability continuous-valued'], ['Wazeer Zulfikar, Nishat Protyasha, Camila Canales, Heli Patel, James Williamson, Laura Sarnie, Lisa Nowinski, Nataliya Kosmyna, Paige Townsend, Sophia Yuditskaya, Tanya Talkar, Utkarsh Oggy Sarawgi, Christopher McDougle, Thomas Quatieri, Pattie Maes, Maria Mody', 'Analyzing Speech Motor Movement using Surface Electromyography in Minimally Verbal Adults with Autism Spectrum Disorder', 'zulfikar24_interspeech', 'semg muscle skill facial greater gender-matched neurotypical discharge video-based correlation'], ['John Janiczek, Dading Chong, Dongyang Dai, Arlo Faria, Chao Wang, Tao Wang, Yuzong Liu', 'Multi-modal Adversarial Training for Zero-Shot Voice Cloning', 'janiczek24_interspeech', 'model magnified conditionally tt failing discriminates speech dataset fastspeech gan'], ['Xin Jing, Andreas Triantafyllopoulos, BjÃ¶rn Schuller', 'ParaCLAP â Towards a general language-audio model for computational paralinguistic tasks', 'jing24b_interspeech', 'clap audio query set pretraining relies surpass captioning available emerged'], ['Michael Neumann, Hardik Kothare, Jackson Liscombe, Emma C.L. Leschly, Oliver Roesler, Vikram Ramanarayanan', 'Multimodal Digital Biomarkers for Longitudinal Tracking of Speech Impairment Severity in ALS: An Investigation of Clinically Important Differences', 'neumann24_interspeech', 'mcid clinical remote disease meaningful assessment alsfrs-r responsiveness responsive change'], ['Sefik Emre Eskimez, Xiaofei Wang, Manthan Thakker, Chung-Hsien Tsai, Canrun Li, Zhen Xiao, Hemin Yang, Zirun Zhu, Min Tang, Jinyu Li, Sheng Zhao, Naoyuki Kanda', 'Total-Duration-Aware Duration Modeling for Text-to-Speech Systems', 'eskimez24_interspeech', 'tda adjusting diversity phoneme speech model total quality intelligibility tt'], ['Keita Suzuki, Nobukatsu Hojo, Kazutoshi Shinoda, Saki Mizuno, Ryo Masumura', 'Participant-Pair-Wise Bottleneck Transformer for Engagement Estimation from Video Conversation', 'suzuki24_interspeech', 'multi-person token global participant multimodal stream attention among interaction sentiment'], ['Qiao Xiao, Pingchuan Ma, Adriana Fernandez-Lopez, Boqian Wu, Lu Yin, Stavros Petridis, Mykola Pechenizkiy, Maja Pantic, Decebal Constantin Mocanu, Shiwei Liu', 'Dynamic Data Pruning for Automatic Speech Recognition', 'xiao24b_interspeech', 'asr ever-growing barely prohibitively training speech-related entail save overhead granularity'], ['Aryan Chaudhary, Arshdeep Singh, Vinayak Abrol, Mark D. Plumbley', 'Efficient CNNs with Quaternion Transformations and Pruning for Audio Tagging', 'chaudhary24_interspeech', 'footprint memory cost algebra computational large-scale reduce resource-constrained audioset challenge'], ['Yatong Bai, Trung Dang, Dung Tran, Kazuhito Koishida, Somayeh Sojoudi', 'ConsistencyTTA: Accelerating Diffusion-Based Text-to-Audio Generation with Consistency Distillation', 'bai24b_interspeech', 'tta diffusion latent query inference clap audiocaps cfg model closed-loop'], ['Florian Lux, Sarina Meyer, Lyonel Behringer, Frank Zalkow, Phat Do, Matt Coler, EmanuÃ«l A. P. Habets, Ngoc Thang Vu', 'Meta Learning Text-to-Speech Synthesis in over 7000 Languages', 'lux24_interspeech', 'empower massively landscape releasing linguistic foster innovation zero-shot pretraining speech'], ['Xiaofei Wang, Sefik Emre Eskimez, Manthan Thakker, Hemin Yang, Zirun Zhu, Min Tang, Yufei Xia, Jinzhu Li, Sheng Zhao, Jinyu Li, Naoyuki Kanda', 'An Investigation of Noise Robustness for Flow-Matching-Based Zero-Shot TTS', 'wang24v_interspeech', 'prompt audio pre-training quality generated strategy deteriorates masked mixing denoising'], ['Thomas Bott, Florian Lux, Ngoc Thang Vu', 'Controlling Emotion in Text-to-Speech with Natural Language Prompts', 'bott24_interspeech', 'prompt conditioned embeddings tractability steering emotionally prompting text merged intuitive'], ['Hao Yen, Pin-Jui Ku, Sabato Marco Siniscalchi, Chin-Hui Lee', 'Language-Universal Speech Attributes Modeling for Zero-Shot Multilingual Spoken Keyword Recognition', 'yen24_interspeech', 'skr phoneme-based seen character setting wer dat language sequence reduction'], ['Yanis Labrak, Adel Moumen, Richard Dufour, Mickael Rouvier', 'Zero-Shot End-To-End Spoken Question Answering In Medical Domain', 'labrak24_interspeech', 'sqa llm methodology resource transformative question-answering landscape accumulation resource-constrained underscore'], ['Jee-weon Jung, Wangyou Zhang, Jiatong Shi, Zakaria Aldeneh, Takuya Higuchi, Alex Gichamba, Barry-John Theobald, Ahmed Hussen Abdelaziz, Shinji Watanabe', 'ESPnet-SPK: full pipeline speaker embedding toolkit with reproducible recipes, self-supervised front-ends, and off-the-shelf models', 'jung24c_interspeech', 'embeddings extractor vox effortlessly effortless support use including simplifies facilitating'], ['Jing Pan, Jian Wu, Yashesh Gaur, Sunit Sivasankaran, Zhuo Chen, Shujie Liu, Jinyu Li', 'COSMIC: Data Efficient Instruction-tuning For Speech In-Context Learning', 'pan24b_interspeech', 'instruction-following -shot capability llm contextual sqa gpt- question-answer cost-effective biasing'], ['Weiran Wang, Zelin Wu, Diamantino Caseiro, Tsendsuren Munkhdalai, Khe Chai Sim, Pat Rondon, Golan Pundak, Gan Song, Rohit Prabhavalkar, Zhong Meng, Ding Zhao, Tara Sainath, Yanzhang He, Pedro Moreno Mengibar', 'Contextual Biasing with the Knuth-Morris-Pratt Matching Algorithm', 'wang24w_interspeech', 'bonus receives efficiency vectorization search-based search trade cancel wfst gpu'], ['Tiantian Feng, Dimitrios Dimitriadis, Shrikanth S. Narayanan', 'Can Synthetic Audio From Generative Foundation Models Assist Audio Recognition and Speech Modeling?', 'feng24b_interspeech', 'speech-related usc-sail distance generation high-fidelity quality com github heavily assessing'], ['Grant Anderson, Emma Hart, Dimitra Gkatzia, Ian Beaver', 'Automated Human-Readable Label Generation in Open Intent Discovery', 'anderson24_interspeech', 'unlabelled extraction candidate cluster applying resorting dataset discovering analysing method'], ['Benjamin Barrera-Altuna, Daeun Lee, Zaima Zarnaz, Jinyoung Han, Seungbae Kim', 'The Interspeech 2024 TAUKADIAL Challenge: Multilingual Mild Cognitive Impairment Detection with Multimodal Approach', 'barreraaltuna24_interspeech', 'mci mortality speaking language dementia across linguistic worldwide scalability decline'], ['Ruchao Fan, Natarajan Balaji Shankar, Abeer Alwan', "Benchmarking Children's ASR with Supervised and Self-supervised Speech Foundation Models", 'fan24b_interspeech', 'finetuning sfms peft wavlm child whisper various benchmark state-ofthe-art stabilize'], ['Jee-weon Jung, Xin Wang, Nicholas Evans, Shinji Watanabe, Hye-jin Shim, Hemlata Tak, Siddhant Arora, Junichi Yamagishi, Joon Son Chung', 'To what extent can ASV systems naturally defend against spoofing attacks?', 'jung24d_interspeech', 'advancement spoofing-robust cutting-edge effortlessly necessitating acquires underscore defense non-target zero-shot'], ['Ye Ni, Cong Pang, Chengwei Huang, Cairong Zou', 'MSA-DPCRN: A Multi-Scale Asymmetric Dual-Path Convolution Recurrent Network with Attentional Feature Fusion for Acoustic Echo Cancellation', 'ni24_interspeech', 'overlook deep-learning aec merge fuse numerous model validate majority maintaining'], ['Min Ma, Yuma Koizumi, Shigeki Karita, Heiga Zen, Jason Riesa, Haruko Ishikawa, Michiel Bacchiani', 'FLEURS-R: A Restored Multilingual Speech Corpus for Generation Tasks', 'ma24c_interspeech', 'fleurs restoration catalyze tt n-way few-shot language fidelity maintains quality'], ['Carly Demopoulos, Linnea Lampinen, Cristian Preciado, Hardik Kothare, Vikram Ramanarayanan', 'Preliminary Investigation of Psychometric Properties of a Novel Multimodal Dialog Based Affect Production Task in Children and Adolescents with Autism', 'demopoulos24_interspeech', 'apt age sex facial neurotypical ethnicity communication vocal race ability'], ['Shiyao Wang, Shiwan Zhao, Jiaming Zhou, Aobo Kong, Yong Qin', 'Enhancing Dysarthric Speech Recognition for Unseen Speakers via Prototype-Based Adaptation', 'wang24x_interspeech', 'dsr fine-tuning prototype per-word inconvenient encapsulate formidable disabled markedly hubert'], ['Shruti Palaskar, Ognjen Rudovic, Sameer Dharur, Florian Pesce, Gautam Krishna, Aswin Sivaraman, Jack Berkowitz, Ahmed Hussen Abdelaziz, Saurabh Adya, Ahmed Tewfik', 'Multimodal Large Language Models with Fusion Low Rank Adaptation for Device Directed Speech Detection', 'palaskar24_interspeech', 'llm fft eer pre-trained device-directed parity lower consume needing attains'], ['Lin Zhang, Xin Wang, Erica Cooper, Mireia Diez, Federico Landini, Nicholas Evans, Junichi Yamagishi', 'Spoof Diarization: &quot;What Spoofed When&quot; in Partially Spoofed Audio', 'zhang24j_interspeech', 'spoofing clustering partialspoof scenario pioneering task locating defines establishing localization'], ['Zehua Zhang, Xuyi Zhuang, Yukun Qian, Mingjiang Wang', 'Lightweight Dynamic Sparse Transformer for Monaural Speech Enhancement', 'zhang24k_interspeech', 'branch deep coarse fine block wb-pesq spectrum si-sdr feature aggregation'], ['Yu Tomita, Yingxiang Gao, Nobuaki Minematsu, Noriko Nakanishi, Daisuke Saito', 'Analysis and Visualization of Directional Diversity in Listening Fluency of World Englishes Speakers in the Framework of Mutual Shadowing', 'tomita24_interspeech', 'fluently listens disfluency passage communicability larger franca pronunciation shadowed lingua'], ['Yuxuan Xi, Yan Song, Lirong Dai, Haoyu Song, Ian McLoughlin', 'An Effective Local Prototypical Mapping Network for Speech Emotion Recognition', 'xi24_interspeech', 'prototype utterance-level frame-level optimized emotion-aware complex loss mer emotion-related backbone'], ['Yun Liu, Xuechen Liu, Xiaoxiao Miao, Junichi Yamagishi', 'Target Speaker Extraction with Curriculum Learning', 'liu24j_interspeech', 'tse selects interfering increasing strategically libri similarity exceeded signal-to-distortion expose'], ['Jihyun Kim, Stijn Kindt, Nilesh Madhu, Hong-Goo Kang', 'Enhanced Deep Speech Separation in Clustered Ad Hoc Distributed Microphone Environments', 'kim24m_interspeech', 'tac ad-hoc layer dual-path tailor blindly unpredictable learning accommodate fuse'], ['Behnam Gholami, Mostafa El-Khamy, KeeBong Song', 'Knowledge Distillation for Tiny Speech Enhancement with Latent Feature Augmentation', 'gholami24_interspeech', 'model teacher smaller student dnn voicebank complex resource-constrained deploying mimic'], ['Hardik Kothare, Michael Neumann, Cathy Zhang, Jackson Liscombe, Jordi W J van Unnik, Lianne C M Botman, Leonard H van den Berg, Ruben P A van Eijk, Vikram Ramanarayanan', 'How Consistent are Speech-Based Biomarkers in Remote Tracking of ALS Disease Progression Across Languages? A Case Study of English and Dutch', 'kothare24_interspeech', 'pal non-bulbar dutch-speaking bulbar onset english-speaking metric trajectory responsiveness amyotrophic'], ['Dongchao Yang, Dingdong Wang, Haohan Guo, Xueyuan Chen, Xixin Wu, Helen Meng', 'SimpleSpeech: Towards Simple and Efficient Text-to-Speech with Scalar Latent Transformer Diffusion Models', 'yang24l_interspeech', 'sq-codec nar speech-only space compact finite named speech tt non-'], ['Liu Xiaowang, Jinsong Zhang', 'A Study on the Information Mechanism of the 3rd Tone Sandhi Rule in Mandarin Disyllabic Words', 'xiaowang24_interspeech', 'lexical perspective sentence loss communicative minimal level definitive pair confusing'], ['Byeongjoo Ahn, Karren Yang, Brian Hamilton, Jonathan Sheaffer, Anurag Ranjan, Miguel Sarabia, Oncel Tuzel, Jen-Hao Rick Chang', 'Novel-view Acoustic Synthesis From 3D Reconstructed Rooms', 'ahn24c_interspeech', 'scene psnr dereverberation source sdr localization sound separation naively please'], ['Bence Mark Halpern, Thomas Tienkamp, Wen-Chin Huang, Lester Phillip Violeta, Teja Rebernik, Sebastiaan de Visscher, Max Witjes, Martijn Wieling, Defne Abur, Tomoki Toda', 'Quantifying the effect of speech pathology on automatic and human speaker verification', 'halpern24_interspeech', 'asv severity negatively perceptual performance correlated post-surgery surgical objective surgery'], ['Xinghao Huang, Weiwei Jiang, Long Rao, Wei Xu, Wenqing Cheng', 'Active Speaker Detection in Fisheye Meeting Scenes with Scene Spatial Spectrums', 'huang24g_interspeech', 'multi-party asd audio roundtable map on-screen circular dataset sota impressive'], ['Vishwanath Pratap Singh, Federico Malato, Ville HautamÃ¤ki, Md. Sahidullah, Tomi Kinnunen', 'ROAR: Reinforcing Original to Augmented Data Ratio Dynamics for Wav2vec2.0 Based ASR', 'singh24c_interspeech', 'augmentation heuristic librispeech dqn training amount balancing reinforcement recipe min'], ['Bin Zhao, Mingxuan Huang, Chenlu Ma, Jinyi Xue, Aijun Li, Kunyu Xu', 'Decoding Human Language Acquisition: EEG Evidence for Predictive Probabilistic Statistics in Word Segmentation', 'zhao24e_interspeech', 'stream tri-syllable glean auditory lobe lexical temporal statistical gyrus assertion'], ['Muhammad Yeza Baihaqi, Angel Garcia Contreras, Seiya Kawano, Koichiro Yoshino', 'Rapport-Driven Virtual Agent: Rapport Building Dialogue Strategy for Improving User Experience at First Meeting', 'baihaqi24_interspeech', 'free-form engagement satisfaction score human-agent naturalness correlation prompting collaborative llm'], ['Sahil Kumar, Jialu Li, Youshan Zhang', 'Vision Transformer Segmentation for Visual Bird Sound Denoising', 'kumar24_interspeech', 'vitvs contribution vit encompass persistent positioning long-range multi-scale audio struggle'], ['Vahid Khanagha, Dimitris Koutsaidis, Kaustubh Kalgaonkar, Sriram Srinivasan', 'Interference Aware Training Target for DNN based joint Acoustic Echo Cancellation and Noise Suppression', 'khanagha24_interspeech', 'double-talk shadowing near-end truth ground speech far-end spectral aec altering'], ['Yashish M. Siriwardena, Nathan Swedlow, Audrey Howard, Evan Gitterman, Dan Darcy, Carol Espy-Wilson, Andrea Fanelli', 'Accent Conversion with Articulatory Representations', 'siriwardena24_interspeech', 'speech non-native representation incorporate idea originates acoustic acoustic-to-articulatory phonetic used'], ['Amir Hussein, Desh Raj, Matthew Wiesner, Daniel Povey, Paola Garcia, Sanjeev Khudanpur', 'Enhancing Neural Transducer for Multilingual ASR with Synchronized Language Diarization', 'hussein24_interspeech', 'lid auxiliary synchronizes spanish-english seamless mandarin-english synchronize code-switching multitask switching'], ['Haolan Wang, Amin Edraki, Wai-Yip Chan, IvÃ¡n LÃ³pez-Espejo, Jesper Jensen', 'No-Reference Speech Intelligibility Prediction Leveraging a Noisy-Speech ASR Pre-Trained Model', 'wang24y_interspeech', 'sip algorithm wav vec data-driven reference-based datasets parameter-efficient low-rank backbone'], ['Bao Hoang, Yijiang Pang, Hiroko Dodge, Jiayu Zhou', 'Translingual Language Markers for Cognitive Assessment from Spontaneous Speech', 'hoang24_interspeech', 'mci mmse detection treatment bilingual clinical taukadial prodromal enrichment mini-mental'], ['Hengchao Shang, Zongyao Li, Jiaxin Guo, Shaojun Li, Zhiqiang Rao, Yuanchang Luo, Daimeng Wei, Hao Yang', 'An End-to-End Speech Summarization Using Large Language Model', 'shang24_interspeech', 'ssum llm summary text connector abstractive long generate audio-text intricate'], ['Shuhua Li, Qirong Mao, Jiatong Shi', 'PL-TTS: A Generalizable Prompt-based Diffusion TTS Augmented by Large Language Model', 'li24y_interspeech', 'style diffusion-based libritts-r enhanced description grained control hot synthesis unsatisfactory'], ['Fabian Ritter-Gutierrez, Kuan-Po Huang, Jeremy H. M. Wong, Dianwen Ng, Hung-yi Lee, Nancy F. Chen, Eng-Siong Chng', 'Dataset-Distillation Generative Model for Speech Emotion Recognition', 'rittergutierrez24_interspeech', 'dataset iemocap downstream training reduces yet hinge accelerates size class'], ['Jiarui Hai, Karan Thakkar, Helin Wang, Zengyi Qin, Mounya Elhilali', 'DreamVoice: Text-Guided Voice Conversion', 'hai24_interspeech', 'timbre one-shot desired generation plugin libritts inclusive diffusion-based technology vctk'], ['Yuwu Tang, Ziang Ma, Haitao Zhang', 'Enhanced Feature Learning with Normalized Knowledge Distillation for Audio Tagging', 'tang24b_interspeech', 'cnn-based lightweight transformer-based temperature model customized abundant backbone mainstream method'], ['George Joseph, Arun Baby', 'Speaker Personalization for Automatic Speech Recognition using Weight-Decomposed Low-Rank Adaptation', 'joseph24_interspeech', 'lora personalizing asr fine-tuning optimization model holy showcasing paramount limited'], ['Yinlin Guo, Yening Lv, Jinqiao Dou, Yan Zhang, Yuehai Wang', 'FLY-TTS: Fast, Lightweight and High-Quality End-to-End Text-to-Speech Synthesis', 'guo24c_interspeech', 'fourier model convnext vits intel flow-based wavlm compress baseline cpu'], ['Hanbin Bae, Pavel Andreev, Azat Saginbaev, Nicholas Babaev, WonJun Lee, Hosang Sung, Hoon-Young Cho', 'Speech Boosting: Low-Latency Live Speech Enhancement for TWS Earbuds', 'bae24_interspeech', 'on-device latency usage conversation complexity solution anc computational design wireless'], ['Tanya Talkar, Sherman Charles, Chelsea Krantsevich, Kan Kawabata', "Detection of Cognitive Impairment And Alzheimer's Disease Using a Speech- and Language-Based Protocol", 'talkar24_interspeech', 'pad mci auc tool speech-based individual administer presence medication blood'], ['Hyunjae Cho, Junhyeok Lee, Wonbin Jung', 'JenGAN: Stacked Shifted Filters in GAN-Based Speech Synthesis', 'cho24b_interspeech', 'artifact inference aliasing stacking non-autoregressive low-pass vocoders prevent audible evaluation'], ['Iwen E Kang, Christophe Van Gysel, Man-Hung Siu', 'Transformer-based Model for ASR N-Best Rescoring and Rewriting', 'kang24c_interspeech', 'rewrite rescore pertaining on-device privacy exploring assistant ensure increasingly engine'], ['Jaewon Kim, Won-Gook Choi, Seyun Ahn, Joon-Hyuk Chang', 'Sound of Vision: Audio Generation from Visual Text Embedding through Training Domain Discriminator', 'kim24n_interspeech', 'text-to-audio advancement tta aligns address inability adaptability fidelity compromise ensures'], ['Haojie Zhang, Tao Zhang, Ganjun Liu, Dehui Fu, Xiaohui Hou, Ying Lv', 'DysArinVox: DYSphonia &amp; DYSarthria mandARIN speech corpus', 'zhang24l_interspeech', 'chinese pathological comprehensive meticulously imagery diagnostics crafted diagnosed facilitating ensuring'], ['Noumida A, Rajeev Rajan', 'Multi-label Bird Species Classification from Field Recordings using Mel_Graph-GCN Framework', 'a24_interspeech', 'graph deep cnn convolutional gcn macro specaugment mel-spectrograms mel-spectrogram neural'], ['Sai Srujana Buddi, Satyam Kumar, Utkarsh Sarawgi, Vineet Garg, Shivesh Ranjan, Ognjen Rudovic, Ahmed Hussen Abdelaziz, Saurabh Adya', 'Comparative Analysis of Personalized Voice Activity Detection Systems: Assessing Real-World Effectiveness', 'buddi24_interspeech', 'pvad vad comprehensive various ass metric understanding paramount context-aware technology'], ['Ho-Young Choi, Won-Gook Choi, Joon-Hyuk Chang', 'Retrieval-Augmented Classifier Guidance for Audio Generation', 'choi24c_interspeech', 'sampling language-audio incurred low-quality noise-free diffusion dcase pretraining retrieved retrieve'], ['Payal Mohapatra, Shamika Likhite, Subrata Biswas, Bashima Islam, Qi Zhu', 'Missingness-resilient Video-enhanced Multimodal Disfluency Detection', 'mohapatra24_interspeech', 'modality video unified missing fusion accommodates assured resilient curate available'], ['Qifei Li, Yingming Gao, Yuhua Wen, Cong Wang, Ya Li', 'Enhancing Modal Fusion by Alignment and Label Matching for Multimodal Emotion Recognition', 'li24z_interspeech', 'mem mer audio-video information emotional multitask guiding learning arising framework'], ['Zhengyang Chen, Xuechen Liu, Erica Cooper, Junichi Yamagishi, Yanmin Qian', 'Generating Speakers by Prompting Listener Impressions for Pre-trained Multi-Speaker Text-to-Speech Systems', 'chen24q_interspeech', 'prompt trait multispeaker tt pretrained texttospeech method module tailor lora'], ['Junxu Wang, Zhihua Fang, Liang He', 'Self-Supervised Speaker Verification with Mini-Batch Prediction Correction', 'wang24z_interspeech', 'pseudo-labels noisy re-clustering method rectified exponential batch learning bound determines'], ['Zhong Meng, Zelin Wu, Rohit Prabhavalkar, Cal Peyser, Weiran Wang, Nanxin Chen, Tara N. Sainath, Bhuvana Ramabhadran', 'Text Injection for Neural Contextual Biasing', 'meng24d_interspeech', 'cti unpaired asr wer mwer injected phrase speech-like speech-text model'], ['Zihan Pan, Tianchi Liu, Hardik B. Sailor, Qiongqiong Wang', 'Attentive Merging of Hidden Embeddings from Pre-trained Speech Model for Anti-spoofing Detection', 'pan24c_interspeech', 'wavlm transformer hierarchical behavior layer uncertain large notably multi-layer ssl'], ['Kentaro Onda, Joonyong Park, Nobuaki Minematsu, Daisuke Saito', 'A Pilot Study of GSLM-based Simulation of Foreign Accentuation Only Using Native Speech Corpora', 'onda24_interspeech', 'gslm accent language spoken process inputting mentally listens reproduction controllable'], ['Donghyun Seong, Joon-Hyuk Chang', 'H4C-TTS: Leveraging Multi-Modal Historical Context for Conversational Text-to-Speech', 'seong24_interspeech', 'tt conversation encoder situation appropriate recent modeling contextually natural distinguishing'], ['Daryush D. Mehta, Jarrad H. Van Stan, Hamzeh Ghasemzadeh, Robert E. Hillman', 'Comparing ambulatory voice measures during daily life with brief laboratory assessments in speakers with and without vocal hyperfunction', 'mehta24_interspeech', 'recording hyperfunctional accelerometer habitual use accounted tilt relate pressure offset'], ['Li Li, Shogo Seki', 'Improved Remixing Process for Domain Adaptation-Based Speech Enhancement by Mitigating Data Imbalance in Signal-to-Noise Ratio', 'li24aa_interspeech', 'underrepresented snr balanced teacher subpar remixit encompass recorded model dataset'], ['Yuke Lin, Ming Cheng, Fulin Zhang, Yingying Gao, Shilei Zhang, Ming Li', 'VoxBlink2: A 100K+ Speaker Recognition Corpus and the Open-Set Speaker-Identification Benchmark', 'lin24j_interspeech', 'dataset gallery afterward explore single-model encompassing categorize probe wild concrete'], ['A F M Saif, Lisha Chen, Xiaodong Cui, Songtao Lu, Brian Kingsbury, Tianyi Chen', 'M2ASR: Multilingual Multi-task Automatic Speech Recognition via Multi-objective Optimization', 'saif24_interspeech', 'training conflict supervised formulates model objective across multiple task degrading'], ['Liangyu Nie, Sudarsana Reddy Kadiri, Ruchit Agrawal', 'MMSD-Net: Towards Multi-modal Stuttering Detection', 'nie24_interspeech', 'uni-modal speech stuttered impediment disruption context-aware irregular -score neural integral'], ['Mingyue Shi, Huali Zhou, Qinglin Meng, Nengheng Zheng', 'DBD-CI: Doubling the Band Density for Bilateral Cochlear Implants', 'shi24c_interspeech', 'electrode odd alternately speech-in-noise side even stimulating ripple ace dichotic'], ['Peidong Wang, Jian Xue, Jinyu Li, Junkun Chen, Aswin Shanmugam Subramanian', 'Soft Language Identification for Language-Agnostic Many-to-One End-to-End Speech Translation', 'wang24aa_interspeech', 'input model linear source accomplish initialized ensures network specified keeping'], ['Takaaki Saeki, Soumi Maiti, Shinnosuke Takamichi, Shinji Watanabe, Hiroshi Saruwatari', 'SpeechBERTScore: Reference-Aware Automatic Evaluation of Speech Generation Leveraging NLP Evaluation Metrics', 'saeki24_interspeech', 'subjective bertscore gold dense human computes cross-lingual applicability growing opinion'], ['Kang Zhu, Cunhang Fan, Jianhua Tao, Zhao Lv', 'Prompt Link Multimodal Fusion in Multimodal Sentiment Analysis', 'zhu24_interspeech', 'cpl linkage spl connecting modality dimension distance channel randomness connects'], ['Min-Han Shih, Ho-Lam Chung, Yu-Chi Pai, Ming-Hao Hsu, Guan-Ting Lin, Shang-Wen Li, Hung-yi Lee', 'GSQA: An End-to-End Model for Generative Spoken Question Answering', 'shih24b_interspeech', 'abstractive extractive sqa dataset answer empowers directly stride text engage'], ['Yiyang Zhao, Shuai Wang, Guangzhi Sun, Zehua Chen, Chao Zhang, Mingxing Xu, Thomas Fang Zheng', 'Whisper-PMFA: Partial Multi-Scale Feature Aggregation for Speaker Verification using Whisper Models', 'zhao24f_interspeech', 'block eer encoder pmfa cn-celeb low-rank eers ecapa-tdnn receiving resnet'], ['Anna Oura, Hideaki Kikuchi, Tetsunori Kobayashi', 'Preprocessing for acoustic-to-articulatory inversion using real-time MRI movies of Japanese speech', 'oura24_interspeech', 'rtmri aai normalization filtering articulatory estimation extraneous resemble indirect wavelet'], ['Yuting Yang, Guodong Ma, Yuke Li, Binbin Du, Haoqi Zhu, Liang Ruan', 'Learning from Back Chunks: Acquiring More Future Knowledge for Streaming ASR Models via Self Distillation', 'yang24m_interspeech', 'long-distance look-ahead aishell- later latency window information contextual fat chunk-based'], ['Yakun Song, Zhuo Chen, Xiaofei Wang, Ziyang Ma, Guanrou Yang, Xie Chen', 'TacoLM: GaTed Attention Equipped Codec Language Model are Efficient Zero-Shot Text to Speech Synthesizers', 'song24b_interspeech', 'inference efficiency speed vall-e layer cross-attention auto-regressive neural demo suffers'], ['Yaoxun Xu, Shi-Xiong Zhang, Jianwei Yu, Zhiyong Wu, Dong Yu', 'Comparing Discrete and Continuous Space LLMs for Speech Recognition', 'xu24d_interspeech', 'asr llama llm-based open-sourced organizing language advancing hubert achievement representation'], ['Chun Yin, Tai-Shih Chi, Yu Tsao, Hsin-Min Wang', 'SVSNet+: Enhancing Speaker Voice Similarity Assessment Models with Representations from Speech Foundation Models', 'yin24b_interspeech', 'wavlm sfms sfm pre-trained downstream incorporating performance dataset thoroughly baseline'], ['Oliver Roesler, Jackson Liscombe, Michael Neumann, Hardik Kothare, Abhishek Hosamath, Lakshmi Arbatti, Doug Habberstad, Christiane Suendermann-Oeft, Meredith Bartlett, Cathy Zhang, Nikhil Sukhdev, Kolja Wilms, Anusha Badathala, Sandrine Istas, Steve Ruhmel, Bryan Hansen, Madeline Hannan, David Henley, Arthur Wallace, Ira Shoulson, David Suendermann-Oeft, Vikram Ramanarayanan', 'Towards Scalable Remote Assessment of Mild Cognitive Impairment Via Multimodal Dialog', 'roesler24_interspeech', 'mci patient control administering liked reported biomarkers orofacial self-reported cloud-based'], ['Nahomi Kusunoki, Yosuke Higuchi, Tetsuji Ogawa, Tetsunori Kobayashi', 'Hierarchical Multi-Task Learning with CTC and Recursive Operation', 'kusunoki24_interspeech', 'hmtl intermediate layer prediction model lower-level subwords balancing asr facilitating'], ['Eva Szekely, Maxwell Hope', 'An inclusive approach to creating a palette of synthetic voices for gender diversity', 'szekely24_interspeech', 'tt speaker identity expansive failing gender-independent vocal sgd emergent seeking'], ['Dail Kim, Da-Hee Yang, Donghyun Kim, Joon-Hyuk Chang, Jeonghwan Choi, Moa Lee, Jaemo Yang, Han-gil Moon', 'Guided conditioning with predictive network on score-based diffusion model for speech enhancement', 'kim24o_interspeech', 'removal trade-off diffusion-based guiding noise highlighted method emerged reflects outperforming'], ['Osamu Take, Shinnosuke Takamichi, Kentaro Seki, Yoshiaki Bando, Hiroshi Saruwatari', 'SaSLaW: Dialogue Speech Corpus with Audio-visual Egocentric Information Toward Environment-adaptive Dialogue Speech Synthesis', 'take24_interspeech', 'environment audio diverse human-speech spontaneous text-to-speech communication adaptation watch seamless'], ['Hanzhao Li, Liumeng Xue, Haohan Guo, Xinfa Zhu, Yuanjun Lv, Lei Xie, Yunlin Chen, Hao Yin, Zhifei Li', 'Single-Codec: Single-Codebook Speech Codec towards High-Performance Speech Generation', 'li24ba_interspeech', 'multi-codebook module discrete encodec vq-vae time-invariant resampling decouple upsampling downsampling'], ['Woon-Haeng Heo, Joongyu Maeng, Yoseb Kang, Namhyun Cho', 'Centroid Estimation with Transformer-Based Speaker Embedder for Robust Target Speaker Extraction', 'heo24_interspeech', 'tse separator enrollment aiding information division separating stability utterance speech'], ['Xinyi Wu, Changqing Xu, Nan Li, Rongfeng Su, Lan Wang, Nan Yan', 'Depression Enhances Internal Inconsistency between Spoken and Semantic Emotion: Evidence from the Analysis of Emotion Expression in Conversation', 'wu24j_interspeech', 'depressed expressed modality consistency healthy talk neutral patient emotional topic'], ['Yan Xiong, Visar Berisha, Julie Liss, Chaitali Chakrabarti', 'Improving Speech-Based Dysarthria Detection using Multi-task Learning with Gradient Projection', 'xiong24_interspeech', 'mtl clinical conflict size diagnostics single-task adversely task analytic task-specific'], ['Christina TÃ¥nnander, Shivam Mehta, Jonas Beskow, Jens Edlund', 'Beyond graphemes and phonemes: continuous phonological features in neural text-to-speech synthesis', 'tannander24_interspeech', 'confirming tt position perception change phoneme monotonic dual gradual axis'], ['Peter Wu, Ryan Kaveh, Raghav Nautiyal, Christine Zhang, Albert Guo, Anvitha Kachinthaya, Tavish Mishra, Bohan Yu, Alan W Black, Rikky Muller, Gopala Krishna Anumanchipalli', 'Towards EMG-to-Speech with Necklace Form Factor', 'wu24k_interspeech', 'emg electrode neck placed reveal device dry inconvenient electromyography regularly'], ['Tuan Nguyen, Huy Dat Tran', 'LingWav2Vec2: Linguistic-augmented wav2vec 2.0 for Vietnamese Mispronunciation Detection', 'nguyen24b_interspeech', 'canonical phoneme mha pronunciation top- feeding challenge linguistic multi-head adoption'], ['Jinyu Li, Leonardo Lancia', 'A multimodal approach to study the nature of coordinative patterns underlying speech rhythm', 'li24ca_interspeech', 'prominence language-specific production coordination sensorimotor speaker pre-recorded syllable defines unfamiliar'], ['Vahid Noroozi, Zhehuai Chen, Somshubra Majumdar, Steve Huang, Jagadeesh Balam, Boris Ginsburg', 'Instruction Data Generation and Unsupervised Adaptation for Speech Language Models', 'noroozi24_interspeech', 'synthetic generate sample text emerges component expand cross-modal large scarcity'], ['Shaoxiang Dang, Tetsuya Matsumoto, Yoshinori Takeuchi, Takashi Tsuboi, Yasuhiro Tanaka, Daisuke Nakatsubo, Satoshi Maesawa, Ryuta Saito, Masahisa Katsuno, Hiroaki Kudo', 'Developing vocal system impaired patient-aimed voice quality assessment approach using ASR representation-included multiple features', 'dang24b_interspeech', 'stn-dbs patient clinical predicting subthalamic extraordinary showcasing hurdle immense deep'], ['Xuyuan Li, Zengqiang Shang, Peiyang Shi, Hua Hua, Ta Li, Pengyuan Zhang', 'Expressive paragraph text-to-speech synthesis with multi-step variational autoencoder', 'li24da_interspeech', 'ep-mstts speech sliced vits-based variable style model audiobook challenge blizzard'], ['Shivam Mehta, Harm Lameris, Rajiv Punmiya, Jonas Beskow, Eva Szekely, Gustav Eje Henter', 'Should you use a probabilistic duration model in TTS? Probably! Especially for spontaneous speech', 'mehta24b_interspeech', 'nar modelling regression-based speaks non-autoregressive ignore deterministic sampled converting aloud'], ['Haitong Sun, Jaehyun Choi, Nobuaki Minematsu, Daisuke Saito', 'Acceleration of Posteriorgram-based DTW by Distilling the Class-to-class Distances Encoded in the Classifier Used to Calculate Posteriors', 'sun24d_interspeech', 'frame-to-frame posteriorgram n-dimensional distance bhattacharyya class distill fly often sequence'], ['Xu Li, Qirui Wang, Xiaoyu Liu', 'MaskSR: Masked Language Model for Full-band Speech Restoration', 'li24ea_interspeech', 'restoring token distortion reconstructs clipping sub-tasks extracted reverb target high'], ['Sathvik Udupa, Jesuraj Bandekar, Saurabh Kumar, Deekshitha G, Sandhya B, Abhayjeet S, Savitha Murthy, Priyanka Pai, Srinivasa Raghavan, Raoul Nanavati, Prasanta Kumar Ghosh', 'Adapter pre-training for improved speech recognition in unseen domains using low resource adapter tuning of self-supervised models', 'udupa24_interspeech', 'fine-tune ssl low-resource language decoding source target method large cer'], ['Daniel Galvez, Vladimir Bataev, Hainan Xu, Tim Kaldewey', 'Speed of Light Exact Greedy Decoding for RNN-T Speech Recognition Models on GPU', 'galvez24_interspeech', 'billion idle cuda implementation transducer inference end-to-end gpu-based parameter looping'], ['Melanie Weirich, Daniel Duran, Stefanie Jannedy', 'Gender and age based f0-variation in the German Plapper Corpus', 'weirich24_interspeech', 'femininity germany participant mean speaker difference effect masculinity donated female'], ['Han EunGi, Oh Hyun-Bin, Kim Sung-Bin, Corentin Nivelet Etcheberry, Suekyeong Nam, Janghoon Ju, Tae-Hyun Oh', 'Enhancing Speech-Driven 3D Facial Animation with Audio-Visual Guidance from Lip Reading Expert', 'eungi24_interspeech', 'loss motion movement garnered overlook generate perceptual realism readability cost-effective'], ['Liangwei Chen, Xiren Zhou, Qiang Tu, Huanhuan Chen', 'Enhancing Speech and Music Discrimination Through the Integration of Static and Dynamic Features', 'chen24r_interspeech', 'audio raw classification reservoir speech-music readout extracted evolve autoencoders stacked'], ['Yan Wan, Mengyi Sun, Xinchen Kang, Jingting Li, Pengfei Guo, Ming Gao, Su-Jing Wang', 'CDSD: Chinese Dysarthria Speech Database', 'wan24b_interspeech', 'dysarthric cer formidable individual impacting socially html featuring dsr widespread'], ['Qingye Shen, Leonardo Lancia, Noel Nguyen', 'A novel experimental design for the study of listener-to-listener convergence in phoneme categorization', 'shen24c_interspeech', 'listener endpoint game constraint identify psychometric comply unambiguously sound avenue'], ['Yuchun Shu, Bo Hu, Yifeng He, Hao Shi, Longbiao Wang, Jianwu Dang', 'Error Correction by Paying Attention to Both Acoustic and Confidence References for Automatic Speech Recognition', 'shu24_interspeech', 'asr wrong hypothesis n-best well-founded cross-attention word non-autoregressive edit recovering'], ['Meiling Chen, Pengjie Liu, Heng Yang, Haofeng Wang', 'Towards End-to-End Unified Recognition for Mandarin and Cantonese', 'chen24s_interspeech', 'cer mandarin-only efficiency doubled coexist training system model high-resource demanding'], ['Ted Kye', 'Affricates in Lushootseed', 'kye24_interspeech', 'salish ejective coast voiced acoustic-articulatory affricate diachronic frication gravity typological'], ['Zeyang Song, Qianhui Liu, Qu Yang, Yizhou Peng, Haizhou Li', 'ED-sKWS: Early-Decision Spiking Neural Networks for Rapid, and Energy-Efficient Keyword Spotting', 'song24c_interspeech', 'kw energy consumption command speech efficiency snns snn end timestamp'], ['Zimeng Li, Zhongxuan Mao, Shengting Shen, Ivan Yuen, Ping Tang', 'The Production of Contrastive Focus by  7 to 13-year-olds Learning Mandarin Chinese', 'li24fa_interspeech', 'age revealed acquire discourse child tonal perceived tone lexical conveys'], ['Sarina Meyer, Florian Lux, Ngoc Thang Vu', 'Probing the Feasibility of Multilingual Speaker Anonymization', 'meyer24_interspeech', 'privacy language globe speech restricts anonymized protect deterioration component english'], ['Yuejiao Wang, Xianmin Gong, Lingwei Meng, Xixin Wu, Helen Meng', 'Large Language Model-based FMRI Encoding of Language Functions for Subjects with Neurocognitive Disorder', 'wang24ba_interspeech', 'ncd brain language-related functional score cognitive older correlation change adult'], ['Yue Gu, Zhihao Du, Shiliang Zhang, jiqing Han, Yongjun He', 'Personality-memory Gated Adaptation: An Efficient Speaker Adaptation for Personalized End-to-end Automatic Speech Recognition', 'gu24b_interspeech', 'adapter target generalization asr backbone personality cer encoder sacrifice vocal'], ['Daniel Haider, Felix Perfler, Vincent Lostanlen, Martin Ehler, Peter Balazs', 'Hold Me Tight: Stable Encoder-Decoder Design for Speech Enhancement', 'haider24_interspeech', 'audio encoder adapt guaranteeing conservation filter solution preprocess low-complexity objective'], ['Muhammad Umer Sheikh, Hassan Abid, Bhuiyan Sanjid Shafique, Asif Hanif, Muhammad Haris Khan', 'Bird Whisperer: Leveraging Large Pre-trained Acoustic Model for Bird Call Classification', 'sheikh24_interspeech', 'whisper adapting bioacoustic non-human categorizing underscore feature -score imbalance human'], ['Sylvain Coulange, Tsuneo Kato, Solange Rossato, Monica Masperi', 'Exploring Impact of Pausing and Lexical Stress Patterns on L2 English Comprehensibility in Real Time', 'coulange24_interspeech', 'pause click stressed incorrectly protocol struggling real-time sixty listener word'], ['Rhiannon Mogridge, Anton Ragni', 'Learning from memory-based models', 'mogridge24_interspeech', 'cpc psychology memory parametric field equivalently feature task eliminated surprising'], ['Chan-yeong Lim, Hyun-seo Shin, Ju-ho Kim, Jungwoo Heo, Kyo-Won Koo, Seung-bin Kim, Ha-Jin Yu', 'Improving Noise Robustness in Self-supervised Pre-trained Model for Speaker Verification', 'lim24_interspeech', 'warm-up distorting loss noisy information teacher-student strategy unexplored angular prototypical'], ['Jiajun He, Tomoki Toda', '2DP-2MRC: 2-Dimensional Pointer-based Machine Reading Comprehension Method for Multimodal Moment Retrieval', 'he24_interspeech', 'clip-based coarse-grained video underperforms overlooking imprecise pointer existing heavy categorized'], ['Qiang Fang', 'On The Performance of EMA-synchronized Speech and Stand-alone Speech in Acoustic-to-articulatory Inversion', 'fang24_interspeech', 'aai synchronized degrade articulatory root-mean-square acoustic-articulatory pearson various ema latest'], ['Raj Gothi, Rahul Kumar, Mildred Pereira, Nagesh Nayak, Preeti Rao', 'A Dataset and Two-pass System for Reading Miscue Detection', 'gothi24_interspeech', 'asr wide-ranging resource-intensive diagnostics mispronounced limiting elementary alternate viewed fluency'], ['Yuxin Xie, Zhihong Zhu, Xianwei Zhuang, Liming Liang, Zhichang Wang, Yuexian Zou', 'GPA: Global and Prototype Alignment for Audio-Text Retrieval', 'xie24c_interspeech', 'coarse-grained audio text atr pair fine-grained interaction similarity justify pursue'], ['Yaqian Hao, Chenguang Hu, Yingying Gao, Shilei Zhang, Junlan Feng', 'On Calibration of Speech Classification Models: Insights from Energy-Based Model Investigations', 'hao24_interspeech', 'overconfidence calibrating task manifesting guaranteeing classifier deep decision-making mitigating sacrificing'], ['Taisei Omine, Kenta Akita, Reiji Tsuruno', 'Robust Laughter Segmentation with Automatic Diverse Data Synthesis', 'omine24_interspeech', 'audio arbitrary annotation annotates datasets training necessitates laugh automatically annotate'], ['Wing-Zin Leung, Mattias Cross, Anton Ragni, Stefan Goetze', 'Training Data Augmentation for Dysarthric Automatic Speech Recognition by Text-to-Dysarthric-Speech Synthesis', 'leung24_interspeech', 'dasr asr diffusion-based fine-tuning pwd augmentative aac limited finetuning dysarthria'], ['Denise Moussa, Sandra Bergmann, Christian Riess', 'Unmasking Neural Codecs: Forensic Identification of AI-compressed Speech', 'moussa24_interspeech', 'audio ai-based forensics compression lossy trace neurally towards encodec evidence'], ['Yaqian Hao, Chenguang Hu, Yingying Gao, Shilei Zhang, Junlan Feng', 'Exploring Energy-Based Models for Out-of-Distribution Detection in Dialect Identification', 'hao24b_interspeech', 'ood energy score joint enhance conclusively loss sharpness model confronted'], ['Hao Li, Yuan Fang, Xueliang Zhang, Fei Chen, Guanglai Gao', 'Cross-Attention-Guided WaveNet for EEG-to-MEL Spectrogram Reconstruction', 'li24ga_interspeech', '-band mel eeg granularity modality enhance mixup correlation combined cross-attention'], ['Raul Monteiro', 'Adding User Feedback To Enhance CB-Whisper', 'monteiro24_interspeech', 'ov-kws biasing keywords tt keyword-spotting open-vocabulary classifier non-trivial audio heavy'], ['Sarah Wesolek, Piotr Gulgowski, Joanna Blaszczak, Marzena Zygis', 'The influence of L2 accent strength and different error types on personality trait ratings', 'wesolek24_interspeech', 'warmth competence grammatical phonological substitution towards impact unfavorable graded diminished'], ['Ashishkumar Gudmalwar, Nirmesh Shah, Sai Akarsh, Pankaj Wasnik, Rajiv Ratn Shah', 'VECL-TTS: Voice identity and Emotional style controllable Cross-Lingual Text-to-Speech', 'gudmalwar24_interspeech', 'tt emotion dubbing marathi necessitates limited introduce language telugu transferring'], ['Jenifer Vega Rodriguez, Nathalie VallÃ©e, Christophe Savariaux, Silvain Gerber', 'Nasal Air Flow During Speech Production In Korebaju', 'vegarodriguez24_interspeech', 'consonant oral implosive colombia amazonian eva ejective coe harmony iso'], ['Juhwan Yoon, WooSeok Ko, Seyun Um, Sungwoong Hwang, Soojoong Hwang, Changhwan Kim, Hong-Goo Kang', 'UNIQUE : Unsupervised Network for Integrated Speech Quality Evaluation', 'yoon24b_interspeech', 'score metric manner synthetic anomaly objective measure comprising sophisticated paired'], ['Xuenan Xu, Haohe Liu, Mengyue Wu, Wenwu Wang, Mark D. Plumbley', 'Efficient Audio Captioning with Encoder-Level Knowledge Distillation', 'xu24e_interspeech', 'aac loss mse contrastive data-scarce sequence-level model distill exhibiting performance'], ['Zhiyong Wang, Ruibo Fu, Zhengqi Wen, Yuankun Xie, Yukun Liu, Xiaopeng Wang, Xuefei Liu, Yongwei Li, Jianhua Tao, Xin Qi, Yi Lu, Shuchen Shi', 'Generalized Fake Audio Detection via Deep Stable Learning', 'wang24ca_interspeech', 'swl extra datasets distribution training shift weight decorrelating complicate sample'], ['Haoxiang Shi, Ziqi Liang, Jun Yu', 'Emotional Cues Extraction and Fusion for Multi-modal Emotion Prediction and Recognition in Conversation', 'shi24d_interspeech', 'epc stage modality erc modality-specific forthcoming overlooking meld forecast learning'], ['Xuenan Xu, Pingyue Zhang, Ming Yan, Ji Zhang, Mengyue Wu', 'Enhancing Zero-shot Audio Classification using Sound Attribute Knowledge from Large Language Models', 'xu24f_interspeech', 'class description label innate audioset multi-dimensional learning relied ablation never'], ['Neha Sahipjohn, Ashishkumar Gudmalwar, Nirmesh Shah, Pankaj Wasnik, Rajiv Ratn Shah', 'DubWise: Video-Guided Speech Duration Control in Multimodal LLM-based Text-to-Speech for Dubbing', 'sahipjohn24_interspeech', 'lip token text different language video tt sync via cloning'], ['Zeyu Xie, Baihan Li, Xuenan Xu, Zheng Liang, Kai Yu, Mengyue Wu', 'FakeSound: Deepfake General Audio Detection', 'xie24d_interspeech', 'human discerning tester proliferation model dataset website surpasses locate viewed'], ['Tomi H. Kinnunen, Rosa Gonzalez HautamÃ¤ki, Xin Wang, Junichi Yamagishi', 'Speaker Detection by the Individual Listener and the Crowd: Parametric Models Applicable to Bonafide and Deepfake Speech', 'kinnunen24_interspeech', 'role-play subjective det eers fake set-up crowdsourcing spoofed posse observing'], ['Ying Shi, Lantian Li, Shi Yin, Dong Wang, Jiqing Han', 'Serialized Output Training by Learned Dominance', 'shi24e_interspeech', '-mix pit multi-talker speech component showcased sot librimix time-based module'], ['Bolaji Yusuf, Jan Honza Cernocky, Murat SaraÃ§lar', 'Pretraining End-to-End Keyword Search with Automatically Discovered Acoustic Units', 'yusuf24b_interspeech', 'aud untranscribed kw generally system complimentary asr-based finetuning data simplify'], ['Wei Liu, Jingyong Hou, Dong Yang, Muyong Cao, Tan Lee', 'LUPET: Incorporating Hierarchical Information Path into Multilingual ASR', 'liu24k_interspeech', 'lid layer routed design mitigates language high-resource phoneme high-performance linguistic'], ['Jing Xu, Minglin Wu, Xixin Wu, Helen Meng', 'Seamless Language Expansion: Enhancing Multilingual Mastery in Self-Supervised Models', 'xu24g_interspeech', 'existed ssl new preservation re-clustering impairing adaptation lora ability re-synthesis'], ['Martha Schubert, Daniel Duran, Ingo Siegert', 'Challenges of German Speech Recognition: A Study on Multi-ethnolectal Speech Among Adolescents', 'schubert24_interspeech', 'engine openai meta nemo spontaneous nvidia underrepresented persist discern speaker'], ['Taewoo Kim, Choonsang Cho, Young Han Lee', 'Period Singer: Integrating Periodic and Aperiodic Variational Autoencoders for Natural-Sounding End-to-End Singing Voice Synthesis', 'kim24p_interspeech', 'svs alignment corroborated one-to-many aligner address monotonic high-fidelity component owing'], ['Nao Hodoshima', 'Effects of talker and playback rate of reverberation-induced speech on speech intelligibility of older adults', 'hodoshima24_interspeech', 'oas intelligible reverberation fast original slow significantly twenty-four announcement headphone'], ['Swarup Ranjan Behera, Abhishek Dhiman, Karthik Gowda, Aalekhya Satya Narayani', 'FastAST: Accelerating Audio Spectrogram Transformer via Token Merging and Cross-Model Knowledge Distillation', 'behera24_interspeech', 'ast tome speed accuracy framework inference resource-efficient impact throughput compromising'], ['Zirui Ge, Xinzhou Xu, Haiyan Guo, Tingting Wang, Zhen Yang, BjÃ¶rn W. Schuller', 'DGPN: A Dual Graph Prototypical Network for Few-Shot Speech Spoofing Algorithm Recognition', 'ge24_interspeech', 'inter-speech impeding incipient showcasing ample depict realm anti-spoofing representation emerging'], ['Baihan Li, Zeyu Xie, Xuenan Xu, Yiwei Guo, Ming Yan, Ji Zhang, Kai Yu, Mengyue Wu', 'DiveSound: LLM-Assisted Automatic Taxonomy Construction for Diverse Audio Generation', 'li24ha_interspeech', 'diversity dataset multimodal framework subcategories text-to-audio visual overlook class diversified'], ['Zuzanna Miodonska, Michal KrÄcichwost, Ewa KwaÅniok, Agata Sage, Pawel Badura', 'Frication noise features of Polish voiceless dental fricative and affricate produced by children with and without speech disorder', 'miodonska24_interspeech', 'interdental articulation band formant-related employed normative sibilant computer-aided disordered accompanying'], ['Ying Hu, Huamin Yang, Hao Huang, Liang He', 'Cross-modal Features Interaction-and-Aggregation Network with Self-consistency Training for Speech Emotion Recognition', 'hu24e_interspeech', 'ser multimodal modality supervise task-related shallower bimodal selective adaptively deeper'], ['Donghyun Seong, Hoyoung Lee, Joon-Hyuk Chang', 'TSP-TTS: Text-based Style Predictor with Residual Vector Quantization for Expressive Text-to-Speech', 'seong24b_interspeech', 'speech tt representation incorporating reference human-like quality fail conditioned regular'], ['Ziping Zhao, Tian Gao, Haishuai Wang, BjÃ¶rn Schuller', 'MFDR: Multiple-stage Fusion and Dynamically Refined Network for Multimodal Emotion Recognition', 'zhao24g_interspeech', 'perception window context strip cmu-mosei frame misalignment truncation emotionally discovering'], ['Bubai Maji, Rajlakshmi Guha, Aurobinda Routray, Shazia Nasreen, Debabrata Majumdar', 'Investigation of Layer-Wise Speech Representations in Self-Supervised Learning Models: A Cross-Lingual Study in Detecting Depression', 'maji24_interspeech', 'upstream wavlm hubert pooling add single-language mixed-language detection language max'], ['Yun Hao, Reihaneh Amooie, Wietse de Vries, Thomas Tienkamp, Rik van Noord, Martijn Wieling', 'Exploring Self-Supervised Speech Representations for Cross-lingual Acoustic-to-Articulatory Inversion', 'hao24c_interspeech', 'aai articulatory ssl data potential language prospect inferring english scarce'], ['Wei Liu, Jingyong Hou, Dong Yang, Muyong Cao, Tan Lee', 'A Parameter-efficient Language Extension Framework for Multilingual ASR', 'liu24l_interspeech', 'masr peft continual module candidate sub-problems add-on probabilistically low-resourced fundamentally'], ['Debasish Ray Mohapatra, Victor Zappi, Sidney Fels', '2.5D Vocal Tract Modeling: Bridging Low-Dimensional Efficiency with 3D Accuracy', 'mohapatra24b_interspeech', 'solver geometry symmetry model finite-difference blend mid-sagittal aligns surpassing cross-sectional'], ['Jesuraj Bandekar, Sathvik Udupa, Prasanta Kumar Ghosh', 'Articulatory synthesis using representations learnt through phonetic label-aware contrastive loss', 'bandekar24_interspeech', 'speech trajectory human-level framewise deep human-like learning learning-based baseline sequence-to-sequence'], ['Yongjie Si, Yanxiong Li, Jialong Li, Jiaxin Tan, Qianhua He', 'Fully Few-shot Class-incremental Audio Classification Using Expandable Dual-embedding Extractor', 'si24_interspeech', 'ast session prototype base fsc- embedding classifier training class sample'], ['Rastislav Rabatin, Frank Seide, Ernie Chang', 'Navigating the Minefield of MT Beam Search in Cascaded Streaming Speech Translation', 'rabatin24_interspeech', 'beam-search greedy handling intermediate real-time emitting final unequal machine anticipated'], ['Ling Dong, Zhengtao Yu, Wenjun Wang, Yuxin Huang, Shengxiang Gao, Guojiang Zhou', 'Integrating Speech Self-Supervised Learning Models and Large Language Models for ASR', 'dong24_interspeech', 'llm decoder-only garnered potential transport connecting mainstream aligning writing ssl'], ['Anbai Jiang, Bing Han, Zhiqiang Lv, Yufeng Deng, Wei-Qiang Zhang, Xie Chen, Yanmin Qian, Jia Liu, Pingyi Fan', 'AnoPatch: Towards Better Consistency in Machine Anomalous Sound Detection', 'jiang24c_interspeech', 'pre-trained asd audio dcase inconsistency vit fine-tunes datasets inductive model'], ['Nguyen Manh Tien Anh, Thach Ho Sy', 'Improving Speech Recognition with Prompt-based Contextualized ASR and LLM-based Re-predictor', 'manhtienanh24_interspeech', 'contextual mechanism bot system biasing adapter task text encounter task-specific'], ['Katelyn Taylor, Amelia Gully, Helena Daffern', 'Familiar and Unfamiliar Speaker Identification in Speech and Singing', 'taylor24_interspeech', 'social close network listener sung familiarity recognise sample foil listening'], ['Zihan Zhang, Xianjun Xia, Chuanzeng Huang, Yijian Xiao, Lei Xie', 'BS-PLCNet 2: Two-stage Band-split Packet Loss Concealment Network with Intra-model Knowledge Distillation', 'zhang24m_interspeech', 'plc icassp plcmos noncausal future complexity dual-path flop module computational'], ['Shuchen Shi, Ruibo Fu, Zhengqi Wen, Jianhua Tao, Tao Wang, Chunyu Qiang, Yi Lu, Xin Qi, Xuefei Liu, Yukun Liu, Yongwei Li, Zhiyong Wang, Xiaopeng Wang', 'PPPR: Portable Plug-in Prompt Refiner for Text to Audio Generation', 'shi24f_interspeech', 'tta description rich enhance text-to-audio inception surpassing altering playing faced'], ['Minglin Wu, Jing Xu, Xixin Wu, Helen Meng', 'Prompting Large Language Models with Mispronunciation Detection and Diagnosis Abilities', 'wu24l_interspeech', 'llm audio prompt english per encoder decoder cu-chloe phone mdd'], ['Keigo Hojo, Yukoh Wakabayashi, Kengo Ohta, Atsunori Ogawa, Norihide Kitaoka', 'Boosting CTC-based ASR using inter-layer attention-based CTC loss', 'hojo24_interspeech', 'layer encoder intermediate output wer tedlium attention mechanism rtf dividing'], ['Dan Wells, Andrea Lorena Aldana Blanco, Cassia Valentini, Erica Cooper, Aidan Pine, Junichi Yamagishi, Korin Richmond', 'Experimental evaluation of MOS, AB and BWS listening test designs', 'wells24_interspeech', 'type listener seeming liked likeability counterbalanced re-use fastest easiest questioned'], ['Beida Zheng, Mijit Ablimit, Hankiz Yilahun, Askar Hamdulla', 'Convolutional gated MLP and attention improve end-to-end spoken language understanding', 'zheng24b_interspeech', 'intention filling slot slu task detection long-tailed plagued long-tail interrelated'], ['Alon Vinnikov, Amir Ivry, Aviv Hurvitz, Igor Abramovski, Sharon Koubi, Ilya Gurvich, Shai Peer, Xiong Xiao, Benjamin Martinez Elizalde, Naoyuki Kanda, Xiaofei Wang, Shalev Shaer, Stav Yagev, Yossi Asher, Sunit Sivasankaran, Yifan Gong, Min Tang, Huaming Wang, Eyal Krupka', 'NOTSOFAR-1 Challenge: New Datasets, Baseline, and Tasks for Distant Meeting Transcription', 'vinnikov24_interspeech', 'dasr benchmark launch attendee dataset office far-field -hour averaging multi-channel'], ['Jinpeng Li, Yu Pu, Qi Sun, Wei-Qiang Zhang', "Improving Whisper's Recognition Performance for Under-Represented Language Kazakh Leveraging Unpaired Speech and Text", 'li24ia_interspeech', 'pseudo-labeled data gpt researching hallucination worth low-cost penalty fine-tune ultimately'], ['Yunrui Cai, Zhiyong Wu, Jia Jia, Helen Meng', 'LoRA-MER: Low-Rank Adaptation of Pre-Trained Speech Models for Multimodal Emotion Recognition Using Mutual Information', 'cai24b_interspeech', 'mer challenge extract lora mine model feature frozen surpasses fine-tune'], ['Kim Sung-Bin, Lee Chae-Yeon, Gihun Son, Oh Hyun-Bin, Janghoon Ju, Suekyeong Nam, Tae-Hyun Oh', 'MultiTalk: Enhancing 3D Talking Head Generation Across Languages with Multilingual Video Dataset', 'sungbin24_interspeech', 'lip-sync movement datasets speech-driven convincing covering github comprising enhances mouth'], ['Wenjun Wang, Shangbin Mo, Ling Dong, Zhengtao Yu, Junjun Guo, Yuxin Huang', 'DGSRN: Noise-Robust Speech Recognition Method with Dual-Path Gated Spectral Refinement Network', 'wang24da_interspeech', 'addressing noise joint enhancement distortion residue persist issue dense suppression'], ['Gahye Kim, Yunjung Eom, Selina S. Sung, Seunghee Ha, Tae-Jin Yoon, Jungmin So', 'Automatic Children Speech Sound Disorder Detection with Age and Speaker Bias Mitigation', 'kim24q_interspeech', 'ssd debiasing age-dependent impediment dataset group pivotal childhood mitigating multi-head'], ['Jen-Tzung Chien, I-Ping Yeh, Man-Wai Mak', 'Collaborative Contrastive Learning for Hypothesis Domain Adaptation', 'chien24c_interspeech', 'source speaker domain-invariant collaboratively harsh pursue pseudo dual data representation'], ['Xuefei Li, Hao Huang, Ying Hu, Liang He, Jiabao Zhang, Yuyi Wang', 'YOLOPitch: A Time-Frequency Dual-Branch YOLO Model for Pitch Estimation', 'li24ja_interspeech', 'sota determination unvoiced music voiced additional detection f-score proposing accuracy'], ['Qi Wu', 'Mandarin T3 Production by Chinese and Japanese Native Speakers', 'wu24m_interspeech', 'tone adjacent face learner influence underscore challenge study creaky mispronunciation'], ['Saturnino Luz, Sofia De La Fuente Garcia, Fasih Haider, Davida Fromm, Brian MacWhinney, Alyssa Lanzi, Ya-Ning Chang, Chia-Ju Chou, Yi-Chien Liu', 'Connected Speech-Based Cognitive Assessment in Chinese and English', 'luz24_interspeech', 'prediction diagnosis score impairment propensity language-agnostic encompass dataset generalise cognition'], ['Jae-Hong Lee, Sang-Eon Lee, Dong-Hyun Kim, DoHee Kim, Joon-Hyuk Chang', 'Online Subloop Search via Uncertainty Quantization for Efficient Test-Time Adaptation', 'lee24j_interspeech', 'iteration leader updated method number quantizes inefficiency test thread sample'], ['Haoyu Wang, Guoqiang Hu, Guodong Lin, Wei-Qiang Zhang, Jian Li', 'Simul-Whisper: Attention-Guided Streaming Whisper with Truncation Detection', 'wang24ea_interspeech', 'chunk decoding chunk-based out-of-distribution cross-attention hinders truncated auto-regressive impressive encoder-decoder'], ['Arnav Goel, Medha Hira, Anubha Gupta', 'Exploring Multilingual Unseen Speaker Emotion Recognition: Leveraging Co-Attention Cues in Multitask Learning', 'goel24_interspeech', 'ser benchmark cross-validation field ravdess crema-d emodb advent -fold wavlm'], ['Ilseok Kim, Ju-Seok Seong, Joon-Hyuk Chang', 'Few-Shot Keyword-Incremental Learning with Total Calibration', 'kim24r_interspeech', 'fill session kw class new prototype keywords loses initial mixup'], ['Amit Meghanani, Thomas Hain', 'LASER: Learning by Aligning Self-supervised Representations of Speech for Improving Content-related Tasks', 'meghanani24_interspeech', 'cost-effective wavlm hubert fine-tuning regularisation ssl-based superb observed continuing asr'], ['Siddique Latif, Raja Jurdak, BjÃ¶rn W. Schuller', 'Evaluating Transformer-Enhanced Deep Reinforcement Learning for Speech Emotion Recognition', 'latif24_interspeech', 'ser rnns transformer-based transformer benchmark speech-emotion prior centred using recent'], ['Eunseop Yoon, Hee Suk Yoon, John Harvill, Mark Hasegawa-Johnson, Chang D. Yoo', 'LI-TTA: Language Informed Test-Time Adaptation for Automatic Speech Recognition', 'yoon24c_interspeech', 'tta self-supervision correction linguistic asr shift exemplification diverges loss wherein'], ['Georgios Paraskevopoulos, Chara Tsoukala, Athanasios Katsamanis, Vassilis Katsouros', 'The Greek podcast corpus: Competitive speech models for low-resourced languages with weakly supervised data', 'paraskevopoulos24_interspeech', 'modern underscored data-intensive silver large-v exacerbated assembling compile podcasts technology'], ['Qiquan Zhang, Hongxu Zhu, Xinyuan Qian, Eliathamby Ambikairajah, Haizhou Li', 'An Exploration of Length Generalization in Transformer-Based Speech Enhancement', 'zhang24n_interspeech', 'transformer position embedding utterance ape explore infeasible unexplored quadratic facilitated'], ['Shareef Babu Kalluri, Prachi Singh, Pratik Roy Chowdhuri, Apoorva Kulkarni, Shikha Baghel, Pradyoth Hegde, Swapnil Sontakke, Deepak K T, S.R. Mahadeva Prasanna, Deepu Vijayasenan, Sriram Ganapathy', 'The Second DISPLACE Challenge: DIarization of SPeaker and LAnguage in Conversational Environments', 'kalluri24_interspeech', 'dataset track hour leader recording asr board highlighted far-field baseline'], ['Marc Freixes, Marc Arnela, Joan Claudi SocorÃ³, Luis Joglar-Ongay, Oriol Guasch, Francesc AlÃ­as-Pujol', 'Glottal inverse filtering and vocal tract tuning for the numerical simulation of vowel /a/ with different levels of vocal effort', 'freixes24_interspeech', 'source low methodology predominates inverse-filtered liljencrants-fant adjusts model validates reproducing'], ['Shuochen Gao, Shun Lei, Fan Zhuo, Hangyu Liu, Feng Liu, Boshi Tang, Qiaochu Huang, Shiyin Kang, Zhiyong Wu', 'An End-to-End Approach for Chord-Conditioned Song Generation', 'gao24e_interspeech', 'chord music accompaniment flaw vocal harmony inaccuracy control cross-attention lyric'], ['Shuai Wang, Ke Zhang, Shaoxiong Lin, Junjie Li, Xuefei Wang, Meng Ge, Jianwei Yu, Yanmin Qian, Haizhou Li', 'WeSep: A Scalable and Flexible Toolkit Towards Generalizable Target Speaker Extraction', 'wang24fa_interspeech', 'tse subsequential isolating featured toolkits off-the-shelf cocktail multi-talker on-the-fly recipe'], ['Minmin Yang, Rachid Ridouane', 'Intrusive schwa within French stop-liquid clusters: An acoustic analysis', 'yang24n_interspeech', 'word-final liquid consonant stop occurrence place articulation position prevalence factor'], ['Wenhao Guan, Kaidi Wang, Wangjin Zhou, Yang Wang, Feng Deng, Hui Wang, Lin Li, Qingyang Hong, Yong Qin', 'LAFMA: A Latent Flow Matching Model for Text-to-Audio Generation', 'guan24b_interspeech', 'diffusion audio step tta sample generated space sacrificing facilitated accompanied'], ['Xiaopeng Wang, Ruibo Fu, Zhengqi Wen, Zhiyong Wang, Yuankun Xie, Yukun Liu, Jianhua Tao, Xuefei Liu, Yongwei Li, Xin Qi, Yi Lu, Shuchen Shi', 'Genuine-Focused Learning using Mask AutoEncoder for Generalized Fake Audio Detection', 'wang24ga_interspeech', 'fad genuine mae spoofed reconstruction feature gfl content-related focus supplement'], ['Xueyuan Chen, Dongchao Yang, Dingdong Wang, Xixin Wu, Zhiyong Wu, Helen Meng', 'CoLM-DSR: Leveraging Neural Codec Language Modeling for Multi-Modal Dysarthric Speech Reconstruction', 'chen24t_interspeech', 'prosody dsr naturalness codecs similarity speaker embeddings encoder normal extract'], ['Peikun Chen, Sining Sun, Changhao Shan, Qing Yang, Lei Xie', 'Streaming Decoder-Only Automatic Speech Recognition with Discrete Speech Units: A Pilot Study', 'chen24u_interspeech', 'non-streaming unified token model attention introduce speech-text designed asr speech-related'], ['Valentin Pelloin, LÃ©na Dodson, Ãmile Chapuis, Nicolas HervÃ©, David Doukhan', 'Automatic Classification of News Subjects in Broadcast News: Application to a Gender Bias Representation Analysis', 'pelloin24_interspeech', 'topic llm woman dataset politics french channel broadcasted delineate computational'], ['Xuanru Zhou, Anshul Kashyap, Steve Li, Ayati Sharma, Brittany Morin, David Baquirin, Jet Vonk, Zoe Ezzes, Zachary Miller, Maria Tempini, Jiachen Lian, Gopala Anumanchipalli', 'YOLO-Stutter: End-to-end Region-Wise Speech Dysfluency Detection', 'zhou24e_interspeech', 'dysfluencies dysfluent aggregator aphasia open-sourced speech-text prolongation governed imperfect state-of-the-art'], ['Ziqian Ning, Shuai Wang, Pengcheng Zhu, Zhichao Wang, Jixun Yao, Lei Xie, Mengxiao Bi', 'DualVC 3: Leveraging Language Model Generated Pseudo Context for End-to-end Low Latency Streaming Voice Conversion', 'ning24_interspeech', 'encoder optional popularity multi-level k-means adopts cascade chunk ssl clustered'], ['Chao-Wei Huang, Hui Lu, Hongyu Gong, Hirofumi Inaguma, Ilia Kulikov, Ruslan Mavlyutov, Sravya Popuri', 'Investigating Decoder-only Large Language Models for Speech-to-text Translation', 'huang24h_interspeech', 'llm covost fleurs consume parameter-efficient exceptional proprietary avenue task speech-related'], ['Dake Guo, Xinfa Zhu, Liumeng Xue, Yongmao Zhang, Wenjie Tian, Lei Xie', 'Text-aware and Context-aware Expressive Audiobook Speech Synthesis', 'guo24d_interspeech', 'style diverse tt expressiveness taca encoder vits-based capture narrator space'], ['Hang Zhao, Yifei Xin, Zhesong Yu, Bilei Zhu, Lu Lu, Zejun Ma', 'MINT: Boosting Audio-Language Model via Multi-Target Pre-Training and Instruction Tuning', 'zhao24h_interspeech', 'audio-text frozen task diverse integration alignment empowers generation cross-modality understanding'], ['Yudong Yang, Rongfeng Su, Rukiye Ruzi, Manwa Ng, Shaofeng Zhao, Nan Yan, Lan Wang', 'Optical Flow Guided Tongue Trajectory Generation for Diffusion-based Acoustic to Articulatory Inversion', 'yang24o_interspeech', 'uti aai diffusion reference generated data omitting constraint contour additional'], ['Xiang-Li Lu, Yi-Fen Liu', 'Deep Prosodic Features in Tandem with Perceptual Judgments of Word Reduction for Tone Recognition in Conversed Speech', 'lu24d_interspeech', 'classification transformer-based rhythmic tackle leveraging encoding classify predicting jointly encoder'], ['Han Kunmei', 'Modelling Lexical Characteristics of the Healthy Aging Population: A Corpus-Based Study', 'kunmei24_interspeech', 'language nlp old age concreteness large-language prodromal tool help normative'], ['Shaojun Li, Daimeng Wei, Hengchao Shang, Jiaxin Guo, ZongYao Li, Zhanglin Wu, Zhiqiang Rao, Yuanchang Luo, Xianghui He, Hao Yang', 'Speaker-Smoothed kNN Speaker Adaptation for End-to-End ASR', 'li24ka_interspeech', 'magicdata pre-built setting k-nearest comparably data neighbor x-vector cer sparsity'], ['Jeong-Hwan Choi, Ye-Rin Jeoung, Ilseok Kim, Joon-Hyuk Chang', 'Efficient Speaker Embedding Extraction Using a Twofold Sliding Window Algorithm for Speaker Diarization', 'choi24d_interspeech', 'swa frame-level representation concatenated pre-trained employ extract floating-point adapter non-overlapping'], ['Mun-Hak Lee, Jae-Hong Lee, DoHee Kim, Ye-Eun Ko, Joon-Hyuk Chang', 'Balanced-Wav2Vec: Enhancing Stability and Robustness of Representation Learning Through Sample Reweighting Techniques', 'lee24k_interspeech', 'collapse mode wav codebook exacerbates stably loss skewed suppresses converges'], ['Xuankai Chang, Jiatong Shi, Jinchuan Tian, Yuning Wu, Yuxun Tang, Yihan Wu, Shinji Watanabe, Yossi Adi, Xie Chen, Qin Jin', 'The Interspeech 2024 Challenge on Speech Processing Using Discrete Units', 'chang24b_interspeech', 'compelling pivotal encompasses foster evolving restoration singing highlighted offering baseline'], ['Hang Su, Yuxiang Kong, Lichun Fan, Peng Gao, Yujun Wang, Zhiyong Wu', 'Speaker Change Detection with Weighted-sum Knowledge Distillation based on Self-supervised Pre-trained Models', 'su24_interspeech', 'scd method fine-tuning model basic consumes many industrial selectively industry'], ['Yeh-Sheng Lin, Shu-Chuan Tseng, Jyh-Shing Roger Jang', 'Leveraging Phonemic Transcription and Whisper toward Clinically Significant Indices for Automatic Child Speech Assessment', 'lin24k_interspeech', 'normative diagnosing early speech-language ssd unsuitable workflow phoneme validates pathologist'], ['Rui Wang, Liping Chen, Kong Aik Lee, Zhen-Hua Ling', 'Asynchronous Voice Anonymization Using Adversarial Perturbation On Speaker Embedding', 'wang24ha_interspeech', 'attribute perception human preserved pseudo-speaker obscured machine anonymized disentanglement altering'], ['Yishuang Li, Wenhao Guan, Hukai Huang, Shiyu Miao, Qi Su, Lin Li, Qingyang Hong', 'Efficient Integrated Features Based on Pre-trained Models for Speaker Verification', 'li24la_interspeech', 'ptms handcrafted representation undoubtedly decent discarded fine-tune adaptively fuse multi-layer'], ['Jiu Feng, Mehmet Hamza Erol, Joon Son Chung, Arda Senocak', 'ElasticAST: An Audio Spectrogram Transformer for All Length and Resolutions', 'feng24c_interspeech', 'asts ast inference flexibility input packing inherit accommodates fixed-size training'], ['Kun Zou, Fengyun Tan, Ziyang Zhuang, Chenfeng Miao, Tao Wei, Shaodan Zhai, Zijian Li, Wei Hu, Shaojun Wang, Jing Xiao', 'E-Paraformer: A Faster and Better  Parallel Transformer for Non-autoregressive End-to-End Mandarin Speech Recognition', 'zou24_interspeech', 'paraformer cif speedup aishell- embeddings integrate-and-fire inefficiency nar mechanism token-level'], ['Yu Watanabe, Koichiro Ito, Shigeki Matsubara', 'Utilization of Text Data for Response Timing Detection in Attentive Listening', 'watanabe24_interspeech', 'narrative punctuation agent utilize accumulated trained model insertion mark inspired'], ['Ziyun Cui, Chang Lei, Wen Wu, Yinan Duan, Diyang Qu, Ji Wu, Runsen Chen, Chao Zhang', 'Spontaneous Speech-Based Suicide Risk Detection Using Whisper and Large Language Models', 'cui24_interspeech', 'adolescent finetuning llm potential eighteen parameter-efficient audio-text speech -score aged'], ['Chia-Kai Yeh, Chih-Chun Chen, Ching-Hsien Hsu, Jen-Tzung Chien', 'Cross-Modality Diffusion Modeling and Sampling for Speech Recognition', 'yeh24_interspeech', 'discrete transformer excels decorrelation continuous serving non-autoregressive merit identifies redundancy'], ['Ainikaerjiang Aimaiti, Di Wu, Liting Jiang, Gulinigeer Abudouwaili, Hao Huang, Wushour Silamu', 'An Uyghur Extension to the MASSIVE Multi-lingual Spoken Language Understanding Corpus with Comprehensive Evaluations', 'aimaiti24_interspeech', 'slu massive-ug dataset embedding affix agglutinative available stem task-oriented com'], ['Murali Karthick Baskar, Andrew Rosenberg, Bhuvana Ramabhadran, Neeraj Gaur, Zhong Meng', 'Speech Prefix-Tuning with RNNT Loss for Improving LLM Predictions', 'baskar24_interspeech', 'frozen indic prefix fine-tuned asr applying approches testset language-based lead'], ['Mojtaba Kadkhodaie Elyaderani, John Glover, Thomas Schaaf', 'Reference-Free Estimation of the Quality of Clinical Notes Generated from Doctor-Patient Conversations', 'kadkhodaieelyaderani24_interspeech', 'note collection automatically-generated reference-based generation robust section counterpart absence diverse'], ['Tianqi Geng, Hui Feng', "Form and Function in Prosodic Representation:  In the Case of 'ma' in Tianjin Mandarin", 'geng24_interspeech', 'deixis pronoun particle modal marker pitch discourse distinct narrowest widest'], ['Muqiao Yang, Xiang Li, Umberto Cappellazzo, Shinji Watanabe, Bhiksha Raj', 'Towards Unified Evaluation of Continual Learning in Spoken Language Understanding', 'yang24p_interspeech', 'plasticity generalizability stability metric slu property neglect across task ordering'], ['Shijie Lai, Minglu He, Zijing Zhao, Kai Wang, Hao Huang, Jichen Yang', 'Synthesizing Long-Form Speech merely from Sentence-Level Corpus with Content Extrapolation and LLM Contextual Enrichment', 'lai24b_interspeech', 'generalization pause mega llm-based generate model natural equipped gated failure'], ['Bingliang Zhao, Jiangping Kong, Xiyu Wu', 'Age-related Differences in Acoustic Cues for the Perception of Checked Syllables in Shengzhou Wu', 'zhao24i_interspeech', 'coda stop glottal evolution perceptual vowel duration chinese unchecked weaken'], ['Sreyan Ghosh, Sonal Kumar, Ashish Seth, Purva Chiniya, Utkarsh Tyagi, Ramani Duraiswami, Dinesh Manocha', 'LipGER: Visually-Conditioned Generative Error Correction for Robust Automatic Speech Recognition', 'ghosh24b_interspeech', 'motion lip asr llm visual cue instruct datasets beam-search avsr'], ['David Doukhan, Lena Dodson, Manon Conan, Valentin Pelloin, AurÃ©lien Clamouse, MÃ©lina Lepape, GÃ©raldine Van Hille, CÃ©cile MÃ©adel, MarlÃ¨ne Coulomb-Gully', 'Gender Representation in TV and Radio: Automatic Information Extraction methods versus Manual Analyses', 'doukhan24_interspeech', 'woman descriptor channel protagonist french war reference systemic depicting journalist'], ['Neeraj Gaur, Rohan Agrawal, Gary Wang, Parisa Haghani, Andrew Rosenberg, Bhuvana Ramabhadran', 'ASTRA: Aligning Speech and Text Representations for Asr without Sampling', 'gaur24_interspeech', 'rnnt match modality length fleurs duration-based injection prevailing upsampling misalignment'], ['AnaÃ¯s Rameau, Satrajit Ghosh, Alexandros Sigaras, Olivier Elemento, Jean-Christophe Belisle-Pipon, Vardit Ravitsky, Maria Powell, Alistair Johnson, David Dorr, Philip Payne, Micah Boyer, Stephanie Watts, Ruth Bahr, Frank Rudzicz, Jordan Lerner-Ellis, Shaheen Awan, Don Bolser, Yael Bensoussan', 'Developing Multi-Disorder Voice Protocols: A team science approach involving clinical expertise, bioethics, standards, and DEI.', 'rameau24_interspeech', 'respiratory cohort disease large-scale ethically fuel biomarkers sourced pro anxiety'], ['Yuewei Zhang, Huanbin Zou, Jie Zhu', 'Sub-PNWR: Speech Enhancement Based on Signal Sub-Band Splitting and Pseudo Noisy Waveform Reconstruction Loss', 'zhang24o_interspeech', 'full-band denoised bank filter module spectrum computational spaced entail devise'], ['Kai-Wei Chang, Ming-Hao Hsu, Shan-Wen Li, Hung-yi Lee', 'Exploring In-Context Learning of Textless Speech Language Model for Speech Classification Tasks', 'chang24c_interspeech', 'icl demonstration nlp manner equipping capability gpt- first perform few-shot'], ['Akihiro Kato, Hiroyuki Nagano, Kohei Chike, Masaki Nose', 'Self-Supervised Learning for ASR Pre-Training with Uniquely Determined Target Labels and Controlling Cepstrum Truncation for Speech Augmentation', 'kato24_interspeech', 'pre-trained libri-light limited hubert data conformer method condition cer non'], ['Fangjing Niu, Xiaozhe Qi, Xinya Chen, Liang He', 'Speech Topic Classification Based on Multi-Scale and Graph Attention Networks', 'niu24b_interspeech', 'node transcribed convolutional global capture relationship stc surpassing subjected text'], ['Jinchuan Tian, Yifan Peng, William Chen, Kwanghee Choi, Karen Livescu, Shinji Watanabe', 'On the Effects of Heterogeneous Data Sources on Speech-to-Text Foundation Models', 'tian24_interspeech', 'owsm open series staying heterogeneity transparency proxy llm punctuation incorporation'], ['Fathima Zaheera, Supritha Shetty, Gayadhar Pradhan, Deepak K T', 'Automatic Assessment of Dysarthria using Speech and synthetically generated Electroglottograph signal', 'zaheera24_interspeech', 'lmfe dysarthric stm averaged mfccs mel complementary automated computed ua-speech'], ['Yixiang Niu, Ning Chen, Hongqing Zhu, Zhiying Zhu, Guangqiang Li, Yibo Chen', 'Auditory Spatial Attention Detection Based on Feature Disentanglement and Brain Connectivity-Informed Graph Neural Networks', 'niu24c_interspeech', 'eeg asad connectivity cross-subject single-trial surround inter-subject electroencephalogram graph-based model'], ['Tianhua Qi, Shiyan Wang, Cheng Lu, Yan Zhao, Yuan Zong, Wenming Zheng', 'Towards Realistic Emotional Voice Conversion using Controllable Emotional Intensity', 'qi24_interspeech', 'evc diversity rhythm emotion renderer pseudo-labels mere smoothly controllability nuance'], ['Jincen Wang, Yan Zhao, Cheng Lu, Chuangao Tang, Sunan Li, Yuan Zong, Wenming Zheng', 'Boosting Cross-Corpus Speech Emotion Recognition using CycleGAN with Contrastive Learning', 'wang24ia_interspeech', 'premise gan ser data casia testing synthetic enterface originates identically'], ['Cheng Lu, Yuan Zong, Yan Zhao, Hailun Lian, Tianhua Qi, BjÃ¶rn Schuller, Wenming Zheng', 'Hierarchical Distribution Adaptation for Unsupervised Cross-corpus Speech Emotion Recognition', 'lu24e_interspeech', 'hda testing utterance-level ser domain undermines sda uda module fda'], ['Jacob Bitterman, Daniel Levi, Hilel Hagai Diamandi, Sharon Gannot, Tal Rosenwein', 'RevRIR: Joint Reverberant Speech and Room Impulse Response Embedding using Contrastive Learning with Application to Room Shape Classification', 'bitterman24_interspeech', 'rir task fingerprinting determine cumbersome specific receives embed volume utterance'], ['Tianyi Xu, Kaixun Huang, Pengcheng Guo, Yu Zhou, Longtao Huang, Hui Xue, Lei Xie', 'Towards Rehearsal-Free Multilingual ASR: A LoRA-based Case Study on Whisper ', 'xu24h_interspeech', 'forgetting original language model parameter uyghur tibetan allocate new lora'], ['Jincen Wang, Yan Zhao, Cheng Lu, Hailun Lian, Hongli Chang, Yuan Zong, Wenming Zheng', 'Confidence-aware Hypothesis Transfer Networks for Source-Free Cross-Corpus Speech Emotion Recognition', 'wang24ja_interspeech', 'ser source module target emovo casia enterface emodb self-training confident'], ['Ofer Schwartz, Sharon Gannot', 'Efficient Joint Bemforming and Acoustic Echo Cancellation Structure for Conference Call Scenarios', 'schwartz24_interspeech', 'aec microphone scheme pre-filter indifferent weight apply far-end circumvent encompassing'], ['Zhu Li, Xiyuan Gao, Yuqing Zhang, Shekhar Nayak, Matt Coler', 'A Functional Trade-off between Prosodic and Semantic Cues in Conveying Sarcasm', 'li24ma_interspeech', 'sarcastic phrase semantics meaning expression lessened utterance propensity illocutionary disentangles'], ['Katerina Papadimitriou, Gerasimos Potamianos', 'Multimodal Continuous Fingerspelling Recognition via Visual Alignment Learning', 'papadimitriou24_interspeech', 'skeletal signing st-gcn bigru d-cnn paramount persist spatio-temporal accessibility parameterization'], ['Sathvik Udupa, Soumi Maiti, Prasanta Kumar Ghosh', 'IndicMOS: Multilingual MOS Prediction for 7 Indian languages', 'udupa24b_interspeech', 'tt predictor level open-source evaluation tau indic train challenge gold'], ['Xiuwen Zheng, Bornali Phukon, Mark Hasegawa-Johnson', "Fine-Tuning Automatic Speech Recognition for People with Parkinson's: An Effective Strategy for Enhancing Speech Technology Accessibility", 'zheng24c_interspeech', 'multi-task librispeech sap palsy model dysphonic cerebral asr dysarthric data'], ['Peter Birkholz, Patrick HÃ¤sner', 'Measurement and simulation of pressure losses due to airflow in vocal tract models', 'birkholz24_interspeech', 'tube viscous section proportional glottis kinetic power area diameter bernoulli'], ['Khanh Le, Duc Chau', 'Improving Streaming Speech Recognition With Time-Shifted Contextual Attention And Dynamic Right Context Masking', 'le24_interspeech', 'user-perceived drc future in-context chunk-based valued restricts featuring stand batch'], ['Vu Hoang, Viet Thanh Pham, Hoa Nguyen Xuan, Pham Nhi, Phuong Dat, Thi Thu Trang Nguyen', 'VSASV: a Vietnamese Dataset for Spoofing-Aware Speaker Verification', 'hoang24b_interspeech', 'sasv spoofed language system authentic unexplored anti-spoofing concentrated encourage latest'], ['Tuyen Tran, Khanh Le, Ngoc Dang Nguyen, Minh Vu, Huyen Ngo, Woomyoung Park, Thi Thu Trang Nguyen', 'VN-SLU: A Vietnamese Spoken Language Understanding Dataset', 'tran24b_interspeech', 'slu ensuring intent tool crowd-sourcing smart slot scarcity home utterance'], ['Hemant Yadav, Sunayana Sitaram, Rajiv Ratn Shah', 'MS-HuBERT: Mitigating Pre-training and Inference Mismatch in Masked Language Modelling methods for learning Speech Representations', 'yadav24b_interspeech', 'hubert self-supervised asr swap traction disparity finetuning beat vanilla lag'], ['Mattias Nilsson, Riccardo Miccini, Clement Laroche, Tobias Piechowiak, Friedemann Zenke', 'Resource-Efficient Speech Quality Prediction through Quantization Aware Training and Binary Activation Maps', 'nilsson24_interspeech', 'bam device dnsmos commonplace dot prohibitive resource-constrained multiplication -bit summation'], ['Atli Sigurgeirsson, Eddie L. Ungless', "Just Because We Camp, Doesn't Mean We Should: The Ethics of Modelling Queer Voices.", 'sigurgeirsson24_interspeech', 'gay voice pipeline rating lgbtq ramification death capture fairness loss'], ['Adham Ibrahim, Shady Shehata, Ajinkya Kulkarni, Mukhtar Mohamed, Muhammad Abdul-Mageed', 'What Does it Take to Generalize SER Model Across Datasets? A Comprehensive Benchmark', 'ibrahim24_interspeech', 'emotional emotion oversampling explore imbalanced emphasizing thorough whisper speech-based evaluation'], ['Alexander Blatt, Aravind Krishnan, Dietrich Klakow', 'Joint vs Sequential Speaker-Role Detection and Automatic Speech Recognition for Air-traffic Control', 'blatt24_interspeech', 'srd atc architecture asr transcript atco natural-language traditional step preferable'], ['Weiqin Li, Peiji Yang, Yicheng Zhong, Yixuan Zhou, Zhisheng Wang, Zhiyong Wu, Xixin Wu, Helen Meng', 'Spontaneous Style Text-to-Speech Synthesis with Controllable Spontaneous Behaviors Based on Language Models', 'li24na_interspeech', 'prosody speech diverse naturalness low-quality variation categorize uniformly human-like encounter'], ['Sneha Ray Barman, Shakuntala Mahanta, Neeraj Kumar Sharma', 'Deciphering Assamese Vowel Harmony with Featural InfoWaveGAN', 'raybarman24_interspeech', 'regressive long-distance iterative learning illicit grasping non-iterative insightful universality directionality'], ['Orchid Chetia Phukan, Priyabrata Mallick, Swarup Ranjan Behera, Aalekhya Satya Narayani, Arun Balaji Buduru, Rajesh Sharma', 'Towards Multilingual Audio-Visual Question Answering', 'phukan24_interspeech', 'avqa benchmark datasets work existing replicating language suite prevents allocation'], ['Hongchen Wu, Jiwon Yun', 'Influences of Morphosyntax and Semantics on the Intonation of Mandarin Chinese Wh-indeterminates', 'wu24n_interspeech', 'morphosyntactic production faculty prosodic shaping interrogative clause convey speech interference'], ['Jinhyeok Yang, Junhyeok Lee, Hyeong-Seok Choi, Seunghoon Ji, Hyeongju Kim, Juheon Lee', 'DualSpeech: Enhancing Speaker-Fidelity and Text-Intelligibility Through Dual Classifier-Free Guidance', 'yang24q_interspeech', 'tt control exceptional nuance diffusion phoneme-level replicate surpasses demo advancement'], ['Tianchi Liu, Lin Zhang, Rohan Kumar Das, Yi Ma, Ruijie Tao, Haizhou Li', 'How Do Neural Spoofing Countermeasures Detect Partially Spoofed Audio?', 'liu24m_interspeech', 'cm bona fide prioritize decision-making lay interpretability focus explains manipulating'], ['Tillmann Pistor, Adrian Leemann', 'Echoes of Implicit Bias Exploring Aesthetics and Social Meanings of Swiss German Dialect Features', 'pistor24_interspeech', 'bern zurich arrogant aesthetic importance category stereotype single-word rater perception'], ['Aryan Chaudhary, Vinayak Abrol', 'QGAN: Low Footprint Quaternion Neural Vocoder for Speech Synthesis', 'chaudhary24b_interspeech', 'low-footprint vastly landscape model grown gans evolved compromising diffusion high-fidelity'], ['Edresson Casanova, Kelly Davis, Eren GÃ¶lge, GÃ¶rkem GÃ¶knar, Iulian Gulea, Logan Hart, Aya Aljafari, Joshua Meyer, Reuben Morais, Samuel Olayemi, Julian Weber', 'XTTS: a Massively Multilingual Zero-Shot Text-to-Speech Model', 'casanova24_interspeech', 'zs-tts medium language voicebox vall-e resource cloning sota limiting proposing'], ['Nan Chen, Yonghe Wang, Feilong Bao', 'Sign Value Constraint Decomposition for Efficient 1-Bit Quantization of Speech Translation Tasks', 'chen24v_interspeech', 'quantized model matrix layer cost linear approximates distillation speech-to-text trainable'], ['Devang Kulshreshtha, Nikolaos Pappas, Brady Houston, Saket Dingliwal, Srikanth Ronanki', 'Sequential Editing for Lifelong Training of Speech Recognition Models', 'kulshreshtha24_interspeech', 'domain lll necessitate prior new asr fine-tuning access multi-accent inefficiency'], ['Vincenzo Norman Vitale, Loredana Schettino, Francesco Cutugno', 'Rich speech signal: exploring and exploiting  end-to-end automatic speech recognizersâ ability to model hesitation phenomena', 'vitale24_interspeech', 'decoder disregarded deepen procedural system prolongation conformer-based neglect acknowledged regularity'], ['Anna Favaro, Tianyu Cao, Najim Dehak, Laureano Moro-Velazquez', 'Leveraging Universal Speech Representations for Detecting and Assessing the Severity of Mild Cognitive Impairment Across Languages', 'favaro24_interspeech', 'mci feature mmse taukadial cross-lingually language-agnostic mini-mental interpretable suitability cohort'], ['Zitha Sasindran, Harsha Yelchuri, T. V. Prabhakar', 'SeMaScore: A new evaluation metric for automatic speech recognition tasks', 'sasindran24_interspeech', 'bertscore serf segment-wise score atypical corresponds algorithm signal-to-noise scoring involving'], ['Bhasi K. C., Rajeev Rajan, Noumida A', 'Attention-augmented X-vectors for the Evaluation of Mimicked Speech Using Sparse Autoencoder-LSTM framework', 'kc24_interspeech', 'artist mimicking fed encoded later embeddings rank- mimicry competency lstm-based'], ['Vidar Freyr Gudmundsson, Keve MÃ¡rton GÃ¶nczi, Malin Svensson Lundmark, Donna Erickson, Oliver Niebuhr', 'The MARRYS helmet: A new device for researching and training âjaw dancingâ', 'gudmundsson24_interspeech', 'portrait articulograph ema electromagnetic teaching motivation outline science illustrate analyzing'], ['Nikhil Jakhar, Sudhanshu Srivastava, Arun Baby', 'A Unified Approach to Multilingual Automatic Speech Recognition with Improved Language Identification for Indic Languages', 'jakhar24_interspeech', 'lid asr scalability der whisper diarization language-specific model low-resource enhancing'], ['Patrick Cormac English, John D. Kelleher, Julie Carson-Berndsen', 'Searching for Structure: Appraising the Organisation of Speech Features in wav2vec 2.0 Embeddings', 'english24_interspeech', 'within transformer organisational relationship encapsulate uncovering explainability model probing mining'], ['Danilo de Oliveira, Simon Welker, Julius Richter, Timo Gerkmann', "The PESQetarian: On the Relevance of Goodhart's Law for Speech Enhancement", 'deoliveira24_interspeech', 'metric pesq model evaluation listening misleading detrimental instrumental imply used'], ['Liam Kelley, Diego Di Carlo, Aditya Arie Nugraha, Mathieu Fontaine, Yoshiaki Bando, Kazuyoshi Yoshii', 'RIR-in-a-Box: Estimating Room Acoustics from 3D Mesh Data through Shoebox Approximation', 'kelley24_interspeech', 'rirs rir latent differentiable code scene real estimator consistency physical'], ['Himanshu Maurya, Atli Sigurgeirsson', 'A Human-in-the-Loop Approach to Improving Cross-Text Prosody Transfer', 'maurya24_interspeech', 'reference hitl text rendition target prosodic utterance appropriate suffices closeness'], ['Themos Stafylakis, Anna Silnova, Johan Rohdin, OldÅich Plchot, LukÃ¡Å¡ Burget', 'Challenging margin-based speaker embedding extractors by using the variational information bottleneck', 'stafylakis24_interspeech', 'loss margin logit principled angular merely softmax target deterministic cross-entropy'], ['Federico Lo Iacono, Valentina Colonna, Antonio Romano', 'Preservation, conservation and phonetic study of the voices of Italian poets: A study on the seven years of the VIP archive', 'loiacono24_interspeech', 'poetic cultural preserving oral crucial conserving inheritance fragile project culturally'], ['Si-Ioi Ng, Lingfeng Xu, Kimberly D. Mueller, Julie Liss, Visar Berisha', 'Segmental and Suprasegmental Speech Foundation Models for Classifying Cognitive Risk Factors: Evaluating Out-of-the-Box Performance', 'ng24_interspeech', 'trillsson clinical mci dementia precludes macro-f intraclass use-cases analysis challenged'], ['Miku Nishihara, Dan Wells, Korin Richmond, Aidan Pine', 'Low-dimensional Style Token Control for Hyperarticulated Speech Synthesis', 'nishihara24_interspeech', 'clear pca variation gsts gst dimension tt example space text-tospeech'], ['Janek Ebbers, FranÃ§ois G. Germain, Gordon Wichern, Jonathan Le Roux', 'Sound Event Bounding Boxes', 'ebbers24_interspeech', 'extent presence frame-level confidence thresholding prediction posterior psds frame decouple'], ['Youssef Nafea, Shady Shehata, Zeerak Talat, Ahmed Aboeitta, Ahmed Sharshar, Preslav Nakov', 'AraOffence: Detecting Offensive Speech Across Dialects in Arabic Media', 'nafea24_interspeech', 'nlp labelled text image dialectical abuse under-represented content swahili language'], ['Yuri Khokhlov, Tatiana Prisyach, Anton Mitrofanov, Dmitry Dutov, Igor Agafonov, Tatiana Timofeeva, Aleksei Romanenko, Maxim Korenevsky', 'Classification of Room Impulse Responses and its application for channel verification and diarization', 'khokhlov24_interspeech', 'rir embeddings rirs meeting-like libricss acoustic reverb bearing experiment voxceleb'], ['Alessandro De Luca, Andrew Clark, Volker Dellwo', 'NumberLie: a game-based experiment to understand the acoustics of deception and truthfulness', 'deluca24_interspeech', 'player immediate truth game precise consequence backed trustworthiness lying tailor'], ['Rongshuai Wu, Debasish Ray Mohapatra, Sidney Fels', 'Modeling Vocal Tract Like Acoustic Tubes Using the Immersed Boundary Method', 'wu24o_interspeech', 'solver wave fdtd tube grid geometry regular lagrangian finite-difference discretization'], ['Johanna Cronenberg, Ioana Chitoran, Lori Lamel, Ioana Vasilescu', 'Crosslinguistic Comparison of Acoustic Variation in the Vowel Sequences /ia/ and /io/ in Four Romance Languages', 'cronenberg24_interspeech', 'hiatus diphthong differ formant prefers respect account romanian mix inclusion'], ['Aleksei Gusev, Anastasia Avdeeva', 'Improvement Speaker Similarity for Zero-Shot Any-to-Any Voice Conversion of Whispered and Regular Speech', 'gusev24_interspeech', 'transfer generated unexplored domain lightweight truth streaming quality ground reconstruct'], ['Haibin Wu, Yuan Tseng, Hung-yi Lee', 'CodecFake: Enhancing Anti-Spoofing Models Against Deepfake Audios from Codec-Based Speech Synthesis Systems', 'wu24p_interspeech', 'sota counter current synthesized detect unanswered empowers effectively misuse curate'], ['Joseph Coffey, Okko RÃ¤sÃ¤nen, Camila Scaff, Alejandrina Cristia', 'The Difficulty and Importance of Estimating the Lower and Upper Bounds of Infant Speech Exposure', 'coffey24_interspeech', 'estimate year computational range language plausibility benchmarking discussing well-established usable'], ['John Murzaku, Adil Soubki, Owen Rambow', 'Multimodal Belief Prediction', 'murzaku24_interspeech', 'bert whisper audio fine-tunes corpus commitment text-only approached task text'], ['Dominik Wagner, Ilja Baumann, Korbinian Riedhammer, Tobias Bocklet', 'Outlier Reduction with Gated Attention for Improved Post-training Quantization in Large Sequence-to-sequence Speech Foundation Models', 'wagner24_interspeech', 'gating whisper transformer-based student impede necessitating mechanism mitigation tensor -bit'], ["Allahsera Tapo, Ãric Le Ferrand, Zoey Liu, Christopher Homan, Emily Prud'hommeaux", 'Leveraging Speech Data Diversity to Document Indigenous Heritage and Culture', 'tapo24_interspeech', 'asr history mali mande corpus fieldwork culturally archival commonality diminish'], ['Badr M. Abdullah, Mohammed Maqsood Shaik, Dietrich Klakow', 'Wave to Interlingua: Analyzing Representations of Multilingual Speech Transformers for Spoken Language Translation', 'abdullah24_interspeech', 'language-neutral encoder shared probing across finding interpretability untranscribed speech-to-text trained'], ['Mingshuai Liu, Zhuangqi Chen, Xiaopeng Yan, Yuanjun Lv, Xianjun Xia, Chuanzeng Huang, Yijian Xiao, Lei Xie', 'RaD-Net 2: A causal two-stage repairing and denoising speech enhancement network with knowledge distillation and complex axial self-attention', 'liu24n_interspeech', 'ssi icassp future upgraded dnsmos stage non-causal use challenge receptive'], ['Paula Andrea PÃ©rez-Toro, Tomas Arias-Vergara, Philipp Klumpp, Tobias Weise, Maria Schuster, Elmar Noeth, Juan Rafael Orozco-Arroyave, Andreas Maier', 'Multilingual Speech and Language Analysis for the Assessment of Mild Cognitive Impairment: Outcomes from the Taukadial Challenge', 'pereztoro24_interspeech', 'language-dependent timing hallmark alzheimer dementia neurological uar english manifest decline'], ['Ivan Yakovlev, Rostislav Makarov, Andrei Balykin, Pavel Malov, Anton Okhotnikov, Nikita Torgashov', 'Reshape Dimensions Network for Speaker Recognition', 'yakovlev24_interspeech', 'block map reshaping aggregation versa vice representation facilitating scalable topology'], ['Matthew Maciejewski, Dominik Klement, Ruizhe Huang, Matthew Wiesner, Sanjeev Khudanpur', 'Evaluating the Santa Barbara Corpus: Challenges of the Breadth of Conversational Spoken Language', 'maciejewski24_interspeech', 'party speech problem matured overlooking dinner necessitates heterogeneity technology push'], ['Dominik Wagner, Sebastian P. Bayerl, Ilja Baumann, Elmar Noeth, Korbinian Riedhammer, Tobias Bocklet', 'Large Language Models for Dysfluency Detection in Stuttered Speech', 'wagner24b_interspeech', 'multi-label llm dysfluencies finetune inclusive stuttering non-lexical audio processor deployment'], ["Johannah O'Mahony, Catherine Lai, Ãva SzÃ©kely", 'Well, what can you do with messy data? Exploring the prosody and pragmatic function of the discourse marker &quot;well&quot; with found data and speech synthesis', 'omahony24_interspeech', 'realisation prosodic conversational explore controllable synthesise unlabelled centroid untranscribed subtle'], ['Zhongweiyang Xu, Ali Aroudi, Ke Tan, Ashutosh Pandey, Jung-Suk Lee, Buye Xu, Francesco Nesta', 'FoVNet: Configurable Field-of-View Speech Enhancement with Low Computation and Distortion for Smart Glasses', 'xu24i_interspeech', 'multi-channel efficiency ultra-low solution excels efficient computational designed needing within'], ['Ilja Baumann, Nicole Unger, Dominik Wagner, Korbinian Riedhammer, Tobias Bocklet', 'Automatic Evaluation of a Sentence Memory Test for Preschool Children', 'baumann24_interspeech', 'correctness recited early assessment syntactic capability semantic potential timely childhood'], ['Jinzuomu Zhong, Yang Li, Hui Huang, Korin Richmond, Jie Liu, Zhiba Su, Jing Guo, Benlai Tang, Fengjie Zhu', 'Multi-Modal Automatic Prosody Annotation with Contrastive Pretraining of Speech-Silence and Word-Punctuation', 'zhong24c_interspeech', 'prosodic text-speech stage labor-intensive boundary controllable controllability bearing inconsistent sota'], ['Ilja Baumann, Dominik Wagner, Maria Schuster, Korbinian Riedhammer, Elmar Noeth, Tobias Bocklet', 'Towards Self-Attention Understanding for Automatic Articulatory Processes Analysis in Cleft Lip and Palate Speech', 'baumann24b_interspeech', 'clp phoneme interpretability paving diagnostics anomaly multi-head long-range classification characteristic'], ['Pooneh Mousavi, Jarod Duret, Salah Zaiem, Luca Della Libera, Artem Ploujnikov, Cem Subakan, Mirco Ravanelli', 'How Should We Extract Discrete Audio Tokens from Self-Supervised Models?', 'mousavi24_interspeech', 'ssl semantic ideal configuration optimal layer identify attention benchmarked tokenization'], ['Dominika Woszczyk, Ranya Aloufi, Soteris Demetriou', 'Prosody-Driven Privacy-Preserving Dementia Detection', 'woszczyk24_interspeech', 'embeddings -score privacy preserving speaker limited-resource anonymize adresso adress identifiable'], ['Minh Nguyen, Toan Quoc Nguyen, Kishan KC, Zeyu Zhang, Thuy Vu', 'Reinforcement Learning from Answer Reranking Feedback for Retrieval-Augmented Answer Generation', 'nguyen24c_interspeech', 'odqa reward rag misaligned factual open-domain model human retrieving answering'], ['Gasser Elbanna, Zohreh Mostaani, Mathew Magimai.-Doss', 'Predicting Heart Activity from Speech using Data-driven and Knowledge-based features', 'elbanna24_interspeech', 'physiological self-supervised acoustic speaker-related underscore unexplored speech-related biological generalizability representation'], ['Jinuk Kwon, David Harwath, Debadatta Dash, Paul Ferrari, Jun Wang', 'Direct Speech Synthesis from Non-Invasive, Neuromagnetic Signals', 'kwon24_interspeech', 'brain neural neuroimaging meg magnetoencephalography bci invasive overt electrode mel-spectrograms'], ['Menglu Li, Xiao-Ping Zhang', 'Interpretable Temporal Class Activation Representation for Audio Spoofing  Detection', 'li24oa_interspeech', 'interpretability model fostering t-dcf multi-label trust decision-making transparency bonafide localize'], ['Peter Mihajlik, Yan Meng, Mate S Kadar, Julian Linke, Barbara Schuppler, Katalin MÃ¡dy', 'On Disfluency and Non-lexical Sound Labeling for End-to-end Automatic Speech Recognition', 'mihajlik24_interspeech', 'label filled pause grunt conversational delete decent backchannels asr disfluent'], ['David Looney, Nikolay D. Gaubitch', 'Robust spread spectrum speech watermarking using linear prediction and deep spectral shaping', 'looney24_interspeech', 'music signal deepfake centre date attack primarily classical implication call'], ['Ashutosh Pandey, Sanha Lee, Juan Azcarreta, Daniel Wong, Buye Xu', 'All Neural Low-latency Directional Speech Extraction', 'pandey24_interspeech', 'doa quickly model embeddings capability scenario frame abrupt hand-crafted grid'], ['Benazir Mumtaz, Miriam Butt', 'Urdu Alternative Questions: A Hat Pattern', 'mumtaz24_interspeech', 'altqs spacing contour realization german accent noting prolonged featuring focus'], ['Kevin Huang, Jack Goldberg, Louis Goldstein, Shrikanth Narayanan', 'Analysis of articulatory setting for L1 and L2 English speakers using MRI data', 'huang24i_interspeech', 'acquired articulation korea posture geographical positional united india china draw'], ['Kuang Yuan, Shuo Han, Swarun Kumar, Bhiksha Raj', 'DeWinder: Single-Channel Wind Noise Reduction using Ultrasound Sensing', 'yuan24_interspeech', 'doppler ultrasonic outdoor deep-learning mitigating characteristic airflow fuse quality treat'], ['Mohammad Amaan Sayeed, Hanan Aldarmaki', 'Spoken Word2Vec: Learning Skipgram Embeddings from Speech', 'sayeed24_interspeech', 'encode distributional semantic semantics examine similarity resulting relatedness analogous phonetic'], ['Giulia Sanguedolce, Sophie Brook, Dragos C. Gruia, Patrick A. Naylor, Fatemeh Geranmayeh', 'When Whisper Listens to Aphasia: Advancing Robust Post-Stroke Speech Recognition', 'sanguedolce24_interspeech', 'aphasiabank generalisability intervention asr ai-based wer asrs stroke standardised surpassing'], ['Sidi Yaya Arnaud Yarga, Sean U N Wood', 'Neuromorphic Keyword Spotting with Pulse Density Modulation MEMS Microphones', 'yarga24_interspeech', 'spiking device gsc energy kw command ssc snn stage continuous'], ['Yuzhe Wang, Anna Favaro, Thomas Thebaud, Jesus Villalba, Najim Dehak, Laureano Moro-Velazquez', 'Exploring the Complementary Nature of Speech and Eye Movements for Profiling Neurological Disorders', 'wang24ka_interspeech', 'nd disease ocular parkinson differentiated search subject thief visual visit'], ['Amrutha Prasad, Srikanth Madikeri, Driss Khalil, Petr Motlicek, Christof Schuepbach', 'Speech and Language Recognition with Low-rank Adaptation of Pretrained Models', 'prasad24_interspeech', 'xls-r finetuning whisper drop connected fully resource constraint layer training'], ['Kwangyoun Kim, Suwon Shon, Yi-Te Hsu, Prashant Sridhar, Karen Livescu, Shinji Watanabe', 'Convolution-Augmented Parameter-Efficient Fine-Tuning for Speech Recognition', 'kim24s_interspeech', 'peft bottleneck lora low-rank adapter hubert fine-tune method numerous convolution'], ['Jonathan Him Nok Lee, Mark Liberman, Martin Salzmann', 'Do we EXPECT TO find phonetic traces for syntactic traces?', 'lee24l_interspeech', 'intervening contraction theory regression presence lenition posited contradict multinomial inaudible'], ['Chaofei Fan, Jaimie M. Henderson, Chris Manning, Francis R. Willett', 'Towards a Quantitative Analysis of Coarticulation with a Phoneme-to-Articulatory Model', 'fan24c_interspeech', 'ema magnitude extent longer-range resistance phoneme comprehensively across sequence replicate'], ['Angelo Ortiz Tandazo, Thomas Schatz, Thomas Hueber, Emmanuel Dupoux', 'Simulating articulatory trajectories with phonological feature interpolation', 'ortiztandazo24_interspeech', 'phonology generative perception-production correlation linear co-articulation biological pearson optimisation loop'], ['Tejes Srivastava, Jiatong Shi, William Chen, Shinji Watanabe', 'EFFUSE: Efficient Self-Supervised Feature Fusion for E2E ASR in Low Resource and Multilingual Scenarios', 'srivastava24_interspeech', 'ssl model fusing ml-superb parameter performance size superb average increase'], ['David Meyer, Eitan Abecassis, Clara Fernandez-Labrador, Christopher Schroers', 'RAST: A Reference-Audio Synchronization Tool for Dubbed Content', 'meyer24b_interspeech', 'translated disengagement sync intermittent defect detection misalignment viewer siamese issue'], ['Natalia Morozova, Guanghao You, Sabine Stoll, Adrian Bangerter', 'Measuring acoustic dissimilarity of hierarchical markers in task-oriented dialogue with MFCC-based dynamic time warping', 'morozova24_interspeech', 'transition horizontal vertical acoustically block interactants unfold navigating okay vertically'], ['Daniel Escobar-Grisales, Cristian David RÃ­os-Urrego, Ilja Baumann, Korbinian Riedhammer, Elmar Noeth, Tobias Bocklet, Adolfo M. Garcia, Juan Rafael Orozco-Arroyave', 'Itâs Time to Take Action: Acoustic Modeling of Motor Verbs to Detect Parkinsonâs Disease', 'escobargrisales24_interspeech', 'yielded representation pre-trained discrimination non-motor accuracy neurocognitive model well-established frame-by-frame'], ['Abderrahim Fathan, Xiaolin Zhu, Jahangir Alam', 'On the impact of several regularization techniques on label noise robustness of self-supervised speaker verification systems', 'fathan24_interspeech', 'pls sssv sub-centers investigative loss mixup clustering-based pseudo-labels thorough effect'], ['Aravind Krishnan, Badr M. Abdullah, Dietrich Klakow', 'On the Encoding of Gender in Transformer-based ASR Representations', 'krishnan24_interspeech', 'layer erasing erasure concentration prospect uncover compromising explaining hubert utilization'], ['Xianrui Zheng, Guangzhi Sun, Chao Zhang, Philip C. Woodland', 'SOT Triggered Neural Clustering for Speaker Attributed ASR', 'zheng24d_interspeech', 'sdnc diarisation eval cascaded assign ami system cpwer parallel label'], ['AriÃ«lle Reitsema, Chenxin Li, Leanne van Lambalgen, Laura Preining, Saskia Galindo Jong, Qing Yang, Xinyi Wen, Yiya Chen', 'Perceptual Learning in Lexical Tone: Phonetic Similarity vs. Phonological Categories', 'reitsema24_interspeech', 'contour rising pitch exposure interpretation suprasegmentally recalibrate recalibration disambiguating listener'], ['Wonjune Kang, Deb Roy', 'Prompting Large Language Models with Audio for General-Purpose Speech Summarization', 'kang24d_interspeech', 'llm speech-text text reasoning framework processing summarize input cascade summary'], ['Zehua Kcriss Li, Meiying Melissa Chen, Yi Zhong, Pinxin Liu, Zhiyao Duan', 'GTR-Voice: Articulatory Phonetics Informed Controllable Expressive Speech Synthesis', 'li24pa_interspeech', 'gtr actor professional voice framework dimension tt mastered lens tenseness'], ['Mostafa Shahin, Beena Ahmed', 'Phonological-Level Mispronunciation Detection and Diagnosis', 'shahin24_interspeech', 'mdd phoneme-level pronunciation diagnostic phoneme error false detect rate limited'], ['Tatsunari Takagi, Yukoh Wakabayashi, Atsunori Ogawa, Norihide Kitaoka', 'Text-only Domain Adaptation for CTC-based Speech Recognition through Substitution of Implicit Linguistic Information in the Search Space', 'takagi24_interspeech', 'ctc asr dra method japanese practicality english-language character-level accommodated model'], ['Rishi Jain, Bohan Yu, Peter Wu, Tejas Prabhune, Gopala Anumanchipalli', 'Multimodal Segmentation for Vocal Tract Modeling', 'jain24_interspeech', 'rt-mri articulator mri internal labeling video occluded label dataset -speaker'], ['Gowtham Premananth, Yashish M. Siriwardena, Philip Resnik, Sonia Bansal, Deanna L.Kelly, Carol Espy-Wilson', 'A Multimodal Framework for the Assessment of the Schizophrenia Spectrum', 'premananth24_interspeech', 'fusion weighted modality bi-modal unit -score gated bimodal unimodal symptom'], ['Orchid Chetia Phukan, Gautam Siddharth Kashyap, Arun Balaji Buduru, Rajesh Sharma', 'Are Paralinguistic Representations all that is needed for Speech Emotion Recognition?', 'phukan24b_interspeech', 'ptm ser sota trillsson ml-superb ptms superb fill facilitated attributed'], ['Justin Lovelace, Soham Ray, Kwangyoun Kim, Kilian Q. Weinberger, Felix Wu', 'Sample-Efficient Diffusion for Text-To-Speech Synthesis', 'lovelace24_interspeech', 'sesd le latent vall-e speech regime synthesizes auto-regressive modest impressive'], ['Tomas Arias-Vergara, Paula Andrea PÃ©rez-Toro, Xiaofeng Liu, Fangxu Xing, Maureen Stone, Jiachen Zhuo, Jerry L. Prince, Maria Schuster, Elmar Noeth, Jonghye Woo, Andreas Maier', 'Contrastive Learning Approach for Assessment of Phonological Precision in Patients with Tongue Cancer Using MRI Data', 'ariasvergara24_interspeech', 'class clinical recognition high-resolution frame-wise unavailable synchronized magnetic application imaging'], ['Manila Kodali, Sudarsana Reddy Kadiri, Paavo Alku', 'Fine-tuning of Pre-trained Models for Classification of Vocal Intensity Category from Speech Signals', 'kodali24_interspeech', 'regulate spl loud wav vec arbitrary amplitude scale label occasion'], ['Prad Kadambi, Tristan Mahr, Lucas Annear, Henry Nomeland, Julie Liss, Katherine Hustad, Visar Berisha', "How Does Alignment Error Affect Automated Pronunciation Scoring in Children's Speech?", 'kadambi24_interspeech', 'pllr deviation forced phoneme score manual computed effect magnified using'], ['Chenzi Xu, Jessica Wormald, Paul Foulkes, Philip Harrison, Vincent Hughes, Poppy Welch, Finnian Kelly, David van der Vloed', 'Voice quality in telephone speech: Comparing acoustic measures between VoIP telephone and high-quality recordings', 'xu24j_interspeech', 'cpp studio forensic condition harmonics-to-noise recording differentiation susceptible creaky breathy'], ['Yongyi Zang, Jiatong Shi, You Zhang, Ryuichi Yamamoto, Jionghao Han, Yuxun Tang, Shengyuan Xu, Wenxiao Zhao, Jing Guo, Tomoki Toda, Zhiyao Duan', 'CtrSVDD: A Benchmark Dataset and Baseline Analysis for Controlled Singing Voice Deepfake Detection', 'zang24_interspeech', 'bonafide accessible vocal publicly hour licensing method necessitate datasets controllability'], ['Xi Liu, John H.L. Hansen', 'DNN-based monaural speech enhancement using alternate analysis windows for phase and magnitude modification', 'liu24o_interspeech', 'hanning window stft enhancing phase-aware chebyshev apollo fearless quefrency evolves'], ['Dena Mujtaba, Nihar R. Mahapatra, Megan Arney, J. Scott Yaruss, Caryn Herring, Jia Bin', 'Inclusive ASR for Disfluent Speech: Cascaded Large-Scale Self-Supervised Learning with Targeted Fine-Tuning and Data Augmentation', 'mujtaba24_interspeech', 'inclusivity involuntary enriches datasets stutter curated asrs pave dataset barrier'], ['May Pik Yu Chan, Jianjing Kuang', 'Pitch-driven adjustments in tongue positions: Insights from ultrasound imaging', 'chan24_interspeech', 'pitch adjust participant range resonance sing space higher semitone production'], ['Jiatong Shi, Shih-Heng Wang, William Chen, Martijn Bartelds, Vanya Bannihatti Kumar, Jinchuan Tian, Xuankai Chang, Dan Jurafsky, Karen Livescu, Hung-yi Lee, Shinji Watanabe', 'ML-SUPERB 2.0: Benchmarking Multilingual Speech Models Across Modeling Constraints, Languages, and Datasets', 'shi24g_interspeech', 'downstream ssl setup benchmark performance find asr shallow targeted treat'], ['Khai Le-Duc, Khai-Nguyen Nguyen, Long Vo-Dang, Truong-Son Hy', 'Real-time Speech Summarization for Medical Conversations', 'leduc24_interspeech', 'summary conversation doctor-patient deployable collaboratively first standpoint posing thirdly gold'], ['Jiatong Shi, Xutai Ma, Hirofumi Inaguma, Anna Sun, Shinji Watanabe', 'MMM: Multi-Layer Multi-Residual Multi-Stream Discrete Speech Representation from Self-supervised Learning Model', 'shi24h_interspeech', 'ssl unit on-par compatibility surpass resynthesis lag various k-means codec'], ['Hazim Bukhari, Soham Deshmukh, Hira Dhamyal, Bhiksha Raj, Rita Singh', 'SELM: Enhancing Speech Emotion Recognition for Out-of-Domain Scenarios', 'bukhari24_interspeech', 'ser ood ravdess formulation situation crema-d curated inspiration performance formulate'], ['Paul Best, Santiago Cuervo, Ricard Marxer', 'Transfer Learning from Whisper for Microscopic Intelligibility Prediction', 'best24_interspeech', 'macroscopic response deep model scale predict lexical speech-in-noise word-error-rate listener'], ['Irene Smith, Morgan Sonderegger, The Spade Consortium', 'Modelled Multivariate Overlap: A method for measuring vowel merger', 'smith24_interspeech', 'distribution tension empirical modelling univariate affinity bhattacharyya extraneous unbalanced measure'], ['Tejumade Afonja, Tobi Olatunji, Sewade Ogun, Naome A. Etori, Abraham Owodunni, Moshood Yekini', 'Performant ASR Models for Medical Entities in Accented Speech', 'afonja24_interspeech', 'clinical wer drug rigorously error posing stride healthcare accelerated safety'], ['Prakash Kumar, Ye Tian, Yongwan Lim, Sophia X. Cui, Christina Hagedorn, Dani Byrd, Uttam K. Sinha, Shrikanth Narayanan, Krishna S. Nayak', 'State-of-the-art speech production MRI protocol for new 0.55 Tesla scanners', 'kumar24b_interspeech', 'rt-mri imaging platform real-time tract blurring biofeedback vocal safe slice'], ['Yiwen Shao, Shi-Xiong Zhang, Dong Yu', 'RIR-SF: Room Impulse Response Based Spatial Feature for Target Speech Recognition in Multi-Channel Multi-Speaker Scenarios', 'shao24_interspeech', 'reflection wave asr all-neural overlooking rir hinders speaker overcoming multi-talker'], ['Margaret Kroll, Kelsey Kraus', 'Optimizing the role of human evaluation in LLM-based spoken document summarization systems', 'kroll24_interspeech', 'llm paradigm replicability bertscore human-in-the-loop abstractive content rouge trustworthiness ability'], ['Robin Netzorg, Alyssa Cote, Sumi Koshin, Klo Vivienne Garoute, Gopala Krishna Anumanchipalli', 'Speech After Gender: A Trans-Feminine Perspective on Next Steps for Speech Science and Technology', 'netzorg24_interspeech', 'voice speaker texture modification vocal fail categorical notion static identity'], ['Irina-Elena Veliche, Zhuangqun Huang, Vineeth Ayyat Kochaniyan, Fuchun Peng, Ozlem Kalinli, Michael L. Seltzer', 'Towards measuring fairness in speech recognition: Fair-Speech dataset', 'veliche24_interspeech', 'demographic asr ethnicity submit geographic self-reported saying across united untranscribed'], ['Yiwen Shao, Shi-Xiong Zhang, Yong Xu, Meng Yu, Dong Yu, Daniel Povey, Sanjeev Khudanpur', 'Multi-Channel Multi-Speaker ASR Using Target Speakerâs Solo Segment', 'shao24b_interspeech', 'solo-sf array microphone circumventing alimeeting voiceprint layout discerning formidable effective'], ['Eunice Akani, Frederic Bechet, BenoÃ®t Favre, Romain Gemignani', 'Unified Framework for Spoken Language Understanding and Summarization in Task-Based Human Dialog processing', 'akani24_interspeech', 'summary dialogue task-related decoda goal-oriented summarizing information concise multitask process'], ['Sewade Ogun, Abraham T. Owodunni, Tobi Olatunji, Eniola Alese, Babatunde Oladimeji, Tejumade Afonja, Kayode Olaleye, Naome A. Etori, Tosin Adewumi', '1000 African Voices: Advancing inclusive multi-speaker multi-accent speech synthesis', 'ogun24_interspeech', 'persona creation automated geography data-rich continent under-represented content accent like'], ['Minxue Niu, Mimansa Jaiswal, Emily Mower Provost', 'From Text to Emotion: Unveiling the Emotion Annotation Capabilities of LLMs', 'niu24d_interspeech', 'gpt- human model impact training underestimate potential assisting underscore automating'], ['Dawei Liang, Alice Zhang, David Harwath, Edison Thomaz', 'Improving Audio Classification with Low-Sampled Microphone Input: An Empirical Study Using Model Self-Distillation', 'liang24_interspeech', 'khz panns sampling mobile high-quality traction lower rate low-quality wearable'], ['Emily P. Ahn, Eleanor Chodroff, Myriam Lapierre, Gina-Anne Levow', 'The Use of Phone Categories and Cross-Language Modeling for Phone Alignment of PanÃ£ra', 'ahn24d_interspeech', 'forced granularity model pretrained language-specific low-resource acoustic language amazonian broadening'], ['Ioana Colgiu, Laura Spinu, Rajiv Rao, Yasaman Rafat', 'Bilingual Rhotic Production Patterns: A Generational Comparison of Spanish-English Bilingual Speakers in Canada', 'colgiu24_interspeech', 'cli trill late early drift approximant tap alveolar phonemic producing'], ['Nana Lin, Youxiang Zhu, Xiaohui Liang, John A. Batsis, Caroline Summerour', 'Analyzing Multimodal Features of Spontaneous Voice Assistant Commands for Mild Cognitive Impairment Detection', 'lin24l_interspeech', 'mci intent task fusion in-home subdomains read progressing dementia classification'], ['K R Prajwal, Triantafyllos Afouras, Andrew Zisserman', 'Speech Recognition Models are Strong Lip-readers', 'prajwal24_interspeech', 'lip-reading pre-trained asr lip video mapping perform model lr regime'], ['Yuxun Tang, Yuning Wu, Jiatong Shi, Qin Jin', 'SingOMD: Singing Oriented Multi-resolution Discrete Representation Construction from Speech Models', 'tang24c_interspeech', 'ssl generation discretizing discretized resampling necessitates wherein feature resynthesis encounter'], ['Vrushank Changawala, Frank Rudzicz', 'Whister: Using Whisperâs representations for Stuttering detection', 'changawala24_interspeech', 'split dysfluency data cross-corpora specifically generalizable surpassing segment -second frozen'], ['Krishna C. Puvvada, Piotr Å»elasko, He Huang, Oleksii Hrinchuk, Nithin Rao Koluguri, Kunal Dhawan, Somshubra Majumdar, Elena Rastorgueva, Zhehuai Chen, Vitaly Lavrukhin, Jagadeesh Balam, Boris Ginsburg', 'Less is More: Accurate Speech Recognition &amp; Translation without Web-Scale Data', 'puvvada24_interspeech', 'model owsm canary training dynamic blending open-sourced state-of-the noise-robust whisper'], ['Junming Yuan, Ying Shi, LanTian Li, Dong Wang, Askar Hamdulla', 'Few-Shot Keyword Spotting from Mixed Speech', 'yuan24b_interspeech', 'pre-training fine-tuning solve keywords blended phase ssl-based effective struggle hubert'], ['Xintong Wang, Mingqian Shi, Ye Wang', 'Pitch-Aware RNN-T for Mandarin Chinese Mispronunciation Detection and Diagnosis', 'wang24la_interspeech', 'mdd stateless stage model pitch hubert scarcity acceptance two-stage solely'], ['Annika Heuser, Tyler Kendall, Miguel del Rio, Quinn McNamara, Nishchal Bhandari, Corey Miller, MigÃ¼el JettÃ©', 'Quantification of stylistic differences in human- and ASR-produced transcripts of African American English', 'heuser24_interspeech', 'aae verbatim transcriber asr human compounded underrepresented speech morphosyntactic categorize'], ['James Tavernor, Yara El-Tawil, Emily Mower Provost', 'The Whole Is Bigger Than the Sum of Its Parts: Modeling Individual Annotators to Capture Emotional Variability', 'tavernor24_interspeech', 'emotion distribution label nuanced inter-annotator lose cross-corpus address nuance learning'], ['Pavan Kalyan, Preeti Rao, Preethi Jyothi, Pushpak Bhattacharyya', 'Emotion Arithmetic: Emotional Speech Synthesis via Weight Space Interpolation', 'kalyan24_interspeech', 'vector behaviour task idea negation generation steer subtracting steering model'], ['Rui Liu, Jiatian Xi, Ziyue Jiang, Haizhou Li', 'FluentEditor: Text-based Speech Editing by Considering Acoustic and Prosody Consistency', 'liu24p_interspeech', 'fluency tse edited region -lab consistent constraint original vctk segment'], ['Yiru Zhang, Linyu Yao, Qun Yang', 'OR-TSE: An Overlap-Robust Speaker Encoder for Target Speech Extraction', 'zhang24p_interspeech', 'tse reference overlap embeddings pre-enrolled disregarding mixture non-overlapping attentive mainstream'], ['Hyung Yong Kim, Byeong-Yeol Kim, Yunkyu Lim, Jihwan Park, Shukjae Choi, Yooncheol Ju, Jinseok Park, Youshin Lim, Seung Woo Yu, Hanbin Lee, Shinji Watanabe', 'Self-training ASR Guided by Unsupervised ASR Teacher', 'kim24t_interspeech', 'pseudo-target vec dataset labeled pseudo-targets asr-related layer test-other test-clean model'], ['Suyuan Liu, Molly Babel, Jian Zhu', 'A comparison of voice similarity through acoustics, human perception and deep neural network (DNN) speaker verification systems', 'liu24q_interspeech', 'listener perceptual judgment assessed acoustic dis made generated happens score'], ['Zuheyra Tokac, Jennifer Cole', 'Phonological Symmetry Does Not Predict Generalization of Perceptual Adaptation to Vowels', 'tokac24_interspeech', 'lowered inventory variant -vowel identification lasting boundary symmetrical biasing induces'], ['Jingyi Feng, Yusuke Yasuda, Tomoki Toda', 'Exploring the Robustness of Text-to-Speech Synthesis Based on Diffusion Probabilistic Models to Heavily Noisy Transcriptions', 'feng24d_interspeech', 'tt volume transcription data flow-based diffusion-based mitigating suffers autoregressive extremely'], ['Annika Heuser, Jianjing Kuang', 'Information-theoretic hypothesis generation of relative cue weighting for the voicing contrast', 'heuser24b_interspeech', 'sae context child gleaned perceptual different obstruent coda helpful informative'], ['Anton de la Fuente, Dan Jurafsky', 'A layer-wise analysis of Mandarin and English suprasegmentals in SSL speech models', 'delafuente24_interspeech', 'wav vec representation layer suprasegmental later contextual stress represent mainly'], ['Linhan Ma, Dake Guo, Kun Song, Yuepeng Jiang, Shuai Wang, Liumeng Xue, Weiming Xu, Huan Zhao, Binbin Zhang, Lei Xie', 'WenetSpeech4TTS: A 12,800-hour Mandarin TTS Corpus for Large Speech Generation Model Benchmark', 'ma24d_interspeech', 'segment subset huggingface text-to-speech open-sourced audio-text multi-domain fair data eliminating'], ['Sri Harsha Dumpala, Katerina Dikaios, Abraham Nunes, Frank Rudzicz, Rudolf Uher, Sageev Oore', 'Self-Supervised Embeddings for Detecting Individual Symptoms of Depression', 'dumpala24b_interspeech', 'ssl severity predicting identifying small-sized elucidate depressive speech impacting learning'], ['Nan Chen, Yonghe Wang, Feilong Bao', 'Knowledge-Preserving Pluggable Modules for Multilingual Speech Translation Tasks', 'chen24w_interspeech', 'existing resampling retraining language regularization new performance cost model increase'], ['Oguzhan Baser, Kaan Kale, Sandeep P. Chinchali', 'SecureSpectra: Safeguarding Digital Identity from Deep Fake Threats via Intelligent Signatures', 'baser24_interspeech', 'misinformation irreversible unauthorized strike mozilla datasets delicate deepfake defense authentication'], ['Xiaohan Shi, Xingfeng Li, Tomoki Toda', 'Multimodal Fusion of Music Theory-Inspired and Self-Supervised Representations for Improved Emotion Recognition', 'shi24i_interspeech', 'mer modality modality-specific deepen effectiveness hinder underscore comprehensively challenge handcrafted'], ['Max Morrison, Cameron Churchwell, Nathan Pruyne, Bryan Pardo', 'Fine-Grained and Interpretable Neural Speech Editing', 'morrison24_interspeech', 'disentangled volume attribute representation identity timbral imperfection dialogue pronunciation fixing'], ['Matthew McNeill, Rivka Levitan', 'Autoregressive cross-interlocutor attention scores meaningfully capture conversational dynamics', 'mcneill24_interspeech', 'dialogue entrainment organize historical analyzes human-human partner human-machine qualitative history'], ['Yuning Wu, Chunlei Zhang, Jiatong Shi, Yuxun Tang, Shan Yang, Qin Jin', 'TokSing: Singing Voice Synthesis based on Discrete Tokens', 'wu24q_interspeech', 'melody svs token mel intermediate spectrogram offer selfsupervised witness discretization'], ['Viyazonuo Terhiija, Priyankoo Sarmah', 'Voiced and voiceless laterals in Angami', 'terhiija24_interspeech', 'distinction voicing delf cross-linguistically aspirated hnr exception context rare trait'], ['Linhan Ma, Xinfa Zhu, Yuanjun Lv, Zhichao Wang, Ziqian Wang, Wendi He, Hongbin Zhou, Lei Xie', 'Vec-Tok-VC+: Residual-enhanced Robust Zero-shot Voice Conversion with Progressive Constraints in a Dual-mode Training Strategy', 'ma24e_interspeech', 'training-inference content process multi-codebook mismatch prompt-based semantic similarity loss decoupling'], ['Jehyun Kyung, Serin Heo, Joon-Hyuk Chang', 'Enhancing Multimodal Emotion Recognition through ASR Error Compensation and LLM Fine-Tuning', 'kyung24_interspeech', 'mer asr-generated inaccuracy text cmt counteract blend system compromised nuance'], ['Slava Shechtman, Avihu Dekel', 'Low Bitrate High-Quality RVQGAN-based Discrete Speech Tokenizer', 'shechtman24_interspeech', 'tokenizers audio open-source reconstruction publicly token pcm speech-only tokenization bps'], ['Junghun Kim, Ka Hyun Park, Hoyoung Yoon, U Kang', 'Domain-Aware Data Selection for Speech Classification via Meta-Reweighting', 'kim24u_interspeech', 'domain instance source disorder utilizing target accurate softly specific given'], ['Jiali Cheng, Mohamed Elgaar, Nidhi Vakil, Hadi Amiri', 'CogniVoice: Multimodal and Multilingual Fusion Networks for Mild Cognitive Impairment Assessment from Spontaneous Speech', 'cheng24c_interspeech', 'mci mmse taukadial mini-mental point shortcut mitigates reliance decline rmse'], ['Shaowen Chen, Tomoki Toda', 'QHM-GAN: Neural Vocoder based on Quasi-Harmonic Modeling', 'chen24x_interspeech', 'qhm consumption vocoders speech quality network signal hifi-gan prominently black-box'], ['Tian-Hao Zhang, Xinyuan Qian, Feng Chen, Xu-Cheng Yin', 'Transmitted and Aggregated Self-Attention for Automatic Speech Recognition', 'zhang24q_interspeech', 'map attention layer transformer respectively information outstanding aishell- previous cer'], ['Bohan Li, Feiyu Shen, Yiwei Guo, Shuai Wang, Xie Chen, Kai Yu', 'On the Effectiveness of Acoustic BPE in Decoder-Only TTS', 'li24qa_interspeech', 'token slm speech setting semantic discretizing byte-pair libritts shorten favorable'], ['Tahir Javed, Janki Nawale, Sakshi Joshi, Eldho George, Kaushal Bhogale, Deovrat Mehendale, Mitesh M. Khapra', 'LAHAJA: A Robust Multi-accent Benchmark for Evaluating Hindi ASR Systems', 'javed24_interspeech', 'india diverse extempore north-east district accent sourced find existing terminology'], ['Alexis DeMaere, Nicole van Rootselaar, Fangfang Li, Robbin Gibb, Claudia L. R. Gonzalez', 'On the relationship between speech production and vocabulary size in 3-5 year olds', 'demaere24_interspeech', 'six-month multifaceted preschool complimentary null receptive versa vice sex comprehension'], ['Jens Heitkaemper, Joe Caroselli, Arun Narayanan, Nathan Howard', 'TfCleanformer: A streaming, array-agnostic, full- and sub-band modeling front-end for robust ASR', 'heitkaemper24_interspeech', 'enhancement upon non-causal agnostic multiple publication ablation multi-channel outperforming published'], ['Jaeuk Lee, Sohee Jang, Joon-Hyuk Chang', 'Neural ATSM: Fully Neural Network-based Adaptive Time-Scale Modification Using Sentence-Specific Dynamic Control', 'lee24m_interspeech', 'mfa phoneme sentence rate speaking networks-based scale tailoring phoneme-specific montreal'], ['Sara Ng, Gina-Anne Levow, Mari Ostendorf, Richard Wright', 'Investigating the Influence of Stance-Taking on Conversational Timing of Task-Oriented Speech', 'ng24b_interspeech', 'behavior stance turn-taking conversation northwest pacific measurably negotiation known speaker'], ['Darshan Prabhu, Yifan Peng, Preethi Jyothi, Shinji Watanabe', 'MULTI-CONVFORMER: Extending Conformer with Multiple Convolution Kernels', 'prabhu24_interspeech', 'module variant e-branchformer modelling local conformers rival efficient asr altering'], ['Yuan Gao, Hao Shi, Chenhui Chu, Tatsuya Kawahara', 'Speech Emotion Recognition with Multi-level Acoustic and Semantic Information Extraction and Interaction', 'gao24f_interspeech', 'ser extractor emotional asr embeddings system learn module existing gate'], ['Junwen Duan, Fangyuan Wei, Hong-Dong Li, Jin Liu', 'Pre-trained Feature Fusion and Matching for Mild Cognitive Impairment Detection', 'duan24_interspeech', 'mci language-agnostic diagnosis challenge taukadial delaying diagnose expressivity chinese-english progression'], ['Takuhiro Kaneko, Hirokazu Kameoka, Kou Tanaka, Yuto Kondo', 'FastVoiceGrad: One-step Diffusion-Based Voice Conversion with Adversarial Conditional Diffusion Distillation', 'kaneko24_interspeech', 'multi-step inference any-to-any one-shot dozen reverse performance high attracted notable'], ['Sangwon Ryu, Heejin Do, Yunsu Kim, Gary Geunbae Lee, Jungseul Ok', 'Key-Element-Informed sLLM Tuning for Document Summarization', 'ryu24_interspeech', 'llm proprietary key relevance high-quality element instructs fee hallucination low'], ['Haechan Kim, Junho Myung, Seoyoung Kim, Sungpah Lee, Dongyeop Kang, Juho Kim', 'LearnerVoice: A Dataset of Non-Native English Learnersâ Spontaneous Speech', 'kim24v_interspeech', 'ungrammatical vanilla disfluency consisting expression learner self-repairs datasets transcription attributable'], ['Kalvin Chang, Yi-Hui Chou, Jiatong Shi, Hsuan-Ming Chen, Nicole Holliday, Odette Scharenborg, David R. Mortensen', 'Self-supervised Speech Representations Still Struggle with African American Vernacular English', 'chang24d_interspeech', 'aave ssl variety mae asr gap model welldocumented marginalized reinforces'], ['Kaushal Santosh Bhogale, Deovrat Mehendale, Niharika Parasa, Sathish Kumar Reddy G, Tahir Javed, Pratyush Kumar, Mitesh M. Khapra', 'Empowering Low-Resource Language ASR via Large-Scale Pseudo Labeling', 'bhogale24_interspeech', 'pseudo-labeling benchmark youtube multiple labeled pseudo-labeled data existing evaluator augmenting'], ['Sai Harshitha Aluru, Jhansi Mallela, Chiranjeevi Yarra', 'Post-Net: A linguistically inspired sequence-dependent transformed neural architecture for automatic syllable stress detection', 'aluru24_interspeech', 'sota dependency supervised unsupervised isle existing model word syllable-level time-delay'], ['Conor Atkins, Ian Wood, Mohamed Ali Kaafar, Hassan Asghar, Nardine Basta, Michal Kepkowski', 'ConvoCache: Smart Re-Use of Chatbot Responses', 'atkins24_interspeech', 'prefetching coherence find prompt latency generative reuses chatbots caching reduce'], ['Liisa RÃ¤tsep, Rasmus Lellep, Mark Fishel', 'Enabling Conversational Speech Synthesis using Noisy Spontaneous Data', 'ratsep24_interspeech', 'lack stylistically read style text-to-speech datasets sample multi-style estonian compromise'], ['Jhansi Mallela, Sai Harshitha Aluru, Chiranjeevi Yarra', 'A comparative analysis of sequential models that integrate syllable dependency for automatic syllable stress detection', 'mallela24_interspeech', 'grus non-sequential stress-related overlook isle operated sequence lstms rnns identifies'], ['Yuanjun Lv, Hai Li, Ying Yan, Junhui Liu, Danming Xie, Lei Xie', 'FreeV: Free Lunch For Vocoders Through Pseudo Inversed Mel Filter', 'lv24_interspeech', 'apnet initialization inference speed amplitude parameter checkpoint pursuing streamlined mitigates'], ['Jiayan Lin, Shenghui Lu, Hukai Huang, Wenhao Guan, Binbin Xu, Hui Bu, Qingyang Hong, Lin Li', 'MinSpeech: A Corpus of Southern Min Dialect for Automatic Speech Recognition', 'lin24m_interspeech', 'hour hokkien diversely sourced encompassing audio hubert kaldi cultural conformer'], ['Chetan Sharma, Vaishnavi Chandwanshi, Prasanta Kumar Ghosh', 'A comparative study of the impact of voiceless alveolar and palato-alveolar sibilants in English on lip aperture and protrusion during VCV production', 'sharma24_interspeech', 'sibilant case usc change rounding higher vowel classification displacement irrespective'], ['Srija Anand, Praveen Srinivasa Varadhan, Ashwin Sankar, Giri Raju, Mitesh M. Khapra', 'Enhancing Out-of-Vocabulary Performance of Indian TTS Systems for Practical Applications through Low-Effort Data Strategies', 'anand24_interspeech', 'oov tamil hindi word benchmark containing code-mixing economically vocabulary artist'], ['Changli Tang, Wenyi Yu, Guangzhi Sun, Xianzhao Chen, Tian Tan, Wei Li, Jun Zhang, Lu Lu, Zejun Ma, Yuxuan Wang, Chao Zhang', 'Can Large Language Models Understand Spatial Audio?', 'tang24d_interspeech', 'llm fsr lse ssl amidst llm-based inferential via paving mae'], ['Praveen Srinivasa Varadhan, Ashwin Sankar, Giri Raju, Mitesh M Khapra', 'Rasa: Building Expressive Speech Synthesis Systems for Indian Languages in Low-resource Settings', 'srinivasavaradhan24_interspeech', 'neutral hour emotion data expressiveness syllabically prioritizing ekman assamese mushra'], ['Haotian Tan, Sakriani Sakti', 'Contrastive Feedback Mechanism for Simultaneous Speech Translation', 'tan24b_interspeech', 'sst cfm policy unstable prediction decision delaying overlook must-c undesired'], ['Marvin Tammen, Tsubasa Ochiai, Marc Delcroix, Tomohiro Nakatani, Shoko Araki, Simon Doclo', 'Array Geometry-Robust Attention-Based Neural Beamformer for Moving Speakers', 'tammen24_interspeech', 'asa module tuning manual microphone aggregator channel necessitating mask-based permutation'], ['Yi Lu, Yuankun Xie, Ruibo Fu, Zhengqi Wen, Jianhua Tao, Zhiyong Wang, Xin Qi, Xuefei Liu, Yongwei Li, Yukun Liu, Xiaopeng Wang, Shuchen Shi', 'Codecfake: An Initial Dataset for Detecting LLM-based Deepfake Audio', 'lu24f_interspeech', 'generation vocoder add codec neural process waveform multi-step final skipping'], ['Darshan Prabhu, Abhishek Gupta, Omkar Nitsure, Preethi Jyothi, Sriram Ganapathy', 'Improving Self-supervised Pre-training using Accent-Specific Codebooks', 'prabhu24b_interspeech', 'accent asr mozilla seldom finetuning invariance learnable learning trainable refined'], ['Mohamed Osman, Daniel Z. Kaplan, Tamer Nadeem', 'SER Evals: In-domain and Out-of-domain benchmarking for speech emotion recognition', 'osman24_interspeech', 'benchmark ssl model generalization diverse logit stride generalizable advent adaptability'], ['Socrates Vakirtzian, Chara Tsoukala, Stavros Bompolas, Katerina Mouzou, Vivian Stamou, Georgios Paraskevopoulos, Antonios Dimakis, Stella Markantonatou, Angela Ralli, Antonios Anastasopoulos', 'Speech Recognition for Greek Dialects: A Challenging Benchmark', 'vakirtzian24_interspeech', 'variety language encompassing overlooked non-standard asr convention arising impressive cross-lingual'], ['Vivian G. Li', 'In search of structure and correspondence in intra-speaker trial-to-trial variability', 'li24ra_interspeech', 'repetition point measurement position regulated distribution regulation study actively distributional'], ['Martino Ciaperoni, Athanasios Katsamanis, Aristides Gionis, Panagiotis Karras', 'Beam-search SIEVE for low-memory speech recognition', 'ciaperoni24_interspeech', 'beam memory overhead eliminates runtime via search linearly bottleneck viterbi'], ['Joonas Kalda, Tanel Alumae, Martin Lebourdais, HervÃ© Bredin, SÃ©verin Baroudi, Ricard Marxer', 'TalTech-IRIT-LIS Speaker and Language Diarization Systems for DISPLACE 2024', 'kalda24_interspeech', 'track ensemble team submission challenge separation embedding vbx pyannote ahc'], ['Zhenxiong Tan, Xinyin Ma, Gongfan Fang, Xinchao Wang', 'LiteFocus: Accelerated Diffusion Inference for Long Audio Synthesis', 'tan24c_interspeech', 'clip -second attention latent longer tta complicates diffusion-based model designated'], ['Tianhao Wang, Lantian Li, Dong Wang', 'SE/BN Adapter: Parametric Efficient Domain Adaptation for Speaker Recognition', 'wang24ma_interspeech', 'fine-tuning pre-trained well-optimized inefficiency competes cn-celeb freezing ample squeeze-and-excitation inspiration'], ['Zhenyu Zhou, Shibiao Xu, Shi Yin, Lantian Li, Dong Wang', 'A Comprehensive Investigation on Speaker Augmentation for Speaker Recognition', 'zhou24f_interspeech', 'vtlp perturbation potential hinting delve cn-celeb new pivotal underscore proficient'], ['Vrunda N. Sukhadia, Shammur Absar Chowdhury', 'Childrenâs Speech Recognition through Discrete Token Enhancement', 'sukhadia24_interspeech', 'privacy single-view data multi-view asr degrading transforming scarcity low-resource approximate'], ['Dehua Tao, Tan Lee, Harold Chui, Sarah Luk', 'Learning Representation of Therapist Empathy in Counseling Conversation Using Siamese Hierarchical Attention Network', 'tao24b_interspeech', 'embeddings contrastive rating encoder turn learn loss two-level positively subjectively'], ['Shu Li, Peng Zhang, Ye Li', 'Robust Voice Activity Detection using Locality-Sensitive Hashing and Residual Frequency-Temporal Attention', 'li24sa_interspeech', 'contextual vad hourglass mechanism frame analogous enrich auc structure learning'], ['Marianne de Heer Kloots, Willem Zuidema', 'Human-like Linguistic Biases in Neural Speech Models: Phonetic Categorization and Phonotactic Constraints in Wav2Vec2.0', 'deheerkloots24_interspeech', 'bias controlled stimulus phonotactically individual amplified sound localize unit embed'], ['Ajinkya Kulkarni, Atharva Kulkarni, Miguel Couceiro, Isabel Trancoso', 'Unveiling Biases while Embracing Sustainability: Assessing the Dual Challenges of Automatic Speech Recognition Systems', 'kulkarni24_interspeech', 'asr bias carbon mm massively sota consumption emission offering whisper'], ['Franziska Braun, Sebastian P. Bayerl, Florian HÃ¶nig, Hartmut Lehfeld, Thomas Hillemacher, Tobias Bocklet, Korbinian Riedhammer', 'Infusing Acoustic Pause Context into Text-Based Dementia Assessment', 'braun24_interspeech', 'cognitive impairment test biomarker exclusion alzheimer cross-attention mild non-invasive alongside'], ['Xiaolou Li, Zehua Liu, Chen Chen, Lantian Li, Li Guo, Dong Wang', 'Zero-Shot Fake Video Detection by Audio-Visual Consistency', 'li24ta_interspeech', 'genuine audio the-art delineated state-of content vsr one-class anchored advocated'], ['Heejin Do, Wonjun Lee, Gary Geunbae Lee', 'Acoustic Feature Mixup for Balanced Multi-aspect Pronunciation Assessment', 'do24_interspeech', 'tailor non-linearly speechocean error-rate hint interpolating suit enriched imbalance mispronunciation'], ['Ashish Mittal, Darshan Prabhu, Sunita Sarawagi, Preethi Jyothi', 'SALSA: Speedy ASR-LLM Synchronous Aggregation', 'mittal24_interspeech', 'llm decoder asr coupling low-resource mismatch layer tokenizers harnessing fleurs'], ['Takuma Okamoto, Yamato Ohtani, Sota Shimizu, Tomoki Toda, Hisashi Kawai', 'Challenge of Singing Voice Synthesis Using Only Text-To-Speech Corpus With FIRNet Source-Filter Neural Vocoder', 'okamoto24_interspeech', 'svs tt phoneme shift duration input prototyped hifi-gan acoustic controllability'], ['Yuepeng Jiang, Tao Li, Fengyu Yang, Lei Xie, Meng Meng, Yujun Wang', 'Towards Expressive Zero-Shot Speech Synthesis with Hierarchical Prosody Modeling', 'jiang24d_interspeech', 'timbre expressiveness global model naturalness synthesized adaptor introduce hierarchically diffusion'], ['Chen Chen, Zehua Liu, Xiaolou Li, Lantian Li, Dong Wang', 'CNVSRC 2023: The First Chinese Continuous Visual Speech Recognition Challenge', 'chen24y_interspeech', 'vsr single-speaker cnceleb summarises encompassing comprehensively task registered org probe'], ['Joyshree Chakraborty, Leena Dihingia, Priyankoo Sarmah, Rohit Sinha', 'On Comparing Time- and Frequency-Domain Rhythm Measures in Classifying Assamese Dialects', 'chakraborty24_interspeech', 'assam district amplitude-modulated variety wind sun quadratic domain comprise broadly'], ['Rui Liu, Zening Ma', 'Emotion-Aware Speech Self-Supervised Representation Learning with Intensity Knowledge', 'liu24r_interspeech', 'emotion masking speech-emotion -lab prior npc overlook emotion-related neglecting prevailing'], ['Vasista Sai Lodagala, Abhishek Biswas, Shoutrik Das, Jordan F, S Umesh', 'All Ears: Building Self-Supervised Learning based ASR models for Indian Languages at scale', 'lodagala24_interspeech', 'ssl downstream benchmark speech signifies out-perform curate abundance superb across'], ['Yo-Han Park, Wencke Liermann, Yong-Seok Choi, Seung Hi Kim, Jeong-Uk Bang, Seung Yun, Kong Joo Lee', 'Backchannel prediction, based on who, when and what', 'park24b_interspeech', 'talk counseling backchanneling conversation model information backchannels interpersonal piece korean'], ['Haoqin Sun, Shiwan Zhao, Xiangyu Kong, Xuechen Wang, Hui Wang, Jiaming Zhou, Yong Qin', 'Iterative Prototype Refinement for Ambiguous Speech Emotion Recognition', 'sun24e_interspeech', 'ipr label ser precise ambiguity subtlety daunting reinforcing urgent proving'], ['Bao Thang Ta, Minh Tu Le, Van Hai Do, Huynh Thi Thanh Binh', 'Enhancing No-Reference Speech Quality Assessment with Pairwise, Triplet Ranking Losses, and ASR Pretraining', 'ta24_interspeech', 'sqa mse sample distinction relative nisqa symmetrically enforcing garnered among'], ['Kumar Neelabh, Vishnu Sreekumar', 'From Sound to Meaning in the Auditory Cortex: A Neuronal Representation and Classification Analysis', 'neelabh24_interspeech', 'category semantic understood informative neural acoustic repertoire vocalization incoming listened'], ['Roland Hartanto, Sakriani Sakti, Koichi Shinoda', 'MSDET: Multitask Speaker Separation and Direction-of-Arrival Estimation Training', 'hartanto24_interspeech', 'lbt location sms-wsj location-based estoi si-sdr point azimuth doa permutation'], ['Bao Thang Ta, Van Hai Do, Huynh Thi Thanh Binh', 'Enhancing Non-Matching Reference Speech Quality Assessment through Dynamic Weight Adaptation', 'ta24b_interspeech', 'fixed rigidly pristine roll nisqa sqa training assigns multitask accommodate'], ['Anna Min, Chenxu Hu, Yi Ren, Hang Zhao', 'A Unit-based System and Dataset for Expressive Direct Speech-to-Speech Translation', 'min24_interspeech', 'paralinguistic naturalness overlooking curated retains movie natural-sounding conveying research concentrate'], ['Bonian Jia, Huiyao Chen, Yueheng Sun, Meishan Zhang, Min Zhang', 'LLM-Driven Multimodal Opinion Expression Identification', 'jia24_interspeech', 'oei dataset text subtlety underlining encompass delivering depression mirror advancing'], ['Takayuki Arai, Ryohei Suzuki, Chandler Earp, Shinya Tsuji, Keiko Ochi', 'Production of phrases by mechanical models of the human vocal tract', 'arai24_interspeech', 'cam model rotating movable successfully pipe japanese three-tube morning mechanism'], ['Vishal Gourav, Ankit Tyagi, Phanindra Mankale', 'Faster Vocoder: a multi threading approach to achieve low latency during TTS Inference', 'gourav24_interspeech', 'cpl customer time fast text get service processing buy ssml'], ['Aanchan Mohan, Monideep Chakraborti, Katelyn Eng, Nailia Kushaeva, Mirjana Prpa, Jordan Lewis, Tianyi Zhang, Vince Geisler, Carol Geisler', 'A powerful and modern AAC composition tool for impaired speakers', 'mohan24_interspeech', 'message contextually software empowering large-language relevant communication augmentative authenticity able'], ['Grzegorz P. Mika, Konrad ZieliÂ´nski, PaweÅ Cyrta, Marek Grzelec', 'VoxFlow AI: wearable voice converter for atypical speech', 'mika24_interspeech', 'interaction loudspeaker neurological tell demonstration real-life daily usability lie action'], ['Sai Akarsh, Vamshiraghusimha Narasinga, Anil Kumar Vuppala', 'Stress transfer in speech-to-speech machine translation', 'akarsh24_interspeech', 'file speech inclusivity diminishing content sector hindering give monotonous underscore'], ['Takuma Okamoto, Yamato Ohtani, Hisashi Kawai', 'Mobile PresenTra: NICT fast neural text-to-speech system on smartphones with incremental inference of MS-FC-HiFi-GAN for law-latency synthesis', 'okamoto24b_interspeech', 'vocoder smartphone high-fidelity transformer encoder decoder prototyped convnext attendee low-latency'], ['Alex PeirÃ³-Lilja, JosÃ© Giraldo, MartÃ­ Llopart-Font, Carme Armentano-Oller, Baybars KÃ¼lebi, Mireia FarrÃºs', 'Multi-speaker and multi-dialectal Catalan TTS models for video gaming', 'peirolilja24_interspeech', 'multi-accent demo game exported export unity reply architecture reproduced execution'], ['Juliana Francis, Ãva SzÃ©kely, Joakim Gustafson', 'ConnecTone: a modular AAC system prototype with contextual generative text prediction and style-adaptive conversational TTS', 'francis24_interspeech', 'implement transformative testing adjustable augmentative anticipate technology language context-sensitive delivery'], ['Mahdin Rohmatillah, Bryan Gautama Ngo, Willianto Sulaiman, Po-Chuan Chen, Jen-Tzung Chien', 'Reliable dialogue system for facilitating student-counselor communication', 'rohmatillah24_interspeech', 'counselor student mental waiting health history period university dashboard in-person'], ['Yashwardhan Chaudhuri, Paridhi Mundra, Arnesh Batra, Orchid Chetia Phukan, Arun Balaji Buduru', 'ASGIR: audio spectrogram transformer guided classification and information retrieval for birds', 'chaudhuri24_interspeech', 'bird ecological sound habitat conservation wikipedia pivotal localize geographical judging'], ['Devyani Koshal, Orchid Chetia Phukan, Sarthak Jain, Arun Balaji Buduru, Rajesh Sharma', 'PERSONA: an application for emotion recognition, gender recognition and age estimation', 'koshal24_interspeech', 'ptm task obviates model stride concurrently deploying comparatively learning sota'], ['Kesavaraj V, Charan Devarkonda, Vamshiraghusimha Narasinga, Anil Kumar Vuppala', 'Custom wake word detection', 'v24_interspeech', 'keyword open-vocabulary audio-text text embedding personalizing suffered preventing knowledge audio'], ['Song Chen, Mandar Gogate, Kia Dashtipour, Jasper Kirton-Wingate, Adeel Hussain, Faiyaz Doctor, Tughrul Arslan, Amir Hussain', 'Edged based audio-visual speech enhancement demonstrator', 'chen24z_interspeech', 'hearing aid customizing phone noisy anticipate assistive smartphone healthcare advancing'], ['Arif Reza Anway, Bryony Buck, Mandar Gogate, Kia Dashtipour, Michael Akeroyd, Amir Hussain', 'Real-Time Gaze-directed speech enhancement for audio-visual hearing-aids', 'anway24_interspeech', 'avse gaze eye nose estimation angle enhancing pose head hearing'], ['Abhishek Kumar, Srikanth Konjeti, Jithendra Vepa', 'Detection of background agents speech in contact centers', 'kumar24c_interspeech', 'conversation call inadvertently unintended utilise nearby mitigating proximity security quality'], ['Sarthak Jain, Orchid Chetia Phukan, Arun Balaji Buduru, Rajesh Sharma', 'The reasonable effectiveness of speaker embeddings for violence detection', 'jain24b_interspeech', 'avd ssl model sota ptms recognition harm preventing hinder environment'], ['Giovanni Morrone, Enrico Zovato, Fabio Brugnara, Enrico Sartori, Leonardo Badino', 'A toolkit for joint speaker diarization and identification with application to speaker-attributed ASR', 'morrone24_interspeech', 'configuration institutional use-case analytics speaker-related multiple registered user-friendly web-based modular'], ['Leonie Schade, Nico Dallmann, Olcay TÃ¼k, Stefan Lazarov, Petra Wagner', 'Understanding âunderstandingâ: presenting a richly annotated multimodal corpus of dyadic interaction', 'schade24_interspeech', 'annotation non-verbal explanation behaviour past modality gaze explaining several level'], ['Joao Vitor Possamai de Menezes, Arne-Lukas Fietkau, Tom Diener, Steffen Kurbis, Peter Birkholz', 'A demonstrator for articulation-based command word recognition', 'possamaidemenezes24_interspeech', 'software classification device record recording measuring operating articulation system single'], ['Nigel G. Ward, Andres Segura', 'Pragmatically similar utterance finder demonstration', 'ward24b_interspeech', 'similarity participant retrieves listens letting viewer model prospect hear identifies'], ['Elena Ryumina, Dmitry Ryumin, Alexey Karpov', 'OCEAN-AI: open multimodal framework for personality traits assessment and HR-processes automatization', 'ryumina24_interspeech', 'pta module behaving responsibility siamese thinking feeling including automate human'], ['Paridhi Mundra, Manik Sharma, Yashwardhan Chaudhuri, Orchid Chetia Phukan, Arun Balaji Buduru', 'VoxMed: one-step respiratory disease classifier using digital stethoscope sounds', 'mundra24_interspeech', 'patient github classify icbhi ast portugal greece illness recording repository'], ['Sarthak Sharma, Orchid Chetia Phukan, Drishti Singh, Arun Balaji Buduru, Rajesh Sharma', 'AVR: synergizing foundation models for audio-visual humor detection', 'sharma24b_interspeech', 'textual reliance asr circumvents hinge lean necessitating centered intricate eliminating'], ['Harm Lameris, Joakim Gustafson, Ãva SzÃ©kely', 'CreakVC: a voice conversion tool for modulating creaky voice', 'lameris24_interspeech', 'one-shot creak phonation representation level plotting human-in-the-loop cue finetuned modulate'], ['Yu-Sheng Tsao, Yung-Chang Hsu, Jiun-Ting Li, Siang-Hong Weng, Tien-Hong Lo, Berlin Chen', 'EZTalking: English assessment platform for teachers and students', 'tsao24_interspeech', 'feedback capt learning exercise pronunciation portfolio mock ai-powered empowers grasp'], ['Bramhendra Koilakuntla, Prajesh Rana, Paras Ahuja, Srikanth Konjeti, Jithendra Vepa', 'Leveraging large language models for post-transcription correction in contact centers', 'koilakuntla24_interspeech', 'anchor downstream context brand correct compounded skilled transcription analytics pinpoint'], ['Dmitrii Obukhov, Marcel de Korte, Andrey Adaschik', 'ATTEST: an analytics tool for the testing and evaluation of speech technologies', 'obukhov24_interspeech', 'metric released powerful framework acknowledging need user-friendly alongside encourage large'], ['Margot Masson, Erfan A. Shams, Iona Gessinger, Julie Carson-Berndsen', 'PhoneViz: exploring alignments at a glance', 'masson24_interspeech', 'phone spanish-accented chart substituted showcase helping user ipa phonetic concrete'], ['ClÃ©ment Pages, HervÃ© Bredin', 'Gryannote open-source speaker diarization labeling tool', 'pages24_interspeech', 'pyannote pipeline export ecosystem upload hyper-parameters customize visualize component custom'], ['Kai Liu, Ziqing Du, Zhou Huan, Xucheng Wan, Naijun Zheng', 'Real-time scheme for rapid extraction of speaker embeddings in challenging recording conditions', 'liu24s_interspeech', 'speaker-related enrollment target task embedding pristine three-stage realm compromising non-target'], ['Meenakshi Sirigiraju, Arjun Rajasekar, Abhishikth Meejuri, Chiranjeevi Yarra', 'IIITH Ucchar e-Sudharak: an automatic English pronunciation corrector for school-going children with a teacher in the loop', 'sirigiraju24_interspeech', 'tool skill practice student word-level gap sentence language catering empowers'], ['Boon Peng Yap, Kok Liang Tan, Zhenghao Li, Rong Tong', 'Speech enabled visual acuity test', 'yap24_interspeech', 'user posture eye system self-paced sight communicates automatically private recognizes'], ['Mayuko Aiba, Daisuke Saito, Nobuaki Minematsu', 'A ChatGPT-based oral Q&A practice system for first-time student participants in international conferences', 'aiba24_interspeech', 'question chatgpt configuration affirmed generation reference upload uploaded orally verbally'], ['Szu-Yu Chen, Tien-Hong Lo, Yao-Ting Sung, Ching-Yu Tseng, Berlin Chen', 'TEEMI: a speaking practice tool for L2 English learners', 'chen24aa_interspeech', 'foreign user automated assessment globalization surpassed laptop tablet language english-speaking'], ['Karthik Venkat Sridaran, Raja Praveen, Reuben T Varghese, Ajish K Abraham, Shankar R, Winnie Rachel Cherian', 'Visual scene display application for augmentative and alternative communication', 'sridaran24_interspeech', 'aac individual development ability language enhance icon webpage ensured limited'], ['Ikuyo Masuda-Katsuse, Ayako Shirose', 'CALL system using pitch-accent feature representations reflecting listenersâ subjective adequacy', 'masudakatsuse24_interspeech', 'quantitatively accepted implement evaluating learner japanese accent native automatically pitch'], ['Jonathan L Preston, Nina R Benway, Nathan Prestopnik, Nathan Preston', 'The speech motor chaining web app for speech motor learning', 'preston24_interspeech', 'principle telepractice invoke apps design computerized underlie illustrates highlighting therapy'], ['Charlotte Yoder, Karrie Karahalios, Mark Hasegawa-Johnson, Shreyansh Agrawal', 'Visualization for improving foreign language pronunciation', 'yoder24_interspeech', 'chart vowel coherently seldom calibrated tutorial execution learning emphasized page'], ['Nhan Phan, Anna von Zansen, Maria Kautonen, TamÃ¡s GrÃ³sz, Mikko Kurimo', 'CaptainA self-study mobile app for practising speaking: task completion assessment and feedback with generative AI', 'phan24b_interspeech', 'language learner finnish providing picture-based automatic visual nlg grading asa'], ['Mohd Mujtaba Akhtar,  Girish, Orchid Chetia Phukan, Muskaan Singh', 'NeuRO: an application for code-switched autism detection in children', 'akhtar24_interspeech', 'asd individual disorder conversation communication code-switch posing challenge repetitive code-switching'], ['Orchid Chetia Phukan, Sarthak Jain, Shubham Singh, Muskaan Singh, Arun Balaji Buduru, Rajesh Sharma', 'ComFeAT: combination of neural and spectral features for improved depression detection', 'phukan24c_interspeech', 'ptms extracted decline sota previous trained individually speech-based paralinguistic cnn'], ['Isabel Trancoso', 'Towards Responsible Speech Processing', 'trancoso24_interspeech', 'pillar fairness explainability urgent uniquely nonetheless attempting inform inclusion survey'], ['Shoko Araki', 'Frontier of Frontend for Conversational Speech Processing', 'araki24_interspeech', 'conversation technology distant diarization evolution decade talk progress enhancement microphone'], ['Elmar Noeth', 'Analysis of Pathological Speech â Pitfalls along the Way', 'noeth24_interspeech', 'congenital biomarker aspect explainability defect various privacy disease motivation regular'], ['Barbara Tillmann', 'Perception of music and speech: Focus on rhythm processing', 'tillmann24_interspeech', 'rhythmic research language cognitive disorder early revealed dyslexia hypothesis neuroscience']],
                    stateSave: true,
                    columnDefs: [
                        { targets: [0],
                          className: 'dt-left',
                          "mRender": function (data, type, full) {
                              return '<a class="w3-text" href="' + full[2] + '.html' + '">' + full[1] + '<br><span class="w3-text w3-text-theme">' + full[0] + '</span></a>';
                          }
                        },
                        { targets: [1, 2, 3],
                          visible: false,
                        },
                    ],
                    "lengthMenu": [7, 10, 20, 50, 100, 200, 500],
                    "pageLength": 50,
                    "order": [[ 0, 'asc' ]],
                    scrollY:        '60vh',
                    "dom": '<"top"l>rft<"bottom"ip><"clear">',
                    "pagingType": "full_numbers",
                    paging:         true
                });

            });

        </script>

    </body>
</html>